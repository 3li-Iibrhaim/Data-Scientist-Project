{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dde1b98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T05:11:04.325574Z",
     "iopub.status.busy": "2023-08-07T05:11:04.324323Z",
     "iopub.status.idle": "2023-08-07T05:11:04.330766Z",
     "shell.execute_reply": "2023-08-07T05:11:04.329708Z"
    },
    "papermill": {
     "duration": 0.013349,
     "end_time": "2023-08-07T08:08:43.982674",
     "exception": false,
     "start_time": "2023-08-07T08:08:43.969325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **FINAL SUBMISSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6bfdce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T08:08:44.010742Z",
     "iopub.status.busy": "2023-08-07T08:08:44.010218Z",
     "iopub.status.idle": "2023-08-07T08:08:44.015879Z",
     "shell.execute_reply": "2023-08-07T08:08:44.014781Z"
    },
    "papermill": {
     "duration": 0.024635,
     "end_time": "2023-08-07T08:08:44.020666",
     "exception": false,
     "start_time": "2023-08-07T08:08:43.996031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I will use 2 notebook for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a03684",
   "metadata": {
    "papermill": {
     "duration": 0.012395,
     "end_time": "2023-08-07T08:08:44.045442",
     "exception": false,
     "start_time": "2023-08-07T08:08:44.033047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NOTEBOOK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d31179d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T08:08:44.071773Z",
     "iopub.status.busy": "2023-08-07T08:08:44.071485Z",
     "iopub.status.idle": "2023-08-07T08:08:44.075315Z",
     "shell.execute_reply": "2023-08-07T08:08:44.074445Z"
    },
    "papermill": {
     "duration": 0.019396,
     "end_time": "2023-08-07T08:08:44.077362",
     "exception": false,
     "start_time": "2023-08-07T08:08:44.057966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -q /kaggle/input/tabpfn-019-whl/tabpfn-0.1.9-py3-none-any.whl\n",
    "# !mkdir /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n",
    "# !cp /kaggle/input/tabpfn-019-whl/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "334233d9",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-08-07T08:08:44.103810Z",
     "iopub.status.busy": "2023-08-07T08:08:44.103546Z",
     "iopub.status.idle": "2023-08-07T08:08:48.835796Z",
     "shell.execute_reply": "2023-08-07T08:08:48.834852Z"
    },
    "papermill": {
     "duration": 4.748316,
     "end_time": "2023-08-07T08:08:48.838352",
     "exception": false,
     "start_time": "2023-08-07T08:08:44.090036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "import random\n",
    "import gc\n",
    "# from tabpfn import TabPFNClassifier\n",
    "# Import sklearn classes for model selection, cross validation, and performance evaluation\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import seaborn as sns\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder, CountEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Import libraries for Hypertuning\n",
    "import optuna\n",
    "\n",
    "# Import libraries for gradient boosting\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import NuSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from catboost import CatBoost, CatBoostRegressor, CatBoostClassifier\n",
    "from catboost import Pool\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e130f7dd",
   "metadata": {
    "papermill": {
     "duration": 0.012559,
     "end_time": "2023-08-07T08:08:48.864716",
     "exception": false,
     "start_time": "2023-08-07T08:08:48.852157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d445f2ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T08:08:48.892024Z",
     "iopub.status.busy": "2023-08-07T08:08:48.891714Z",
     "iopub.status.idle": "2023-08-07T08:08:48.973011Z",
     "shell.execute_reply": "2023-08-07T08:08:48.971940Z"
    },
    "papermill": {
     "duration": 0.09801,
     "end_time": "2023-08-07T08:08:48.975362",
     "exception": false,
     "start_time": "2023-08-07T08:08:48.877352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AM</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BD</th>\n",
       "      <th>BN</th>\n",
       "      <th>BP</th>\n",
       "      <th>BQ</th>\n",
       "      <th>BR</th>\n",
       "      <th>CB</th>\n",
       "      <th>...</th>\n",
       "      <th>FE</th>\n",
       "      <th>FI</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.209377</td>\n",
       "      <td>3109.03329</td>\n",
       "      <td>22.394407</td>\n",
       "      <td>9.812214</td>\n",
       "      <td>4126.58731</td>\n",
       "      <td>22.5984</td>\n",
       "      <td>175.638726</td>\n",
       "      <td>152.707705</td>\n",
       "      <td>823.928241</td>\n",
       "      <td>47.223358</td>\n",
       "      <td>...</td>\n",
       "      <td>9028.291921</td>\n",
       "      <td>3.583450</td>\n",
       "      <td>7.298162</td>\n",
       "      <td>1.73855</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>11.339138</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>2003.810319</td>\n",
       "      <td>22.136229</td>\n",
       "      <td>0.120343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.145282</td>\n",
       "      <td>978.76416</td>\n",
       "      <td>36.968889</td>\n",
       "      <td>13.517790</td>\n",
       "      <td>5496.92824</td>\n",
       "      <td>19.4205</td>\n",
       "      <td>155.868030</td>\n",
       "      <td>14.754720</td>\n",
       "      <td>51.216883</td>\n",
       "      <td>30.284345</td>\n",
       "      <td>...</td>\n",
       "      <td>6785.003474</td>\n",
       "      <td>10.358927</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.568932</td>\n",
       "      <td>9.292698</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>27981.562750</td>\n",
       "      <td>29.135430</td>\n",
       "      <td>21.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470030</td>\n",
       "      <td>2635.10654</td>\n",
       "      <td>32.360553</td>\n",
       "      <td>12.824570</td>\n",
       "      <td>5135.78024</td>\n",
       "      <td>26.4825</td>\n",
       "      <td>128.988531</td>\n",
       "      <td>219.320160</td>\n",
       "      <td>482.141594</td>\n",
       "      <td>32.563713</td>\n",
       "      <td>...</td>\n",
       "      <td>8338.906181</td>\n",
       "      <td>11.626917</td>\n",
       "      <td>7.709560</td>\n",
       "      <td>0.97556</td>\n",
       "      <td>1.198821</td>\n",
       "      <td>37.077772</td>\n",
       "      <td>88.609437</td>\n",
       "      <td>13676.957810</td>\n",
       "      <td>28.022851</td>\n",
       "      <td>0.196941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AB          AF         AM         AZ          BD       BN  \\\n",
       "0  0.209377  3109.03329  22.394407   9.812214  4126.58731  22.5984   \n",
       "1  0.145282   978.76416  36.968889  13.517790  5496.92824  19.4205   \n",
       "2  0.470030  2635.10654  32.360553  12.824570  5135.78024  26.4825   \n",
       "\n",
       "           BP          BQ          BR         CB  ...           FE         FI  \\\n",
       "0  175.638726  152.707705  823.928241  47.223358  ...  9028.291921   3.583450   \n",
       "1  155.868030   14.754720   51.216883  30.284345  ...  6785.003474  10.358927   \n",
       "2  128.988531  219.320160  482.141594  32.563713  ...  8338.906181  11.626917   \n",
       "\n",
       "         FL       FR        FS         GB         GE            GF         GH  \\\n",
       "0  7.298162  1.73855  0.094822  11.339138  72.611063   2003.810319  22.136229   \n",
       "1  0.173229  0.49706  0.568932   9.292698  72.611063  27981.562750  29.135430   \n",
       "2  7.709560  0.97556  1.198821  37.077772  88.609437  13676.957810  28.022851   \n",
       "\n",
       "          GL  \n",
       "0   0.120343  \n",
       "1  21.978000  \n",
       "2   0.196941  \n",
       "\n",
       "[3 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = '/kaggle/input/icr-identify-age-related-conditions'\n",
    "df_train = pd.read_csv(os.path.join(filepath, 'train.csv'), index_col=[0])\n",
    "df_test = pd.read_csv(os.path.join(filepath, 'test.csv'), index_col=[0])\n",
    "greeks = pd.read_csv(f'{filepath}/greeks.csv')\n",
    "\n",
    "\n",
    "df_train['EJ'] = df_train['EJ'].replace({'A': 0, 'B': 1})\n",
    "df_test['EJ']  = df_test['EJ'].replace({'A': 0, 'B': 1})\n",
    "df_train = df_train.rename(columns={'BD ': 'BD', 'CD ': 'CD', 'CW ': 'CW', 'FD ': 'FD'})\n",
    "df_test = df_test.rename(columns={'BD ': 'BD', 'CD ': 'CD', 'CW ': 'CW', 'FD ': 'FD'})\n",
    "target_col = 'Class'\n",
    "\n",
    "X_train = df_train.drop([f'{target_col}'],axis=1).reset_index(drop=True)\n",
    "y_train = df_train[f'{target_col}'].reset_index(drop=True)\n",
    "X_test = df_test.reset_index(drop=True)\n",
    "\n",
    "# for data in [X_train, X_test]:\n",
    "#     data['AB/DA'] = data['AB'] / data['DA']\n",
    "#     data['BP*DU'] =  data['BP'] * data['DU']\n",
    "#     data['DF*GL_2'] = data['DF'] * data['GL'].pow(2)\n",
    "#     data['DI/DL'] = data['DI'] / data['DL']\n",
    "#     data['CD/GE'] = data['CD'] / data['GE']\n",
    "#     data['EE*EP_2'] = data['EE'] * data['EP'].pow(2)\n",
    "#     data['AZ/EP'] = data['AZ'] / data['EP']\n",
    "#     data['CD/FD'] = data['CD'] / data['FD']\n",
    "#     data['FR/GE'] = data['FR'] / data['GE']\n",
    "#     data['AF/DL'] = data['AF'] / data['DL']\n",
    "#     data['DA_2*GF'] =  data['DA'].pow(2) * data['GF']\n",
    "#     data['AB/DE']  = data['AB'] / data['DE']\n",
    "#     data['DU*GH'] = data['DU'] * data['GH']\n",
    "#     data['BQ/GF'] = data['BQ'] / data['GF']\n",
    "#     data['DF*DI_2'] = data['DF'] * data['DI'].pow(2)\n",
    "#     data[ 'FC/FL'] = data['FC'] / data['FL']\n",
    "#     data['CC/DI'] = data['CC'] / data['DI']\n",
    "#     data['DU*FL_2'] = data['DU'] * data['FL'].pow(2)\n",
    "#     data['AF/EG'] = data['AF'] / data['EG']\n",
    "#     data['CC_2*DN'] = data['CC'].pow(2) * data['DN']\n",
    "#     data['AF/AY'] = data['AF'] / data['AY']\n",
    "#     data['BN/DI'] = data['BN'] / data['DI']\n",
    "#     data['DI_2*DU'] = data['DI'].pow(2) * data['DU']\n",
    "#     data['DF*GL'] = data['DF'] * data['GL']\n",
    "#     data['DL_2*EE'] = data['DL'].pow(2) * data['EE']\n",
    "#     data['AB_2*BQ'] = data['AB'].pow(2) * data['BQ']\n",
    "#     data['DI*DU'] = data['DI'] * data['DU']\n",
    "#     data['BQ*DY'] = data['BQ'] * data['DY']\n",
    "#     data['CR_2*DH'] = data['CR'].pow(2) * data['DH']\n",
    "#     data['BQ*DY_2'] = data['BQ'] * data['DY'].pow(2)\n",
    "#     data['AF/EP'] = data ['AF'] / data['EP']\n",
    "#     data['AB/EG'] = data['AB'] / data['EG']\n",
    "#     data['AB*EL'] = data['AB'] * data['EL']\n",
    "#     data['AY/DU'] = data['AY'] / data['DU']\n",
    "#     data['CC/DU'] = data['CC'] / data['DU']\n",
    "#     data['CR/DU'] = data['CR'] / data['DU']\n",
    "#     data['DL/DY'] = data['DL'] / data['DY']\n",
    "#     data['DA_2*EE'] = data['DA'].pow(2) * data['EE']\n",
    "#     data['AB/FD'] = data['AB'] / data['FD']\n",
    "#     data['DA_2*DE'] = data['DA'].pow(2) * data['DE']\n",
    "#     data['DU/GL'] = data['DU'] / data['GL']\n",
    "#     data['CD/EE'] = data['CD'] / data['EE']\n",
    "#     data['BQ_2*FE'] = data['BQ'].pow(2) * data['FE']\n",
    "#     data['AF/GE'] = data['AF'] / data['GE']\n",
    "#     data['AB/CR'] = data['AB'] / data['CR']\n",
    "#     data['DU/FI'] = data['DU'] / data['FI']\n",
    "#     data['BC*FL_2'] = data['BC'].pow(2) * data['FL'].pow(2)\n",
    "#     data['CC*CR_2'] = data['CC'] * data['CR'].pow(2)\n",
    "#     data['AB/DU'] = data['AB'] / data['DU']\n",
    "#     data['AB/FL'] = data['AB'] / data['FL']\n",
    "#     data['BC*DU_2'] = data['BC'] * data['DU'].pow(2)\n",
    "#     data['DU_2*FR'] = data['DU'].pow(2) * data['FR']\n",
    "#     data['DH/DU'] = data['DH'] / data['DU']\n",
    "#     data['DA/DI'] = data['DA'] / data['DI']\n",
    "#     data['AB/CH'] = data['AB'] / data['CH']\n",
    "#     data['BQ/EE'] = data['BQ'] / data['EE']\n",
    "#     data['AM/DU'] = data['AM'] / data['DU']\n",
    "    \n",
    "drop_cols = ['AH', 'AR', 'AY', 'BZ', 'CF', 'CL', 'GI', 'DH', 'FD', 'AX', 'BC']\n",
    "X_train = X_train.drop(drop_cols, axis=1)\n",
    "X_test =  X_test.drop(drop_cols, axis=1)\n",
    "\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d116e86d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T08:08:49.004386Z",
     "iopub.status.busy": "2023-08-07T08:08:49.003463Z",
     "iopub.status.idle": "2023-08-07T08:08:49.043443Z",
     "shell.execute_reply": "2023-08-07T08:08:49.042414Z"
    },
    "papermill": {
     "duration": 0.056825,
     "end_time": "2023-08-07T08:08:49.045746",
     "exception": false,
     "start_time": "2023-08-07T08:08:48.988921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AM</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BD</th>\n",
       "      <th>BN</th>\n",
       "      <th>BP</th>\n",
       "      <th>BQ</th>\n",
       "      <th>BR</th>\n",
       "      <th>CB</th>\n",
       "      <th>...</th>\n",
       "      <th>FE</th>\n",
       "      <th>FI</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.190105</td>\n",
       "      <td>8.042389</td>\n",
       "      <td>3.152497</td>\n",
       "      <td>2.380676</td>\n",
       "      <td>8.325448</td>\n",
       "      <td>22.5984</td>\n",
       "      <td>5.174107</td>\n",
       "      <td>5.035053</td>\n",
       "      <td>6.715296</td>\n",
       "      <td>3.875844</td>\n",
       "      <td>...</td>\n",
       "      <td>9.108229</td>\n",
       "      <td>1.522452</td>\n",
       "      <td>2.116034</td>\n",
       "      <td>1.007429</td>\n",
       "      <td>0.090592</td>\n",
       "      <td>2.512776</td>\n",
       "      <td>4.298795</td>\n",
       "      <td>7.603305</td>\n",
       "      <td>3.141400</td>\n",
       "      <td>0.120343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.135651</td>\n",
       "      <td>6.887312</td>\n",
       "      <td>3.636767</td>\n",
       "      <td>2.675375</td>\n",
       "      <td>8.612127</td>\n",
       "      <td>19.4205</td>\n",
       "      <td>5.055405</td>\n",
       "      <td>2.757140</td>\n",
       "      <td>3.955406</td>\n",
       "      <td>3.443118</td>\n",
       "      <td>...</td>\n",
       "      <td>8.822617</td>\n",
       "      <td>2.430004</td>\n",
       "      <td>0.159760</td>\n",
       "      <td>0.403503</td>\n",
       "      <td>0.450395</td>\n",
       "      <td>2.331435</td>\n",
       "      <td>4.298795</td>\n",
       "      <td>10.239337</td>\n",
       "      <td>3.405702</td>\n",
       "      <td>21.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.385283</td>\n",
       "      <td>7.877058</td>\n",
       "      <td>3.507374</td>\n",
       "      <td>2.626447</td>\n",
       "      <td>8.544182</td>\n",
       "      <td>26.4825</td>\n",
       "      <td>4.867446</td>\n",
       "      <td>5.395082</td>\n",
       "      <td>6.180310</td>\n",
       "      <td>3.513446</td>\n",
       "      <td>...</td>\n",
       "      <td>9.028807</td>\n",
       "      <td>2.535831</td>\n",
       "      <td>2.164421</td>\n",
       "      <td>0.680852</td>\n",
       "      <td>0.787921</td>\n",
       "      <td>3.639631</td>\n",
       "      <td>4.495461</td>\n",
       "      <td>9.523541</td>\n",
       "      <td>3.368083</td>\n",
       "      <td>0.196941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AB        AF        AM        AZ        BD       BN        BP  \\\n",
       "0  0.190105  8.042389  3.152497  2.380676  8.325448  22.5984  5.174107   \n",
       "1  0.135651  6.887312  3.636767  2.675375  8.612127  19.4205  5.055405   \n",
       "2  0.385283  7.877058  3.507374  2.626447  8.544182  26.4825  4.867446   \n",
       "\n",
       "         BQ        BR        CB  ...        FE        FI        FL        FR  \\\n",
       "0  5.035053  6.715296  3.875844  ...  9.108229  1.522452  2.116034  1.007429   \n",
       "1  2.757140  3.955406  3.443118  ...  8.822617  2.430004  0.159760  0.403503   \n",
       "2  5.395082  6.180310  3.513446  ...  9.028807  2.535831  2.164421  0.680852   \n",
       "\n",
       "         FS        GB        GE         GF        GH         GL  \n",
       "0  0.090592  2.512776  4.298795   7.603305  3.141400   0.120343  \n",
       "1  0.450395  2.331435  4.298795  10.239337  3.405702  21.978000  \n",
       "2  0.787921  3.639631  4.495461   9.523541  3.368083   0.196941  \n",
       "\n",
       "[3 rows x 45 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_cols = [_ for _ in X_train.columns if _ not in ['EJ', 'BN', 'CW', 'EL', 'GL']]\n",
    "X_train.loc[:, log_cols] = np.log1p(X_train.loc[:, log_cols])\n",
    "X_test.loc[:, log_cols] = np.log1p(X_test.loc[:, log_cols])\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99d82813",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T08:08:49.075748Z",
     "iopub.status.busy": "2023-08-07T08:08:49.074782Z",
     "iopub.status.idle": "2023-08-07T08:08:49.079912Z",
     "shell.execute_reply": "2023-08-07T08:08:49.078818Z"
    },
    "papermill": {
     "duration": 0.02266,
     "end_time": "2023-08-07T08:08:49.082086",
     "exception": false,
     "start_time": "2023-08-07T08:08:49.059426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  selected = ['AB/DA', 'BP*DU', 'DF*GL_2',\n",
    "#        'DI/DL', 'CD/GE', 'EE*EP_2', 'AZ/EP', 'CD/FD', 'FR/GE', 'AF/DL',\n",
    "#        'DA_2*GF', 'AB/DE', 'DU*GH', 'BQ/GF', 'DF*DI_2', 'FC/FL', 'CC/DI',\n",
    "#        'DU*FL_2', 'AF/EG', 'CC_2*DN', 'AF/AY', 'BN/DI', 'DI_2*DU', 'DF*GL',\n",
    "#        'DL_2*EE', 'AB_2*BQ', 'DI*DU', 'BQ*DY', 'CR_2*DH', 'BQ*DY_2', 'AF/EP',\n",
    "#        'AB/EG', 'AB*EL', 'AY/DU', 'CC/DU', 'CR/DU', 'DA_2*EE', 'AB/FD',\n",
    "#        'DA_2*DE', 'DU/GL', 'DL/DY', 'CD/EE', 'BQ_2*FE', 'AF/GE', 'AB/CR',\n",
    "#        'DU/FI', 'BC*FL_2', 'CC*CR_2', 'AB/DU', 'AB/FL', 'BC*DU_2', 'DU_2*FR',\n",
    "#        'DH/DU', 'DA/DI', 'AB/CH', 'BQ/EE', 'AM/DU']\n",
    "\n",
    "# X_train = X_train[selected]\n",
    "# X_test = X_test[selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b77a0b6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T08:08:49.112898Z",
     "iopub.status.busy": "2023-08-07T08:08:49.111995Z",
     "iopub.status.idle": "2023-08-07T08:08:49.163316Z",
     "shell.execute_reply": "2023-08-07T08:08:49.162330Z"
    },
    "papermill": {
     "duration": 0.069006,
     "end_time": "2023-08-07T08:08:49.165490",
     "exception": false,
     "start_time": "2023-08-07T08:08:49.096484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape :(617, 45) , y_train shape :(617,)\n",
      "X_test shape :(5, 45)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AM</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BD</th>\n",
       "      <th>BN</th>\n",
       "      <th>BP</th>\n",
       "      <th>BQ</th>\n",
       "      <th>BR</th>\n",
       "      <th>CB</th>\n",
       "      <th>...</th>\n",
       "      <th>FE</th>\n",
       "      <th>FI</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.793051</td>\n",
       "      <td>0.110642</td>\n",
       "      <td>-0.067111</td>\n",
       "      <td>0.025434</td>\n",
       "      <td>-0.598002</td>\n",
       "      <td>0.339209</td>\n",
       "      <td>-0.334638</td>\n",
       "      <td>0.868474</td>\n",
       "      <td>0.332908</td>\n",
       "      <td>0.046309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207783</td>\n",
       "      <td>-3.120884</td>\n",
       "      <td>0.843092</td>\n",
       "      <td>0.506545</td>\n",
       "      <td>-0.737475</td>\n",
       "      <td>-1.149987</td>\n",
       "      <td>-0.627728</td>\n",
       "      <td>-0.819140</td>\n",
       "      <td>-0.956392</td>\n",
       "      <td>-0.815091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.045391</td>\n",
       "      <td>-1.520469</td>\n",
       "      <td>0.506365</td>\n",
       "      <td>0.735599</td>\n",
       "      <td>0.281949</td>\n",
       "      <td>-0.575174</td>\n",
       "      <td>-0.605475</td>\n",
       "      <td>-1.238041</td>\n",
       "      <td>-2.518775</td>\n",
       "      <td>-0.446284</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228882</td>\n",
       "      <td>0.209787</td>\n",
       "      <td>-1.061092</td>\n",
       "      <td>-0.798943</td>\n",
       "      <td>0.593821</td>\n",
       "      <td>-1.585989</td>\n",
       "      <td>-0.627728</td>\n",
       "      <td>0.974516</td>\n",
       "      <td>-0.095903</td>\n",
       "      <td>1.303181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111391</td>\n",
       "      <td>-0.122825</td>\n",
       "      <td>0.353137</td>\n",
       "      <td>0.617694</td>\n",
       "      <td>0.073394</td>\n",
       "      <td>1.456789</td>\n",
       "      <td>-1.034331</td>\n",
       "      <td>1.201413</td>\n",
       "      <td>-0.219872</td>\n",
       "      <td>-0.366226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086357</td>\n",
       "      <td>0.598166</td>\n",
       "      <td>0.890191</td>\n",
       "      <td>-0.199406</td>\n",
       "      <td>1.842690</td>\n",
       "      <td>1.559328</td>\n",
       "      <td>-0.281317</td>\n",
       "      <td>0.487461</td>\n",
       "      <td>-0.218376</td>\n",
       "      <td>-0.807668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AB        AF        AM        AZ        BD        BN        BP  \\\n",
       "0 -0.793051  0.110642 -0.067111  0.025434 -0.598002  0.339209 -0.334638   \n",
       "1 -1.045391 -1.520469  0.506365  0.735599  0.281949 -0.575174 -0.605475   \n",
       "2  0.111391 -0.122825  0.353137  0.617694  0.073394  1.456789 -1.034331   \n",
       "\n",
       "         BQ        BR        CB  ...        FE        FI        FL        FR  \\\n",
       "0  0.868474  0.332908  0.046309  ...  0.207783 -3.120884  0.843092  0.506545   \n",
       "1 -1.238041 -2.518775 -0.446284  ... -0.228882  0.209787 -1.061092 -0.798943   \n",
       "2  1.201413 -0.219872 -0.366226  ...  0.086357  0.598166  0.890191 -0.199406   \n",
       "\n",
       "         FS        GB        GE        GF        GH        GL  \n",
       "0 -0.737475 -1.149987 -0.627728 -0.819140 -0.956392 -0.815091  \n",
       "1  0.593821 -1.585989 -0.627728  0.974516 -0.095903  1.303181  \n",
       "2  1.842690  1.559328 -0.281317  0.487461 -0.218376 -0.807668  \n",
       "\n",
       "[3 rows x 45 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns = [_ for _ in X_train.columns if _ not in ['EJ']]\n",
    "sc = StandardScaler() # MinMaxScaler or StandardScaler\n",
    "X_train[numeric_columns] = sc.fit_transform(X_train[numeric_columns])\n",
    "X_test[numeric_columns] = sc.transform(X_test[numeric_columns])\n",
    "\n",
    "print(f\"X_train shape :{X_train.shape} , y_train shape :{y_train.shape}\")\n",
    "print(f\"X_test shape :{X_test.shape}\")\n",
    "\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "feat = X_train.columns\n",
    "# Delete the train and test dataframes to free up memory\n",
    "del df_train, df_test\n",
    "\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca6282",
   "metadata": {
    "papermill": {
     "duration": 0.013526,
     "end_time": "2023-08-07T08:08:49.193265",
     "exception": false,
     "start_time": "2023-08-07T08:08:49.179739",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04e704dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T08:08:49.222464Z",
     "iopub.status.busy": "2023-08-07T08:08:49.222187Z",
     "iopub.status.idle": "2023-08-07T08:08:49.268531Z",
     "shell.execute_reply": "2023-08-07T08:08:49.267625Z"
    },
    "papermill": {
     "duration": 0.063356,
     "end_time": "2023-08-07T08:08:49.270529",
     "exception": false,
     "start_time": "2023-08-07T08:08:49.207173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Splitter:\n",
    "    def __init__(self, kfold=True, n_splits=10, greeks=pd.DataFrame()):\n",
    "        self.n_splits = n_splits\n",
    "        self.kfold = kfold\n",
    "        self.greeks = greeks\n",
    "\n",
    "    def split_data(self, X, y, random_state_list):\n",
    "        if self.kfold == 'skf':\n",
    "            for random_state in random_state_list:\n",
    "                kf = StratifiedKFold(n_splits=self.n_splits, random_state=random_state, shuffle=True)\n",
    "                for train_index, val_index in kf.split(X, y):\n",
    "                    if type(X) is np.ndarray:\n",
    "                        # DOWNSAMPLE NOTE WORK\n",
    "                        y_train = y.loc[train_index]\n",
    "                        UNT = y_train.loc[y_train==0].sample(\n",
    "                            frac=0.6, random_state=bag*n_reapts+n_splits).index.values\n",
    "                        train_index = np.setdiff1d(train_index,UNT)\n",
    "                        \n",
    "                        X_train, X_val = X[train_index], X[val_index]\n",
    "                        y_train, y_val = y[train_index], y[val_index]\n",
    "                          \n",
    "                    else:\n",
    "                        y_train = y.loc[train_index]\n",
    "                        UNT = y_train.loc[y_train==0].sample(\n",
    "                            frac=0.6, random_state=bag*n_reapts+n_splits).index.values\n",
    "                        train_index = np.setdiff1d(train_index,UNT)\n",
    "                        \n",
    "                        # DOWNSAMPLE NOTE WORK\n",
    "                        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "                        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "                    yield X_train, X_val, y_train, y_val\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid kfold: Must be True\")\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self, n_estimators=100, device=\"cpu\", random_state=0):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.device = device\n",
    "        self.random_state = random_state\n",
    "        self.models = self._define_model()\n",
    "        self.models_name = list(self._define_model().keys())\n",
    "        self.len_models = len(self.models)\n",
    "        \n",
    "    def _define_model(self):\n",
    "        \n",
    "        xgb_params = {\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'learning_rate': 0.413327571405248,\n",
    "            'booster': 'gbtree',\n",
    "            'lambda': 0.0000263894617720096,\n",
    "            'alpha': 0.000463768723479341,\n",
    "            'subsample': 0.237467672874133,\n",
    "            'colsample_bytree': 0.618829300507829,\n",
    "            'max_depth': 5,\n",
    "            'min_child_weight': 9,\n",
    "            'eta': 2.09477807126539E-06,\n",
    "            'gamma': 0.000847289463422307,\n",
    "            'grow_policy': 'depthwise',\n",
    "            'n_jobs': -1,\n",
    "            'objective': 'binary:logistic',\n",
    "#             'eval_metric': 'logloss',\n",
    "            'verbosity': 0,\n",
    "            'tree_method':'gpu_hist',\n",
    "            'random_state': self.random_state,\n",
    "        }\n",
    "        xgb_params1 = {\n",
    "            'n_estimators': 900,\n",
    "            'learning_rate': 0.09641232707445854,\n",
    "            'booster': 'gbtree',\n",
    "            'lambda': 4.666002223704784,\n",
    "            'alpha': 3.708175990751336,\n",
    "            'subsample': 0.6100174145229473,\n",
    "            'colsample_bytree': 0.5506821152321051,\n",
    "            'max_depth': 7,\n",
    "            'min_child_weight': 3,\n",
    "            'eta': 1.740374368661041,\n",
    "            'gamma': 0.007427363662926455,\n",
    "            'grow_policy': 'depthwise',\n",
    "            'objective': 'binary:logistic',\n",
    "#             'eval_metric': 'logloss',\n",
    "            'verbosity': 0,\n",
    "            'random_state': self.random_state,\n",
    "            'scale_pos_weight': scale_pos_weight\n",
    "        }\n",
    "        \n",
    "        xgb_params2 = {\n",
    "            'n_estimators': 650,\n",
    "            'learning_rate': 0.012208383405206188,\n",
    "            'booster': 'gbtree',\n",
    "            'lambda': 0.009968756668882757,\n",
    "            'alpha': 0.02666266827121168,\n",
    "            'subsample': 0.7097814108897231,\n",
    "            'colsample_bytree': 0.7946945784285216,\n",
    "            'max_depth': 3,\n",
    "            'min_child_weight': 4,\n",
    "            'eta': 0.5480204506554545,\n",
    "            'gamma': 0.8788654128774149,\n",
    "            'scale_pos_weight': 4.71,\n",
    "            'objective': 'binary:logistic',\n",
    "#             'eval_metric': 'logloss',\n",
    "            'verbosity': 0,\n",
    "            'random_state': self.random_state,\n",
    "            'scale_pos_weight': scale_pos_weight\n",
    "        }\n",
    "        \n",
    "        xgb_params3 = {\n",
    "            'colsample_bytree': 0.5646751146007976,\n",
    "            'gamma': 7.788727238356553e-06,\n",
    "            'learning_rate': 0.1419865761603358,\n",
    "            'max_bin': 824,\n",
    "            'min_child_weight': 1,\n",
    "            'random_state': 811996,\n",
    "            'reg_alpha': 1.6259583347890365e-07,\n",
    "            'reg_lambda': 2.110691851528507e-08,\n",
    "            'subsample': 0.879020578464637,\n",
    "            'objective': 'binary:logistic',\n",
    "#             'eval_metric': 'logloss',\n",
    "            'max_depth': 3,\n",
    "            'n_jobs': -1,\n",
    "            'verbosity': 0,\n",
    "            'random_state': self.random_state,\n",
    "            'scale_pos_weight': scale_pos_weight\n",
    "        }\n",
    "        \n",
    "        xgb_params4 = {\n",
    "            'random_state': self.random_state,\n",
    "            'colsample_bytree': 0.4836462317215041,\n",
    "            'eta': 0.05976752607337169,\n",
    "            'gamma': 1,\n",
    "            'lambda': 0.2976432557733288,\n",
    "            'max_depth': 6,\n",
    "            'min_child_weight': 1,\n",
    "            'n_estimators': 550,\n",
    "            'objective': 'binary:logistic',\n",
    "            'scale_pos_weight': 4.260162886376033,\n",
    "            'subsample': 0.7119282378433924,\n",
    "        }\n",
    "        \n",
    "        xgb_params5 = {\n",
    "            'colsample_bytree': 0.8757972257439255,\n",
    "            'gamma': 0.11135738771999848,\n",
    "            'max_depth': 7,\n",
    "            'min_child_weight': 3,\n",
    "            'reg_alpha': 0.4833998914998038,\n",
    "            'reg_lambda': 0.006223568555619563,\n",
    "            'scale_pos_weight': 8,\n",
    "            'subsample': 0.7056434340275685,\n",
    "            'random_state': self.random_state\n",
    "        }\n",
    "        \n",
    "        xgb_params6 = {\n",
    "            'max_depth': 5, \n",
    "            'min_child_weight': 2.934487833919741,\n",
    "            'learning_rate': 0.11341944575807082, \n",
    "            'subsample': 0.9045063514419968,\n",
    "            'gamma': 0.4329153382843715,\n",
    "            'colsample_bytree': 0.38872702868412506,\n",
    "            'colsample_bylevel': 0.8321880031718571,\n",
    "            'colsample_bynode': 0.802355707802605,\n",
    "            'random_state': self.random_state\n",
    "       }\n",
    "        \n",
    "        xgb_params7 = { 'colsample_bylevel' : 0.6, 'colsample_bytree' : 1.0, \n",
    "                        'learning_rate' : 0.3,  'max_depth' : 4,\n",
    "                       'subsample' : 1.0,    'scale_pos_weight' : 5,\n",
    "                       'random_state': self.random_state}\n",
    "        \n",
    "        xgb_params8 = {\n",
    "            \"max_depth\": 2,\n",
    "            \"n_estimators\": 200,\n",
    "            \"learning_rate\": 0.4,\n",
    "            \"min_child_weight\": 0.1,\n",
    "            \"max_delta_step\": 0.35,\n",
    "            \"colsample_bytree\": 0.3,\n",
    "            \"colsample_bylevel\": 0.7,\n",
    "            \"gamma\": 1e-4,\n",
    "            \"reg_alpha\": 2e-3,\n",
    "            'random_state': self.random_state\n",
    "        } \n",
    "        if self.device == 'gpu':\n",
    "            xgb_params['tree_method'] = 'gpu_hist'\n",
    "            xgb_params['predictor'] = 'gpu_predictor'\n",
    "            \n",
    "            xgb_params1['tree_method'] = 'gpu_hist'\n",
    "            xgb_params1['predictor'] = 'gpu_predictor'\n",
    "            \n",
    "            xgb_params2['tree_method'] = 'gpu_hist'\n",
    "            xgb_params2['predictor'] = 'gpu_predictor'\n",
    "            \n",
    "            xgb_params3['tree_method'] = 'gpu_hist'\n",
    "            xgb_params3['predictor'] = 'gpu_predictor'\n",
    "            \n",
    "            xgb_params4['tree_method'] = 'gpu_hist'\n",
    "            xgb_params4['predictor'] = 'gpu_predictor'\n",
    "            \n",
    "            xgb_params5['tree_method'] = 'gpu_hist'\n",
    "            xgb_params5['predictor'] = 'gpu_predictor'\n",
    "            \n",
    "            xgb_params6['tree_method'] = 'gpu_hist'\n",
    "            xgb_params6['predictor'] = 'gpu_predictor'\n",
    "    \n",
    "            xgb_params7['tree_method'] = 'gpu_hist'\n",
    "            xgb_params7['predictor'] = 'gpu_predictor'\n",
    "            \n",
    "            xgb_params8['tree_method'] = 'gpu_hist'\n",
    "            xgb_params8['predictor'] = 'gpu_predictor'\n",
    "            \n",
    "        lgb_params = {\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'objective': 'binary',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'learning_rate': 0.005,\n",
    "            'num_leaves': 5,\n",
    "            'colsample_bytree': 0.50,\n",
    "            'subsample': 0.80,\n",
    "            'reg_alpha': 2, \n",
    "            'reg_lambda': 4,\n",
    "            'n_jobs': -1,\n",
    "            'is_unbalance':True,\n",
    "            'device': self.device,\n",
    "            'random_state': self.random_state\n",
    "        }\n",
    "\n",
    "        \n",
    "        lgb1_params = {\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'learning_rate': 0.190197487721534,\n",
    "            'reg_alpha': 0.00749112221417973,\n",
    "            'reg_lambda': 0.000548118227209224,\n",
    "            'num_leaves': 17,\n",
    "            'colsample_bytree': 0.547257860506146,\n",
    "            'subsample': 0.592628085686409,\n",
    "            'subsample_freq': 2,\n",
    "            'min_child_samples': 64,\n",
    "            'objective': 'binary',\n",
    "            #'metric': 'binary_error',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'is_unbalance':True,\n",
    "            'device': self.device,\n",
    "            'random_state': self.random_state\n",
    "        } \n",
    "        \n",
    "        lgb2_params = {\n",
    "            'n_estimators': self.n_estimators,\n",
    "            'learning_rate': 0.181326407627473,\n",
    "            'reg_alpha': 0.000030864084239014,\n",
    "            'reg_lambda': 0.0000395714763869486,\n",
    "            'num_leaves': 122,\n",
    "            'colsample_bytree': 0.75076596295323,\n",
    "            'subsample': 0.6303245788342,\n",
    "            'subsample_freq': 3,\n",
    "            'min_child_samples': 72,\n",
    "            'objective': 'binary',\n",
    "            #'metric': 'binary_error',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'is_unbalance':True,\n",
    "            'device': self.device,\n",
    "            'random_state': self.random_state\n",
    "        }\n",
    "        \n",
    "        lgb3_params = {\n",
    "            \"max_depth\": 4,\n",
    "            \"num_leaves\": 9,\n",
    "            \"min_child_samples\": 17,\n",
    "            \"n_estimators\": 200,\n",
    "            \"learning_rate\": 0.15,\n",
    "            \"colsample_bytree\": 0.4,\n",
    "            \"min_split_gain\": 1e-4,\n",
    "            \"reg_alpha\": 1e-2,\n",
    "            \"reg_lambda\": 5e-3,\n",
    "            'device': self.device,\n",
    "            'random_state': self.random_state\n",
    "        }\n",
    "        \n",
    "        lgb4_params = {\n",
    "            \"max_depth\": 4,\n",
    "            \"num_leaves\": 9,\n",
    "            \"min_child_samples\": 20,\n",
    "            \"n_estimators\": 200,\n",
    "            \"learning_rate\": 0.15,\n",
    "            \"colsample_bytree\": 0.4,\n",
    "            \"reg_alpha\": 1e-2,\n",
    "            \"min_split_gain\": 1e-4\n",
    "            , 'device': self.device\n",
    "            ,'random_state': self.random_state\n",
    "        }\n",
    "        \n",
    "        lgb5_params = {\"boosting_type\": 'goss'\n",
    "           , \"learning_rate\": 0.06733232950390658\n",
    "           , \"n_estimators\": 50000\n",
    "           , \"subsample\": 0.6970532011679706\n",
    "           , \"colsample_bytree\": 0.6055755840633003\n",
    "           , \"class_weight\": 'balanced'\n",
    "#            , \"metric\": 'none'\n",
    "           , \"is_unbalance\": True\n",
    "           , \"max_depth\": 8\n",
    "           , 'device': self.device\n",
    "           ,'random_state': self.random_state}\n",
    "        \n",
    "        cat_params = {\n",
    "            'iterations': self.n_estimators,\n",
    "            'colsample_bylevel': 0.0513276895988184,\n",
    "            'depth': 2,\n",
    "            'learning_rate': 0.0256579773375401,\n",
    "            'l2_leaf_reg': 8.22319805476255,\n",
    "            'random_strength': 0.11327724457066,\n",
    "            'od_type': \"Iter\", \n",
    "            'od_wait': 72,\n",
    "            'bootstrap_type': \"Bayesian\",\n",
    "            'grow_policy': 'SymmetricTree',\n",
    "            'bagging_temperature': 9.58737431845122,\n",
    "            'auto_class_weights': 'Balanced',\n",
    "#             'task_type': self.device.upper(),\n",
    "            'random_state': self.random_state\n",
    "        }\n",
    "\n",
    "        \n",
    "        cat_params1 = {\n",
    "            \"depth\":4,\n",
    "            \"l2_leaf_reg\" : 50,\n",
    "            \"learning_rate\" : 0.3,\n",
    "            \"objective\": \"Logloss\", \n",
    "            \"logging_level\":\"Silent\", \n",
    "            \"iterations\" : 1000,\n",
    "            \"auto_class_weights\" : \"Balanced\",\n",
    "            \"one_hot_max_size\":10,\n",
    "            'random_state': self.random_state,  }\n",
    "        \n",
    "        cat_params2 = {\n",
    "                \"objective\": \"Logloss\",\n",
    "                'bagging_temperature' : 1.0, \n",
    "                'boosting_type' : 'Plain', \n",
    "                'depth' : 5,\n",
    "                'grow_policy' : 'Depthwise',\n",
    "                \"iterations\" : 100,\n",
    "                'l2_leaf_reg' : 2, \n",
    "                'learning_rate' : 0.07, \n",
    "                'max_bin' : 65535, 'max_leaves' : 31,\n",
    "                'min_data_in_leaf' : 3,\n",
    "                'random_strength' : 5.0, \n",
    "                'rsm' : 0.5,\n",
    "                'sampling_frequency' : 'PerTreeLevel',\n",
    "                'scale_pos_weight' : 5.0,\n",
    "                'thread_count' : -1,\n",
    "#                 'task_type': self.device.upper(),\n",
    "                'random_state': self.random_state\n",
    "        }\n",
    "        \n",
    "        cat_params3 = {\n",
    "#             \"objective\": \"Logloss\",\n",
    "            'learning_rate': 0.05, \n",
    "            \"iterations\" : 250,\n",
    "            'depth': 3, # \n",
    "            'colsample_bylevel': 0.50,\n",
    "            'subsample': 0.80,\n",
    "            'l2_leaf_reg': 3, # 3, 30\n",
    "            'auto_class_weights': 'Balanced',\n",
    "#             'task_type': self.device.upper(),\n",
    "            'random_state': self.random_state\n",
    "        }\n",
    "        \n",
    "        cat_params4 = {\n",
    "            \"learning_rate\": 0.003,\n",
    "            \"depth\": 4,\n",
    "            \"iterations\" : 1000,\n",
    "            'auto_class_weights':'Balanced',\n",
    "            'loss_function':'MultiClass',\n",
    "            'eval_metric':'MultiClass:use_weights=False',\n",
    "#             'task_type': self.device.upper(),\n",
    "            'random_state': self.random_state\n",
    "    }\n",
    "        \n",
    "            \n",
    "        models = {\n",
    "            'xgb' : xgb.XGBClassifier(**xgb_params),\n",
    "            'xgb1': xgb.XGBClassifier(**xgb_params1),\n",
    "            'xgb2': xgb.XGBClassifier(**xgb_params2),\n",
    "            'xgb3': xgb.XGBClassifier(**xgb_params3),\n",
    "            'xgb4': xgb.XGBClassifier(**xgb_params4),\n",
    "            'xgb5': xgb.XGBClassifier(**xgb_params5),\n",
    "            'xgb6': xgb.XGBClassifier(**xgb_params6),\n",
    "            'xgb7': xgb.XGBClassifier(**xgb_params7),\n",
    "            'xgb8': xgb.XGBClassifier(**xgb_params8),\n",
    "            \n",
    "            'lgb' : lgb.LGBMClassifier(**lgb_params),\n",
    "            'lgb1': lgb.LGBMClassifier(**lgb1_params),\n",
    "            'lgb2': lgb.LGBMClassifier(**lgb2_params),\n",
    "            'lgb3': lgb.LGBMClassifier(**lgb3_params),\n",
    "            'lgb4': lgb.LGBMClassifier(**lgb4_params),\n",
    "            'lgb5': lgb.LGBMClassifier(**lgb5_params),\n",
    "#             'cat': CatBoostClassifier(**cat_params),\n",
    "#             'cat1': CatBoostClassifier(**cat_params1),\n",
    "#             'cat2': CatBoostClassifier(**cat_params2),\n",
    "#             'cat3': CatBoostClassifier(**cat_params3),\n",
    "#             'cat4': CatBoostClassifier(**cat_params4),\n",
    "            \n",
    "        }\n",
    "        \n",
    "        return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d06c70c",
   "metadata": {
    "papermill": {
     "duration": 0.013915,
     "end_time": "2023-08-07T08:08:49.298301",
     "exception": false,
     "start_time": "2023-08-07T08:08:49.284386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d432ddb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T08:08:49.327754Z",
     "iopub.status.busy": "2023-08-07T08:08:49.326836Z",
     "iopub.status.idle": "2023-08-07T08:08:49.335841Z",
     "shell.execute_reply": "2023-08-07T08:08:49.334972Z"
    },
    "papermill": {
     "duration": 0.025677,
     "end_time": "2023-08-07T08:08:49.337838",
     "exception": false,
     "start_time": "2023-08-07T08:08:49.312161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_log_loss_weight(y_true):\n",
    "    nc = np.bincount(y_true)\n",
    "    w0, w1 = 1/(nc[0]/y_true.shape[0]), 1/(nc[1]/y_true.shape[0])\n",
    "    return w0, w1\n",
    "\n",
    "# https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/415000\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import log_loss\n",
    "# def balanced_log_loss(y_true, y_pred):\n",
    "#     sw = compute_sample_weight(class_weight='balanced', y=y_true)\n",
    "#     balanced_log_loss = log_loss(y_true, y_pred, eps=1e-15, sample_weight=sw)\n",
    "#     return balanced_log_loss\n",
    "\n",
    "\n",
    "def balanced_log_loss(y_true, y_pred):\n",
    "    y_pred = np.stack([1-y_pred,y_pred]).T\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1-1e-15)\n",
    "    y_pred / np.sum(y_pred, axis=1)[:, None]\n",
    "    nc = np.bincount(y_true)\n",
    "    \n",
    "    logloss = (-1/nc[0]*(np.sum(np.where(y_true==0,1,0) * np.log(y_pred[:,0]))) - 1/nc[1]*(np.sum(np.where(y_true!=0,1,0) * np.log(y_pred[:,1])))) / 2\n",
    "    return logloss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3901dffe",
   "metadata": {
    "papermill": {
     "duration": 0.013434,
     "end_time": "2023-08-07T08:08:49.364825",
     "exception": false,
     "start_time": "2023-08-07T08:08:49.351391",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Optimizer (--> Optimize balanced_log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b80f9c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T08:08:49.393569Z",
     "iopub.status.busy": "2023-08-07T08:08:49.392731Z",
     "iopub.status.idle": "2023-08-07T08:08:49.404141Z",
     "shell.execute_reply": "2023-08-07T08:08:49.403292Z"
    },
    "papermill": {
     "duration": 0.028077,
     "end_time": "2023-08-07T08:08:49.406457",
     "exception": false,
     "start_time": "2023-08-07T08:08:49.378380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OptunaWeights:\n",
    "    def __init__(self, random_state, n_trials = 3000):\n",
    "        self.study = None\n",
    "        self.weights = None\n",
    "        self.random_state = random_state\n",
    "        self.n_trials = n_trials\n",
    "\n",
    "    def _objective(self, trial, y_true, y_preds):\n",
    "        # Define the weights for the predictions from each model\n",
    "        weights = [trial.suggest_float(f\"weight{n}\", 1e-15, 1) for n in range(len(y_preds))]\n",
    "\n",
    "#         weights = [trial.suggest_float(f\"weight{n}\", 0.0, 1.0, step=0.1) for n in range(len(y_preds))]\n",
    "        # Calculate the weighted prediction\n",
    "        weighted_pred = np.average(np.array(y_preds).T, axis=1, weights=weights)\n",
    "\n",
    "        # Calculate the score for the weighted prediction\n",
    "        # score = log_loss(y_true, weighted_pred)\n",
    "        score = balanced_log_loss(y_true, weighted_pred)\n",
    "        return score\n",
    "\n",
    "    def fit(self, y_true, y_preds):\n",
    "        optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "        sampler = optuna.samplers.CmaEsSampler(seed=self.random_state)\n",
    "        pruner = optuna.pruners.HyperbandPruner()\n",
    "        self.study = optuna.create_study(sampler=sampler, pruner=pruner, study_name=\"OptunaWeights\", direction='minimize')\n",
    "        objective_partial = partial(self._objective, y_true=y_true, y_preds=y_preds)\n",
    "        self.study.optimize(objective_partial, n_trials=self.n_trials)\n",
    "        self.weights = [self.study.best_params[f\"weight{n}\"] for n in range(len(y_preds))]\n",
    "\n",
    "    def predict(self, y_preds):\n",
    "        assert self.weights is not None, 'OptunaWeights error, must be fitted before predict'\n",
    "        weighted_pred = np.average(np.array(y_preds).T, axis=1, weights=self.weights)\n",
    "        return weighted_pred\n",
    "\n",
    "    def fit_predict(self, y_true, y_preds):\n",
    "        self.fit(y_true, y_preds)\n",
    "        return self.predict(y_preds)\n",
    "    \n",
    "    def weights(self):\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb2dcdd",
   "metadata": {
    "papermill": {
     "duration": 0.013432,
     "end_time": "2023-08-07T08:08:49.433452",
     "exception": false,
     "start_time": "2023-08-07T08:08:49.420020",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59f2f995",
   "metadata": {
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2023-08-07T08:08:49.462522Z",
     "iopub.status.busy": "2023-08-07T08:08:49.462253Z",
     "iopub.status.idle": "2023-08-07T13:31:59.293328Z",
     "shell.execute_reply": "2023-08-07T13:31:59.292300Z"
    },
    "papermill": {
     "duration": 19390.109245,
     "end_time": "2023-08-07T13:31:59.556100",
     "exception": false,
     "start_time": "2023-08-07T08:08:49.446855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### Bag/SEED no. 1\n",
      "# FOLD 1  (xgb 0.401) (xgb1 0.286) (xgb2 0.301) (xgb3 0.353) (xgb4 0.293) (xgb5 0.342) (xgb6 0.334) (xgb7 0.370) (xgb8 0.342) (lgb 0.296) (lgb1 0.303) (lgb2 0.283) (lgb3 0.202) (lgb4 0.193) (lgb5 0.306) \n",
      "==> Ensemble Score 0.18656\n",
      "# FOLD 2  (xgb 0.273) (xgb1 0.172) (xgb2 0.167) (xgb3 0.116) (xgb4 0.115) (xgb5 0.176) (xgb6 0.169) (xgb7 0.070) (xgb8 0.124) (lgb 0.136) (lgb1 0.204) (lgb2 0.212) (lgb3 0.136) (lgb4 0.152) (lgb5 0.178) \n",
      "==> Ensemble Score 0.07373\n",
      "# FOLD 3  (xgb 0.242) (xgb1 0.165) (xgb2 0.189) (xgb3 0.240) (xgb4 0.177) (xgb5 0.114) (xgb6 0.167) (xgb7 0.262) (xgb8 0.138) (lgb 0.182) (lgb1 0.117) (lgb2 0.126) (lgb3 0.211) (lgb4 0.192) (lgb5 0.063) \n",
      "==> Ensemble Score 0.08516\n",
      "# FOLD 4  (xgb 0.268) (xgb1 0.169) (xgb2 0.160) (xgb3 0.130) (xgb4 0.139) (xgb5 0.140) (xgb6 0.179) (xgb7 0.132) (xgb8 0.253) (lgb 0.165) (lgb1 0.243) (lgb2 0.249) (lgb3 0.211) (lgb4 0.197) (lgb5 0.160) \n",
      "==> Ensemble Score 0.12184\n",
      "# FOLD 5  (xgb 0.437) (xgb1 0.201) (xgb2 0.200) (xgb3 0.161) (xgb4 0.190) (xgb5 0.214) (xgb6 0.204) (xgb7 0.169) (xgb8 0.190) (lgb 0.195) (lgb1 0.333) (lgb2 0.345) (lgb3 0.153) (lgb4 0.161) (lgb5 0.226) \n",
      "==> Ensemble Score 0.14728\n",
      "# FOLD 6  (xgb 0.394) (xgb1 0.230) (xgb2 0.228) (xgb3 0.154) (xgb4 0.216) (xgb5 0.296) (xgb6 0.240) (xgb7 0.225) (xgb8 0.175) (lgb 0.216) (lgb1 0.336) (lgb2 0.352) (lgb3 0.152) (lgb4 0.184) (lgb5 0.267) \n",
      "==> Ensemble Score 0.14996\n",
      "# FOLD 7  (xgb 0.289) (xgb1 0.169) (xgb2 0.205) (xgb3 0.158) (xgb4 0.202) (xgb5 0.226) (xgb6 0.168) (xgb7 0.185) (xgb8 0.156) (lgb 0.184) (lgb1 0.162) (lgb2 0.187) (lgb3 0.205) (lgb4 0.175) (lgb5 0.164) \n",
      "==> Ensemble Score 0.13879\n",
      "# FOLD 8  (xgb 0.301) (xgb1 0.369) (xgb2 0.371) (xgb3 0.368) (xgb4 0.356) (xgb5 0.359) (xgb6 0.413) (xgb7 0.350) (xgb8 0.394) (lgb 0.331) (lgb1 0.332) (lgb2 0.327) (lgb3 0.356) (lgb4 0.414) (lgb5 0.372) \n",
      "==> Ensemble Score 0.28509\n",
      "# FOLD 9  (xgb 0.211) (xgb1 0.101) (xgb2 0.098) (xgb3 0.117) (xgb4 0.077) (xgb5 0.077) (xgb6 0.082) (xgb7 0.085) (xgb8 0.083) (lgb 0.093) (lgb1 0.165) (lgb2 0.193) (lgb3 0.057) (lgb4 0.068) (lgb5 0.079) \n",
      "==> Ensemble Score 0.06573\n",
      "# FOLD 10  (xgb 0.527) (xgb1 0.382) (xgb2 0.394) (xgb3 0.498) (xgb4 0.374) (xgb5 0.449) (xgb6 0.463) (xgb7 0.536) (xgb8 0.460) (lgb 0.381) (lgb1 0.339) (lgb2 0.337) (lgb3 0.433) (lgb4 0.423) (lgb5 0.332) \n",
      "==> Ensemble Score 0.30498\n",
      "\n",
      "#### Bag/SEED no. 2\n",
      "# FOLD 1  (xgb 0.357) (xgb1 0.372) (xgb2 0.379) (xgb3 0.403) (xgb4 0.362) (xgb5 0.389) (xgb6 0.460) (xgb7 0.374) (xgb8 0.285) (lgb 0.404) (lgb1 0.258) (lgb2 0.263) (lgb3 0.399) (lgb4 0.352) (lgb5 0.357) \n",
      "==> Ensemble Score 0.23665\n",
      "# FOLD 2  (xgb 0.309) (xgb1 0.155) (xgb2 0.150) (xgb3 0.148) (xgb4 0.143) (xgb5 0.137) (xgb6 0.187) (xgb7 0.109) (xgb8 0.177) (lgb 0.165) (lgb1 0.219) (lgb2 0.233) (lgb3 0.113) (lgb4 0.112) (lgb5 0.146) \n",
      "==> Ensemble Score 0.10683\n",
      "# FOLD 3  (xgb 0.256) (xgb1 0.201) (xgb2 0.223) (xgb3 0.218) (xgb4 0.206) (xgb5 0.175) (xgb6 0.251) (xgb7 0.484) (xgb8 0.220) (lgb 0.243) (lgb1 0.188) (lgb2 0.218) (lgb3 0.270) (lgb4 0.266) (lgb5 0.233) \n",
      "==> Ensemble Score 0.16531\n",
      "# FOLD 4  (xgb 0.533) (xgb1 0.408) (xgb2 0.360) (xgb3 0.363) (xgb4 0.395) (xgb5 0.345) (xgb6 0.418) (xgb7 0.431) (xgb8 0.355) (lgb 0.378) (lgb1 0.468) (lgb2 0.474) (lgb3 0.409) (lgb4 0.313) (lgb5 0.397) \n",
      "==> Ensemble Score 0.31558\n",
      "# FOLD 5  (xgb 0.318) (xgb1 0.243) (xgb2 0.242) (xgb3 0.225) (xgb4 0.241) (xgb5 0.186) (xgb6 0.251) (xgb7 0.234) (xgb8 0.246) (lgb 0.239) (lgb1 0.284) (lgb2 0.317) (lgb3 0.248) (lgb4 0.251) (lgb5 0.220) \n",
      "==> Ensemble Score 0.19574\n",
      "# FOLD 6  (xgb 0.276) (xgb1 0.231) (xgb2 0.242) (xgb3 0.250) (xgb4 0.298) (xgb5 0.180) (xgb6 0.255) (xgb7 0.278) (xgb8 0.341) (lgb 0.241) (lgb1 0.276) (lgb2 0.352) (lgb3 0.305) (lgb4 0.299) (lgb5 0.218) \n",
      "==> Ensemble Score 0.17589\n",
      "# FOLD 7  (xgb 0.383) (xgb1 0.309) (xgb2 0.280) (xgb3 0.342) (xgb4 0.303) (xgb5 0.395) (xgb6 0.410) (xgb7 0.412) (xgb8 0.322) (lgb 0.290) (lgb1 0.301) (lgb2 0.343) (lgb3 0.309) (lgb4 0.306) (lgb5 0.296) \n",
      "==> Ensemble Score 0.27785\n",
      "# FOLD 8  (xgb 0.159) (xgb1 0.142) (xgb2 0.153) (xgb3 0.214) (xgb4 0.139) (xgb5 0.139) (xgb6 0.152) (xgb7 0.157) (xgb8 0.134) (lgb 0.150) (lgb1 0.146) (lgb2 0.150) (lgb3 0.163) (lgb4 0.156) (lgb5 0.140) \n",
      "==> Ensemble Score 0.11123\n",
      "# FOLD 9  (xgb 0.287) (xgb1 0.156) (xgb2 0.173) (xgb3 0.183) (xgb4 0.144) (xgb5 0.136) (xgb6 0.153) (xgb7 0.137) (xgb8 0.095) (lgb 0.147) (lgb1 0.160) (lgb2 0.179) (lgb3 0.118) (lgb4 0.074) (lgb5 0.134) \n",
      "==> Ensemble Score 0.08163\n",
      "# FOLD 10  (xgb 0.509) (xgb1 0.354) (xgb2 0.392) (xgb3 0.364) (xgb4 0.333) (xgb5 0.360) (xgb6 0.365) (xgb7 0.405) (xgb8 0.285) (lgb 0.379) (lgb1 0.369) (lgb2 0.372) (lgb3 0.375) (lgb4 0.308) (lgb5 0.305) \n",
      "==> Ensemble Score 0.28091\n",
      "\n",
      "#### Bag/SEED no. 3\n",
      "# FOLD 1  (xgb 0.390) (xgb1 0.251) (xgb2 0.269) (xgb3 0.262) (xgb4 0.254) (xgb5 0.305) (xgb6 0.247) (xgb7 0.245) (xgb8 0.321) (lgb 0.276) (lgb1 0.303) (lgb2 0.380) (lgb3 0.210) (lgb4 0.250) (lgb5 0.305) \n",
      "==> Ensemble Score 0.19867\n",
      "# FOLD 2  (xgb 0.544) (xgb1 0.353) (xgb2 0.345) (xgb3 0.316) (xgb4 0.384) (xgb5 0.296) (xgb6 0.387) (xgb7 0.370) (xgb8 0.366) (lgb 0.366) (lgb1 0.350) (lgb2 0.383) (lgb3 0.377) (lgb4 0.397) (lgb5 0.339) \n",
      "==> Ensemble Score 0.29619\n",
      "# FOLD 3  (xgb 0.320) (xgb1 0.205) (xgb2 0.200) (xgb3 0.206) (xgb4 0.214) (xgb5 0.149) (xgb6 0.188) (xgb7 0.203) (xgb8 0.156) (lgb 0.214) (lgb1 0.327) (lgb2 0.329) (lgb3 0.147) (lgb4 0.186) (lgb5 0.146) \n",
      "==> Ensemble Score 0.12178\n",
      "# FOLD 4  (xgb 0.304) (xgb1 0.323) (xgb2 0.279) (xgb3 0.251) (xgb4 0.294) (xgb5 0.303) (xgb6 0.292) (xgb7 0.247) (xgb8 0.282) (lgb 0.270) (lgb1 0.377) (lgb2 0.362) (lgb3 0.302) (lgb4 0.298) (lgb5 0.268) \n",
      "==> Ensemble Score 0.22959\n",
      "# FOLD 5  (xgb 0.287) (xgb1 0.177) (xgb2 0.178) (xgb3 0.167) (xgb4 0.131) (xgb5 0.158) (xgb6 0.192) (xgb7 0.189) (xgb8 0.211) (lgb 0.189) (lgb1 0.252) (lgb2 0.281) (lgb3 0.160) (lgb4 0.171) (lgb5 0.155) \n",
      "==> Ensemble Score 0.13061\n",
      "# FOLD 6  (xgb 0.371) (xgb1 0.207) (xgb2 0.206) (xgb3 0.140) (xgb4 0.154) (xgb5 0.296) (xgb6 0.206) (xgb7 0.282) (xgb8 0.154) (lgb 0.188) (lgb1 0.179) (lgb2 0.180) (lgb3 0.166) (lgb4 0.167) (lgb5 0.160) \n",
      "==> Ensemble Score 0.13874\n",
      "# FOLD 7  (xgb 0.367) (xgb1 0.154) (xgb2 0.170) (xgb3 0.135) (xgb4 0.156) (xgb5 0.202) (xgb6 0.168) (xgb7 0.157) (xgb8 0.107) (lgb 0.150) (lgb1 0.138) (lgb2 0.213) (lgb3 0.150) (lgb4 0.077) (lgb5 0.144) \n",
      "==> Ensemble Score 0.09697\n",
      "# FOLD 8  (xgb 0.261) (xgb1 0.230) (xgb2 0.248) (xgb3 0.263) (xgb4 0.231) (xgb5 0.364) (xgb6 0.188) (xgb7 0.236) (xgb8 0.197) (lgb 0.230) (lgb1 0.204) (lgb2 0.216) (lgb3 0.256) (lgb4 0.234) (lgb5 0.181) \n",
      "==> Ensemble Score 0.16961\n",
      "# FOLD 9  (xgb 0.397) (xgb1 0.180) (xgb2 0.184) (xgb3 0.136) (xgb4 0.143) (xgb5 0.204) (xgb6 0.181) (xgb7 0.272) (xgb8 0.203) (lgb 0.203) (lgb1 0.341) (lgb2 0.357) (lgb3 0.180) (lgb4 0.127) (lgb5 0.152) \n",
      "==> Ensemble Score 0.13234\n",
      "# FOLD 10  (xgb 0.445) (xgb1 0.161) (xgb2 0.217) (xgb3 0.173) (xgb4 0.214) (xgb5 0.293) (xgb6 0.321) (xgb7 0.285) (xgb8 0.243) (lgb 0.196) (lgb1 0.276) (lgb2 0.305) (lgb3 0.198) (lgb4 0.225) (lgb5 0.181) \n",
      "==> Ensemble Score 0.15959\n",
      "\n",
      "#### Bag/SEED no. 4\n",
      "# FOLD 1  (xgb 0.364) (xgb1 0.219) (xgb2 0.222) (xgb3 0.176) (xgb4 0.235) (xgb5 0.234) (xgb6 0.281) (xgb7 0.232) (xgb8 0.236) (lgb 0.261) (lgb1 0.307) (lgb2 0.304) (lgb3 0.184) (lgb4 0.156) (lgb5 0.218) \n",
      "==> Ensemble Score 0.16708\n",
      "# FOLD 2  (xgb 0.269) (xgb1 0.226) (xgb2 0.247) (xgb3 0.211) (xgb4 0.265) (xgb5 0.201) (xgb6 0.249) (xgb7 0.230) (xgb8 0.230) (lgb 0.225) (lgb1 0.247) (lgb2 0.267) (lgb3 0.301) (lgb4 0.198) (lgb5 0.208) \n",
      "==> Ensemble Score 0.17809\n",
      "# FOLD 3  (xgb 0.262) (xgb1 0.118) (xgb2 0.129) (xgb3 0.109) (xgb4 0.085) (xgb5 0.145) (xgb6 0.134) (xgb7 0.125) (xgb8 0.071) (lgb 0.128) (lgb1 0.170) (lgb2 0.214) (lgb3 0.092) (lgb4 0.077) (lgb5 0.121) \n",
      "==> Ensemble Score 0.07504\n",
      "# FOLD 4  (xgb 0.612) (xgb1 0.452) (xgb2 0.432) (xgb3 0.392) (xgb4 0.462) (xgb5 0.435) (xgb6 0.372) (xgb7 0.568) (xgb8 0.404) (lgb 0.451) (lgb1 0.503) (lgb2 0.521) (lgb3 0.494) (lgb4 0.475) (lgb5 0.454) \n",
      "==> Ensemble Score 0.37837\n",
      "# FOLD 5  (xgb 0.390) (xgb1 0.167) (xgb2 0.190) (xgb3 0.178) (xgb4 0.143) (xgb5 0.162) (xgb6 0.269) (xgb7 0.177) (xgb8 0.195) (lgb 0.253) (lgb1 0.136) (lgb2 0.154) (lgb3 0.228) (lgb4 0.311) (lgb5 0.151) \n",
      "==> Ensemble Score 0.13703\n",
      "# FOLD 6  (xgb 0.315) (xgb1 0.159) (xgb2 0.157) (xgb3 0.155) (xgb4 0.149) (xgb5 0.108) (xgb6 0.173) (xgb7 0.173) (xgb8 0.148) (lgb 0.157) (lgb1 0.229) (lgb2 0.210) (lgb3 0.102) (lgb4 0.139) (lgb5 0.153) \n",
      "==> Ensemble Score 0.10677\n",
      "# FOLD 7  (xgb 0.387) (xgb1 0.184) (xgb2 0.181) (xgb3 0.176) (xgb4 0.185) (xgb5 0.125) (xgb6 0.186) (xgb7 0.231) (xgb8 0.181) (lgb 0.192) (lgb1 0.313) (lgb2 0.306) (lgb3 0.172) (lgb4 0.147) (lgb5 0.158) \n",
      "==> Ensemble Score 0.13729\n",
      "# FOLD 8  (xgb 0.260) (xgb1 0.237) (xgb2 0.280) (xgb3 0.271) (xgb4 0.249) (xgb5 0.310) (xgb6 0.262) (xgb7 0.403) (xgb8 0.161) (lgb 0.204) (lgb1 0.171) (lgb2 0.145) (lgb3 0.205) (lgb4 0.223) (lgb5 0.122) \n",
      "==> Ensemble Score 0.12234\n",
      "# FOLD 9  (xgb 0.412) (xgb1 0.197) (xgb2 0.265) (xgb3 0.279) (xgb4 0.209) (xgb5 0.178) (xgb6 0.249) (xgb7 0.235) (xgb8 0.270) (lgb 0.242) (lgb1 0.233) (lgb2 0.210) (lgb3 0.283) (lgb4 0.256) (lgb5 0.176) \n",
      "==> Ensemble Score 0.15813\n",
      "# FOLD 10  (xgb 0.368) (xgb1 0.207) (xgb2 0.230) (xgb3 0.260) (xgb4 0.224) (xgb5 0.206) (xgb6 0.208) (xgb7 0.413) (xgb8 0.183) (lgb 0.227) (lgb1 0.112) (lgb2 0.113) (lgb3 0.214) (lgb4 0.193) (lgb5 0.197) \n",
      "==> Ensemble Score 0.11067\n",
      "\n",
      "#### Bag/SEED no. 5\n",
      "# FOLD 1  (xgb 0.401) (xgb1 0.187) (xgb2 0.193) (xgb3 0.191) (xgb4 0.200) (xgb5 0.234) (xgb6 0.274) (xgb7 0.212) (xgb8 0.225) (lgb 0.238) (lgb1 0.216) (lgb2 0.223) (lgb3 0.176) (lgb4 0.223) (lgb5 0.185) \n",
      "==> Ensemble Score 0.16311\n",
      "# FOLD 2  (xgb 0.643) (xgb1 0.421) (xgb2 0.459) (xgb3 0.458) (xgb4 0.492) (xgb5 0.490) (xgb6 0.603) (xgb7 0.494) (xgb8 0.464) (lgb 0.492) (lgb1 0.465) (lgb2 0.516) (lgb3 0.494) (lgb4 0.500) (lgb5 0.444) \n",
      "==> Ensemble Score 0.40799\n",
      "# FOLD 3  (xgb 0.294) (xgb1 0.139) (xgb2 0.153) (xgb3 0.123) (xgb4 0.123) (xgb5 0.121) (xgb6 0.166) (xgb7 0.108) (xgb8 0.146) (lgb 0.143) (lgb1 0.216) (lgb2 0.247) (lgb3 0.131) (lgb4 0.113) (lgb5 0.099) \n",
      "==> Ensemble Score 0.08553\n",
      "# FOLD 4  (xgb 0.349) (xgb1 0.240) (xgb2 0.220) (xgb3 0.206) (xgb4 0.215) (xgb5 0.187) (xgb6 0.218) (xgb7 0.227) (xgb8 0.225) (lgb 0.184) (lgb1 0.234) (lgb2 0.266) (lgb3 0.147) (lgb4 0.146) (lgb5 0.149) \n",
      "==> Ensemble Score 0.13985\n",
      "# FOLD 5  (xgb 0.405) (xgb1 0.224) (xgb2 0.217) (xgb3 0.197) (xgb4 0.197) (xgb5 0.218) (xgb6 0.172) (xgb7 0.173) (xgb8 0.163) (lgb 0.184) (lgb1 0.295) (lgb2 0.320) (lgb3 0.127) (lgb4 0.120) (lgb5 0.225) \n",
      "==> Ensemble Score 0.12297\n",
      "# FOLD 6  (xgb 0.268) (xgb1 0.352) (xgb2 0.386) (xgb3 0.363) (xgb4 0.329) (xgb5 0.386) (xgb6 0.279) (xgb7 0.383) (xgb8 0.296) (lgb 0.353) (lgb1 0.306) (lgb2 0.336) (lgb3 0.324) (lgb4 0.297) (lgb5 0.343) \n",
      "==> Ensemble Score 0.24749\n",
      "# FOLD 7  (xgb 0.352) (xgb1 0.159) (xgb2 0.148) (xgb3 0.083) (xgb4 0.130) (xgb5 0.133) (xgb6 0.160) (xgb7 0.123) (xgb8 0.152) (lgb 0.152) (lgb1 0.251) (lgb2 0.300) (lgb3 0.102) (lgb4 0.129) (lgb5 0.133) \n",
      "==> Ensemble Score 0.08929\n",
      "# FOLD 8  (xgb 0.289) (xgb1 0.124) (xgb2 0.173) (xgb3 0.146) (xgb4 0.120) (xgb5 0.204) (xgb6 0.188) (xgb7 0.073) (xgb8 0.094) (lgb 0.113) (lgb1 0.160) (lgb2 0.179) (lgb3 0.100) (lgb4 0.054) (lgb5 0.056) \n",
      "==> Ensemble Score 0.05585\n",
      "# FOLD 9  (xgb 0.444) (xgb1 0.213) (xgb2 0.230) (xgb3 0.260) (xgb4 0.247) (xgb5 0.221) (xgb6 0.292) (xgb7 0.231) (xgb8 0.228) (lgb 0.257) (lgb1 0.249) (lgb2 0.282) (lgb3 0.231) (lgb4 0.248) (lgb5 0.251) \n",
      "==> Ensemble Score 0.19882\n",
      "# FOLD 10  (xgb 0.269) (xgb1 0.174) (xgb2 0.170) (xgb3 0.103) (xgb4 0.141) (xgb5 0.184) (xgb6 0.175) (xgb7 0.114) (xgb8 0.211) (lgb 0.178) (lgb1 0.256) (lgb2 0.277) (lgb3 0.078) (lgb4 0.094) (lgb5 0.200) \n",
      "==> Ensemble Score 0.09224\n",
      "\n",
      "#### Bag/SEED no. 6\n",
      "# FOLD 1  (xgb 0.388) (xgb1 0.174) (xgb2 0.179) (xgb3 0.158) (xgb4 0.195) (xgb5 0.194) (xgb6 0.235) (xgb7 0.195) (xgb8 0.292) (lgb 0.202) (lgb1 0.219) (lgb2 0.215) (lgb3 0.261) (lgb4 0.256) (lgb5 0.173) \n",
      "==> Ensemble Score 0.16502\n",
      "# FOLD 2  (xgb 0.261) (xgb1 0.169) (xgb2 0.195) (xgb3 0.194) (xgb4 0.139) (xgb5 0.175) (xgb6 0.166) (xgb7 0.195) (xgb8 0.187) (lgb 0.159) (lgb1 0.204) (lgb2 0.251) (lgb3 0.106) (lgb4 0.132) (lgb5 0.150) \n",
      "==> Ensemble Score 0.11658\n",
      "# FOLD 3  (xgb 0.393) (xgb1 0.296) (xgb2 0.295) (xgb3 0.267) (xgb4 0.286) (xgb5 0.359) (xgb6 0.251) (xgb7 0.275) (xgb8 0.237) (lgb 0.285) (lgb1 0.359) (lgb2 0.364) (lgb3 0.284) (lgb4 0.282) (lgb5 0.342) \n",
      "==> Ensemble Score 0.23253\n",
      "# FOLD 4  (xgb 0.334) (xgb1 0.162) (xgb2 0.184) (xgb3 0.238) (xgb4 0.163) (xgb5 0.198) (xgb6 0.132) (xgb7 0.154) (xgb8 0.143) (lgb 0.187) (lgb1 0.127) (lgb2 0.108) (lgb3 0.122) (lgb4 0.109) (lgb5 0.135) \n",
      "==> Ensemble Score 0.10033\n",
      "# FOLD 5  (xgb 0.373) (xgb1 0.211) (xgb2 0.253) (xgb3 0.201) (xgb4 0.224) (xgb5 0.175) (xgb6 0.213) (xgb7 0.185) (xgb8 0.304) (lgb 0.236) (lgb1 0.337) (lgb2 0.342) (lgb3 0.207) (lgb4 0.186) (lgb5 0.241) \n",
      "==> Ensemble Score 0.16513\n",
      "# FOLD 6  (xgb 0.347) (xgb1 0.299) (xgb2 0.270) (xgb3 0.261) (xgb4 0.305) (xgb5 0.311) (xgb6 0.346) (xgb7 0.297) (xgb8 0.264) (lgb 0.271) (lgb1 0.337) (lgb2 0.361) (lgb3 0.328) (lgb4 0.355) (lgb5 0.270) \n",
      "==> Ensemble Score 0.23355\n",
      "# FOLD 7  (xgb 0.221) (xgb1 0.164) (xgb2 0.158) (xgb3 0.127) (xgb4 0.141) (xgb5 0.104) (xgb6 0.137) (xgb7 0.148) (xgb8 0.099) (lgb 0.133) (lgb1 0.205) (lgb2 0.193) (lgb3 0.085) (lgb4 0.094) (lgb5 0.157) \n",
      "==> Ensemble Score 0.08577\n",
      "# FOLD 8  (xgb 0.445) (xgb1 0.193) (xgb2 0.187) (xgb3 0.250) (xgb4 0.183) (xgb5 0.270) (xgb6 0.187) (xgb7 0.220) (xgb8 0.184) (lgb 0.207) (lgb1 0.318) (lgb2 0.347) (lgb3 0.170) (lgb4 0.188) (lgb5 0.214) \n",
      "==> Ensemble Score 0.16319\n",
      "# FOLD 9  (xgb 0.487) (xgb1 0.338) (xgb2 0.359) (xgb3 0.420) (xgb4 0.345) (xgb5 0.368) (xgb6 0.350) (xgb7 0.438) (xgb8 0.367) (lgb 0.378) (lgb1 0.337) (lgb2 0.324) (lgb3 0.340) (lgb4 0.352) (lgb5 0.368) \n",
      "==> Ensemble Score 0.29436\n",
      "# FOLD 10  (xgb 0.507) (xgb1 0.293) (xgb2 0.325) (xgb3 0.327) (xgb4 0.361) (xgb5 0.314) (xgb6 0.434) (xgb7 0.370) (xgb8 0.352) (lgb 0.390) (lgb1 0.345) (lgb2 0.376) (lgb3 0.361) (lgb4 0.298) (lgb5 0.315) \n",
      "==> Ensemble Score 0.27870\n",
      "\n",
      "#### Bag/SEED no. 7\n",
      "# FOLD 1  (xgb 0.327) (xgb1 0.212) (xgb2 0.202) (xgb3 0.196) (xgb4 0.217) (xgb5 0.177) (xgb6 0.249) (xgb7 0.173) (xgb8 0.196) (lgb 0.184) (lgb1 0.164) (lgb2 0.191) (lgb3 0.140) (lgb4 0.190) (lgb5 0.145) \n",
      "==> Ensemble Score 0.12883\n",
      "# FOLD 2  (xgb 0.315) (xgb1 0.235) (xgb2 0.232) (xgb3 0.193) (xgb4 0.229) (xgb5 0.187) (xgb6 0.212) (xgb7 0.344) (xgb8 0.218) (lgb 0.192) (lgb1 0.192) (lgb2 0.197) (lgb3 0.201) (lgb4 0.216) (lgb5 0.136) \n",
      "==> Ensemble Score 0.14199\n",
      "# FOLD 3  (xgb 0.349) (xgb1 0.159) (xgb2 0.158) (xgb3 0.150) (xgb4 0.138) (xgb5 0.131) (xgb6 0.218) (xgb7 0.111) (xgb8 0.173) (lgb 0.139) (lgb1 0.247) (lgb2 0.271) (lgb3 0.153) (lgb4 0.188) (lgb5 0.147) \n",
      "==> Ensemble Score 0.12005\n",
      "# FOLD 4  (xgb 0.286) (xgb1 0.142) (xgb2 0.143) (xgb3 0.119) (xgb4 0.113) (xgb5 0.104) (xgb6 0.108) (xgb7 0.101) (xgb8 0.098) (lgb 0.117) (lgb1 0.236) (lgb2 0.230) (lgb3 0.081) (lgb4 0.076) (lgb5 0.117) \n",
      "==> Ensemble Score 0.07927\n",
      "# FOLD 5  (xgb 0.468) (xgb1 0.414) (xgb2 0.395) (xgb3 0.423) (xgb4 0.354) (xgb5 0.346) (xgb6 0.388) (xgb7 0.436) (xgb8 0.432) (lgb 0.390) (lgb1 0.460) (lgb2 0.476) (lgb3 0.381) (lgb4 0.374) (lgb5 0.345) \n",
      "==> Ensemble Score 0.33377\n",
      "# FOLD 6  (xgb 0.282) (xgb1 0.175) (xgb2 0.186) (xgb3 0.152) (xgb4 0.171) (xgb5 0.162) (xgb6 0.138) (xgb7 0.212) (xgb8 0.159) (lgb 0.157) (lgb1 0.188) (lgb2 0.251) (lgb3 0.095) (lgb4 0.103) (lgb5 0.162) \n",
      "==> Ensemble Score 0.09610\n",
      "# FOLD 7  (xgb 0.424) (xgb1 0.216) (xgb2 0.259) (xgb3 0.270) (xgb4 0.233) (xgb5 0.183) (xgb6 0.290) (xgb7 0.191) (xgb8 0.273) (lgb 0.276) (lgb1 0.284) (lgb2 0.255) (lgb3 0.311) (lgb4 0.335) (lgb5 0.255) \n",
      "==> Ensemble Score 0.17196\n",
      "# FOLD 8  (xgb 0.223) (xgb1 0.141) (xgb2 0.153) (xgb3 0.097) (xgb4 0.120) (xgb5 0.160) (xgb6 0.119) (xgb7 0.125) (xgb8 0.088) (lgb 0.135) (lgb1 0.141) (lgb2 0.135) (lgb3 0.084) (lgb4 0.086) (lgb5 0.135) \n",
      "==> Ensemble Score 0.07755\n",
      "# FOLD 9  (xgb 0.417) (xgb1 0.158) (xgb2 0.153) (xgb3 0.117) (xgb4 0.107) (xgb5 0.149) (xgb6 0.169) (xgb7 0.132) (xgb8 0.114) (lgb 0.165) (lgb1 0.139) (lgb2 0.176) (lgb3 0.070) (lgb4 0.076) (lgb5 0.079) \n",
      "==> Ensemble Score 0.06758\n",
      "# FOLD 10  (xgb 0.505) (xgb1 0.304) (xgb2 0.318) (xgb3 0.315) (xgb4 0.383) (xgb5 0.292) (xgb6 0.395) (xgb7 0.350) (xgb8 0.341) (lgb 0.342) (lgb1 0.346) (lgb2 0.378) (lgb3 0.358) (lgb4 0.366) (lgb5 0.390) \n",
      "==> Ensemble Score 0.28163\n",
      "\n",
      "#### Bag/SEED no. 8\n",
      "# FOLD 1  (xgb 0.280) (xgb1 0.246) (xgb2 0.300) (xgb3 0.363) (xgb4 0.298) (xgb5 0.441) (xgb6 0.328) (xgb7 0.399) (xgb8 0.333) (lgb 0.305) (lgb1 0.273) (lgb2 0.299) (lgb3 0.267) (lgb4 0.268) (lgb5 0.239) \n",
      "==> Ensemble Score 0.23863\n",
      "# FOLD 2  (xgb 0.216) (xgb1 0.160) (xgb2 0.194) (xgb3 0.170) (xgb4 0.163) (xgb5 0.146) (xgb6 0.173) (xgb7 0.223) (xgb8 0.094) (lgb 0.209) (lgb1 0.090) (lgb2 0.064) (lgb3 0.151) (lgb4 0.154) (lgb5 0.072) \n",
      "==> Ensemble Score 0.06693\n",
      "# FOLD 3  (xgb 0.325) (xgb1 0.172) (xgb2 0.196) (xgb3 0.162) (xgb4 0.155) (xgb5 0.172) (xgb6 0.150) (xgb7 0.176) (xgb8 0.132) (lgb 0.167) (lgb1 0.207) (lgb2 0.244) (lgb3 0.138) (lgb4 0.197) (lgb5 0.163) \n",
      "==> Ensemble Score 0.13158\n",
      "# FOLD 4  (xgb 0.239) (xgb1 0.113) (xgb2 0.137) (xgb3 0.112) (xgb4 0.103) (xgb5 0.107) (xgb6 0.183) (xgb7 0.107) (xgb8 0.187) (lgb 0.156) (lgb1 0.110) (lgb2 0.140) (lgb3 0.125) (lgb4 0.122) (lgb5 0.107) \n",
      "==> Ensemble Score 0.07306\n",
      "# FOLD 5  (xgb 0.553) (xgb1 0.371) (xgb2 0.386) (xgb3 0.363) (xgb4 0.390) (xgb5 0.394) (xgb6 0.368) (xgb7 0.395) (xgb8 0.347) (lgb 0.330) (lgb1 0.456) (lgb2 0.441) (lgb3 0.391) (lgb4 0.357) (lgb5 0.344) \n",
      "==> Ensemble Score 0.31443\n",
      "# FOLD 6  (xgb 0.408) (xgb1 0.272) (xgb2 0.292) (xgb3 0.270) (xgb4 0.262) (xgb5 0.317) (xgb6 0.285) (xgb7 0.288) (xgb8 0.300) (lgb 0.293) (lgb1 0.305) (lgb2 0.306) (lgb3 0.267) (lgb4 0.302) (lgb5 0.259) \n",
      "==> Ensemble Score 0.25401\n",
      "# FOLD 7  (xgb 0.392) (xgb1 0.269) (xgb2 0.251) (xgb3 0.249) (xgb4 0.208) (xgb5 0.344) (xgb6 0.224) (xgb7 0.221) (xgb8 0.288) (lgb 0.268) (lgb1 0.332) (lgb2 0.451) (lgb3 0.213) (lgb4 0.198) (lgb5 0.327) \n",
      "==> Ensemble Score 0.20067\n",
      "# FOLD 8  (xgb 0.204) (xgb1 0.157) (xgb2 0.185) (xgb3 0.210) (xgb4 0.167) (xgb5 0.113) (xgb6 0.199) (xgb7 0.283) (xgb8 0.129) (lgb 0.234) (lgb1 0.020) (lgb2 0.048) (lgb3 0.239) (lgb4 0.224) (lgb5 0.092) \n",
      "==> Ensemble Score 0.03143\n",
      "# FOLD 9  (xgb 0.382) (xgb1 0.186) (xgb2 0.203) (xgb3 0.171) (xgb4 0.165) (xgb5 0.217) (xgb6 0.185) (xgb7 0.192) (xgb8 0.170) (lgb 0.222) (lgb1 0.228) (lgb2 0.297) (lgb3 0.137) (lgb4 0.154) (lgb5 0.186) \n",
      "==> Ensemble Score 0.13782\n",
      "# FOLD 10  (xgb 0.372) (xgb1 0.244) (xgb2 0.206) (xgb3 0.242) (xgb4 0.217) (xgb5 0.286) (xgb6 0.304) (xgb7 0.213) (xgb8 0.301) (lgb 0.271) (lgb1 0.343) (lgb2 0.363) (lgb3 0.243) (lgb4 0.303) (lgb5 0.199) \n",
      "==> Ensemble Score 0.19389\n",
      "\n",
      "#### Bag/SEED no. 9\n",
      "# FOLD 1  (xgb 0.513) (xgb1 0.310) (xgb2 0.306) (xgb3 0.294) (xgb4 0.345) (xgb5 0.293) (xgb6 0.348) (xgb7 0.353) (xgb8 0.442) (lgb 0.367) (lgb1 0.443) (lgb2 0.457) (lgb3 0.329) (lgb4 0.405) (lgb5 0.324) \n",
      "==> Ensemble Score 0.28363\n",
      "# FOLD 2  (xgb 0.287) (xgb1 0.237) (xgb2 0.228) (xgb3 0.249) (xgb4 0.231) (xgb5 0.333) (xgb6 0.219) (xgb7 0.232) (xgb8 0.237) (lgb 0.202) (lgb1 0.224) (lgb2 0.236) (lgb3 0.212) (lgb4 0.196) (lgb5 0.239) \n",
      "==> Ensemble Score 0.17747\n",
      "# FOLD 3  (xgb 0.214) (xgb1 0.145) (xgb2 0.157) (xgb3 0.110) (xgb4 0.120) (xgb5 0.126) (xgb6 0.160) (xgb7 0.121) (xgb8 0.119) (lgb 0.161) (lgb1 0.187) (lgb2 0.189) (lgb3 0.116) (lgb4 0.137) (lgb5 0.149) \n",
      "==> Ensemble Score 0.10398\n",
      "# FOLD 4  (xgb 0.490) (xgb1 0.485) (xgb2 0.461) (xgb3 0.453) (xgb4 0.491) (xgb5 0.516) (xgb6 0.523) (xgb7 0.484) (xgb8 0.544) (lgb 0.496) (lgb1 0.504) (lgb2 0.478) (lgb3 0.520) (lgb4 0.489) (lgb5 0.450) \n",
      "==> Ensemble Score 0.42897\n",
      "# FOLD 5  (xgb 0.330) (xgb1 0.221) (xgb2 0.244) (xgb3 0.246) (xgb4 0.251) (xgb5 0.259) (xgb6 0.163) (xgb7 0.287) (xgb8 0.194) (lgb 0.196) (lgb1 0.200) (lgb2 0.200) (lgb3 0.186) (lgb4 0.200) (lgb5 0.180) \n",
      "==> Ensemble Score 0.16475\n",
      "# FOLD 6  (xgb 0.324) (xgb1 0.166) (xgb2 0.159) (xgb3 0.129) (xgb4 0.142) (xgb5 0.165) (xgb6 0.178) (xgb7 0.128) (xgb8 0.159) (lgb 0.140) (lgb1 0.234) (lgb2 0.235) (lgb3 0.095) (lgb4 0.078) (lgb5 0.157) \n",
      "==> Ensemble Score 0.08551\n",
      "# FOLD 7  (xgb 0.248) (xgb1 0.093) (xgb2 0.137) (xgb3 0.101) (xgb4 0.103) (xgb5 0.079) (xgb6 0.145) (xgb7 0.088) (xgb8 0.048) (lgb 0.111) (lgb1 0.090) (lgb2 0.103) (lgb3 0.118) (lgb4 0.086) (lgb5 0.070) \n",
      "==> Ensemble Score 0.06069\n",
      "# FOLD 8  (xgb 0.261) (xgb1 0.158) (xgb2 0.184) (xgb3 0.153) (xgb4 0.145) (xgb5 0.137) (xgb6 0.198) (xgb7 0.192) (xgb8 0.189) (lgb 0.203) (lgb1 0.164) (lgb2 0.211) (lgb3 0.117) (lgb4 0.135) (lgb5 0.162) \n",
      "==> Ensemble Score 0.12117\n",
      "# FOLD 9  (xgb 0.464) (xgb1 0.216) (xgb2 0.243) (xgb3 0.160) (xgb4 0.217) (xgb5 0.182) (xgb6 0.271) (xgb7 0.244) (xgb8 0.165) (lgb 0.243) (lgb1 0.393) (lgb2 0.307) (lgb3 0.133) (lgb4 0.203) (lgb5 0.251) \n",
      "==> Ensemble Score 0.14226\n",
      "# FOLD 10  (xgb 0.406) (xgb1 0.212) (xgb2 0.220) (xgb3 0.210) (xgb4 0.217) (xgb5 0.310) (xgb6 0.334) (xgb7 0.261) (xgb8 0.285) (lgb 0.237) (lgb1 0.319) (lgb2 0.334) (lgb3 0.210) (lgb4 0.210) (lgb5 0.244) \n",
      "==> Ensemble Score 0.20640\n",
      "\n",
      "#### Bag/SEED no. 10\n",
      "# FOLD 1  (xgb 0.452) (xgb1 0.270) (xgb2 0.263) (xgb3 0.305) (xgb4 0.252) (xgb5 0.244) (xgb6 0.389) (xgb7 0.287) (xgb8 0.297) (lgb 0.282) (lgb1 0.379) (lgb2 0.379) (lgb3 0.312) (lgb4 0.306) (lgb5 0.268) \n",
      "==> Ensemble Score 0.24346\n",
      "# FOLD 2  (xgb 0.331) (xgb1 0.174) (xgb2 0.171) (xgb3 0.153) (xgb4 0.128) (xgb5 0.165) (xgb6 0.281) (xgb7 0.220) (xgb8 0.128) (lgb 0.202) (lgb1 0.199) (lgb2 0.209) (lgb3 0.208) (lgb4 0.207) (lgb5 0.122) \n",
      "==> Ensemble Score 0.11831\n",
      "# FOLD 3  (xgb 0.434) (xgb1 0.198) (xgb2 0.185) (xgb3 0.149) (xgb4 0.221) (xgb5 0.190) (xgb6 0.251) (xgb7 0.229) (xgb8 0.263) (lgb 0.222) (lgb1 0.215) (lgb2 0.235) (lgb3 0.200) (lgb4 0.221) (lgb5 0.219) \n",
      "==> Ensemble Score 0.14717\n",
      "# FOLD 4  (xgb 0.371) (xgb1 0.209) (xgb2 0.188) (xgb3 0.163) (xgb4 0.155) (xgb5 0.195) (xgb6 0.256) (xgb7 0.172) (xgb8 0.173) (lgb 0.236) (lgb1 0.364) (lgb2 0.284) (lgb3 0.148) (lgb4 0.117) (lgb5 0.176) \n",
      "==> Ensemble Score 0.13049\n",
      "# FOLD 5  (xgb 0.569) (xgb1 0.244) (xgb2 0.265) (xgb3 0.254) (xgb4 0.310) (xgb5 0.310) (xgb6 0.248) (xgb7 0.389) (xgb8 0.231) (lgb 0.278) (lgb1 0.358) (lgb2 0.358) (lgb3 0.240) (lgb4 0.274) (lgb5 0.248) \n",
      "==> Ensemble Score 0.22603\n",
      "# FOLD 6  (xgb 0.340) (xgb1 0.179) (xgb2 0.232) (xgb3 0.211) (xgb4 0.210) (xgb5 0.179) (xgb6 0.172) (xgb7 0.202) (xgb8 0.176) (lgb 0.170) (lgb1 0.199) (lgb2 0.190) (lgb3 0.163) (lgb4 0.182) (lgb5 0.184) \n",
      "==> Ensemble Score 0.14760\n",
      "# FOLD 7  (xgb 0.342) (xgb1 0.165) (xgb2 0.195) (xgb3 0.150) (xgb4 0.140) (xgb5 0.171) (xgb6 0.140) (xgb7 0.131) (xgb8 0.143) (lgb 0.163) (lgb1 0.211) (lgb2 0.215) (lgb3 0.100) (lgb4 0.109) (lgb5 0.103) \n",
      "==> Ensemble Score 0.09144\n",
      "# FOLD 8  (xgb 0.424) (xgb1 0.294) (xgb2 0.304) (xgb3 0.367) (xgb4 0.357) (xgb5 0.321) (xgb6 0.306) (xgb7 0.243) (xgb8 0.281) (lgb 0.331) (lgb1 0.330) (lgb2 0.345) (lgb3 0.423) (lgb4 0.343) (lgb5 0.311) \n",
      "==> Ensemble Score 0.24395\n",
      "# FOLD 9  (xgb 0.273) (xgb1 0.207) (xgb2 0.191) (xgb3 0.167) (xgb4 0.176) (xgb5 0.172) (xgb6 0.185) (xgb7 0.204) (xgb8 0.199) (lgb 0.192) (lgb1 0.175) (lgb2 0.201) (lgb3 0.189) (lgb4 0.200) (lgb5 0.208) \n",
      "==> Ensemble Score 0.15837\n",
      "# FOLD 10  (xgb 0.441) (xgb1 0.345) (xgb2 0.348) (xgb3 0.341) (xgb4 0.365) (xgb5 0.409) (xgb6 0.384) (xgb7 0.382) (xgb8 0.416) (lgb 0.339) (lgb1 0.334) (lgb2 0.346) (lgb3 0.356) (lgb4 0.378) (lgb5 0.324) \n",
      "==> Ensemble Score 0.31134\n",
      "\n",
      "#### Bag/SEED no. 11\n",
      "# FOLD 1  (xgb 0.361) (xgb1 0.384) (xgb2 0.343) (xgb3 0.397) (xgb4 0.432) (xgb5 0.435) (xgb6 0.395) (xgb7 0.449) (xgb8 0.401) (lgb 0.375) (lgb1 0.387) (lgb2 0.351) (lgb3 0.384) (lgb4 0.360) (lgb5 0.347) \n",
      "==> Ensemble Score 0.31828\n",
      "# FOLD 2  (xgb 0.342) (xgb1 0.149) (xgb2 0.181) (xgb3 0.146) (xgb4 0.170) (xgb5 0.090) (xgb6 0.201) (xgb7 0.129) (xgb8 0.219) (lgb 0.185) (lgb1 0.277) (lgb2 0.265) (lgb3 0.136) (lgb4 0.162) (lgb5 0.150) \n",
      "==> Ensemble Score 0.09445\n",
      "# FOLD 3  (xgb 0.335) (xgb1 0.195) (xgb2 0.222) (xgb3 0.195) (xgb4 0.217) (xgb5 0.222) (xgb6 0.233) (xgb7 0.186) (xgb8 0.235) (lgb 0.233) (lgb1 0.208) (lgb2 0.225) (lgb3 0.175) (lgb4 0.184) (lgb5 0.189) \n",
      "==> Ensemble Score 0.15666\n",
      "# FOLD 4  (xgb 0.192) (xgb1 0.186) (xgb2 0.178) (xgb3 0.141) (xgb4 0.156) (xgb5 0.181) (xgb6 0.131) (xgb7 0.128) (xgb8 0.126) (lgb 0.160) (lgb1 0.164) (lgb2 0.155) (lgb3 0.104) (lgb4 0.120) (lgb5 0.102) \n",
      "==> Ensemble Score 0.09368\n",
      "# FOLD 5  (xgb 0.148) (xgb1 0.094) (xgb2 0.110) (xgb3 0.061) (xgb4 0.064) (xgb5 0.093) (xgb6 0.120) (xgb7 0.069) (xgb8 0.052) (lgb 0.113) (lgb1 0.098) (lgb2 0.092) (lgb3 0.028) (lgb4 0.027) (lgb5 0.018) \n",
      "==> Ensemble Score 0.02266\n",
      "# FOLD 6  (xgb 0.431) (xgb1 0.222) (xgb2 0.227) (xgb3 0.191) (xgb4 0.265) (xgb5 0.239) (xgb6 0.282) (xgb7 0.270) (xgb8 0.261) (lgb 0.189) (lgb1 0.310) (lgb2 0.312) (lgb3 0.211) (lgb4 0.176) (lgb5 0.247) \n",
      "==> Ensemble Score 0.17166\n",
      "# FOLD 7  (xgb 0.460) (xgb1 0.279) (xgb2 0.243) (xgb3 0.294) (xgb4 0.242) (xgb5 0.241) (xgb6 0.308) (xgb7 0.255) (xgb8 0.223) (lgb 0.325) (lgb1 0.286) (lgb2 0.277) (lgb3 0.307) (lgb4 0.250) (lgb5 0.181) \n",
      "==> Ensemble Score 0.17752\n",
      "# FOLD 8  (xgb 0.352) (xgb1 0.277) (xgb2 0.312) (xgb3 0.327) (xgb4 0.284) (xgb5 0.307) (xgb6 0.211) (xgb7 0.375) (xgb8 0.219) (lgb 0.302) (lgb1 0.393) (lgb2 0.384) (lgb3 0.205) (lgb4 0.218) (lgb5 0.295) \n",
      "==> Ensemble Score 0.19895\n",
      "# FOLD 9  (xgb 0.215) (xgb1 0.170) (xgb2 0.144) (xgb3 0.130) (xgb4 0.180) (xgb5 0.142) (xgb6 0.191) (xgb7 0.100) (xgb8 0.162) (lgb 0.154) (lgb1 0.140) (lgb2 0.162) (lgb3 0.106) (lgb4 0.161) (lgb5 0.129) \n",
      "==> Ensemble Score 0.08962\n",
      "# FOLD 10  (xgb 0.538) (xgb1 0.288) (xgb2 0.260) (xgb3 0.289) (xgb4 0.291) (xgb5 0.273) (xgb6 0.251) (xgb7 0.297) (xgb8 0.313) (lgb 0.270) (lgb1 0.294) (lgb2 0.331) (lgb3 0.277) (lgb4 0.254) (lgb5 0.236) \n",
      "==> Ensemble Score 0.22370\n",
      "\n",
      "#### Bag/SEED no. 12\n",
      "# FOLD 1  (xgb 0.337) (xgb1 0.255) (xgb2 0.215) (xgb3 0.190) (xgb4 0.228) (xgb5 0.137) (xgb6 0.310) (xgb7 0.162) (xgb8 0.290) (lgb 0.229) (lgb1 0.339) (lgb2 0.387) (lgb3 0.259) (lgb4 0.333) (lgb5 0.209) \n",
      "==> Ensemble Score 0.13661\n",
      "# FOLD 2  (xgb 0.365) (xgb1 0.138) (xgb2 0.149) (xgb3 0.094) (xgb4 0.130) (xgb5 0.142) (xgb6 0.120) (xgb7 0.101) (xgb8 0.129) (lgb 0.141) (lgb1 0.187) (lgb2 0.202) (lgb3 0.093) (lgb4 0.110) (lgb5 0.160) \n",
      "==> Ensemble Score 0.08829\n",
      "# FOLD 3  (xgb 0.394) (xgb1 0.297) (xgb2 0.309) (xgb3 0.313) (xgb4 0.382) (xgb5 0.295) (xgb6 0.332) (xgb7 0.391) (xgb8 0.389) (lgb 0.346) (lgb1 0.270) (lgb2 0.346) (lgb3 0.376) (lgb4 0.425) (lgb5 0.319) \n",
      "==> Ensemble Score 0.26580\n",
      "# FOLD 4  (xgb 0.348) (xgb1 0.249) (xgb2 0.247) (xgb3 0.185) (xgb4 0.211) (xgb5 0.317) (xgb6 0.272) (xgb7 0.189) (xgb8 0.247) (lgb 0.243) (lgb1 0.363) (lgb2 0.370) (lgb3 0.141) (lgb4 0.200) (lgb5 0.258) \n",
      "==> Ensemble Score 0.16171\n",
      "# FOLD 5  (xgb 0.199) (xgb1 0.117) (xgb2 0.140) (xgb3 0.139) (xgb4 0.106) (xgb5 0.093) (xgb6 0.155) (xgb7 0.208) (xgb8 0.117) (lgb 0.152) (lgb1 0.170) (lgb2 0.194) (lgb3 0.099) (lgb4 0.124) (lgb5 0.098) \n",
      "==> Ensemble Score 0.08204\n",
      "# FOLD 6  (xgb 0.236) (xgb1 0.287) (xgb2 0.289) (xgb3 0.357) (xgb4 0.269) (xgb5 0.352) (xgb6 0.296) (xgb7 0.352) (xgb8 0.329) (lgb 0.309) (lgb1 0.236) (lgb2 0.298) (lgb3 0.286) (lgb4 0.363) (lgb5 0.270) \n",
      "==> Ensemble Score 0.22154\n",
      "# FOLD 7  (xgb 0.304) (xgb1 0.137) (xgb2 0.167) (xgb3 0.132) (xgb4 0.128) (xgb5 0.149) (xgb6 0.180) (xgb7 0.133) (xgb8 0.113) (lgb 0.166) (lgb1 0.131) (lgb2 0.126) (lgb3 0.120) (lgb4 0.096) (lgb5 0.158) \n",
      "==> Ensemble Score 0.10188\n",
      "# FOLD 8  (xgb 0.431) (xgb1 0.326) (xgb2 0.288) (xgb3 0.280) (xgb4 0.251) (xgb5 0.308) (xgb6 0.334) (xgb7 0.335) (xgb8 0.346) (lgb 0.325) (lgb1 0.282) (lgb2 0.310) (lgb3 0.261) (lgb4 0.260) (lgb5 0.301) \n",
      "==> Ensemble Score 0.23611\n",
      "# FOLD 9  (xgb 0.202) (xgb1 0.149) (xgb2 0.166) (xgb3 0.147) (xgb4 0.166) (xgb5 0.179) (xgb6 0.132) (xgb7 0.141) (xgb8 0.134) (lgb 0.149) (lgb1 0.103) (lgb2 0.120) (lgb3 0.123) (lgb4 0.135) (lgb5 0.152) \n",
      "==> Ensemble Score 0.10415\n",
      "# FOLD 10  (xgb 0.348) (xgb1 0.196) (xgb2 0.195) (xgb3 0.162) (xgb4 0.175) (xgb5 0.206) (xgb6 0.197) (xgb7 0.136) (xgb8 0.177) (lgb 0.187) (lgb1 0.337) (lgb2 0.326) (lgb3 0.129) (lgb4 0.135) (lgb5 0.200) \n",
      "==> Ensemble Score 0.12544\n",
      "\n",
      "#### Bag/SEED no. 13\n",
      "# FOLD 1  (xgb 0.418) (xgb1 0.183) (xgb2 0.189) (xgb3 0.161) (xgb4 0.170) (xgb5 0.143) (xgb6 0.131) (xgb7 0.154) (xgb8 0.089) (lgb 0.154) (lgb1 0.144) (lgb2 0.174) (lgb3 0.085) (lgb4 0.110) (lgb5 0.172) \n",
      "==> Ensemble Score 0.08633\n",
      "# FOLD 2  (xgb 0.393) (xgb1 0.283) (xgb2 0.252) (xgb3 0.264) (xgb4 0.232) (xgb5 0.225) (xgb6 0.297) (xgb7 0.279) (xgb8 0.339) (lgb 0.286) (lgb1 0.253) (lgb2 0.274) (lgb3 0.258) (lgb4 0.268) (lgb5 0.251) \n",
      "==> Ensemble Score 0.20666\n",
      "# FOLD 3  (xgb 0.513) (xgb1 0.374) (xgb2 0.388) (xgb3 0.457) (xgb4 0.372) (xgb5 0.424) (xgb6 0.409) (xgb7 0.394) (xgb8 0.338) (lgb 0.382) (lgb1 0.386) (lgb2 0.375) (lgb3 0.321) (lgb4 0.386) (lgb5 0.379) \n",
      "==> Ensemble Score 0.31771\n",
      "# FOLD 4  (xgb 0.432) (xgb1 0.190) (xgb2 0.193) (xgb3 0.193) (xgb4 0.175) (xgb5 0.216) (xgb6 0.194) (xgb7 0.197) (xgb8 0.161) (lgb 0.185) (lgb1 0.240) (lgb2 0.283) (lgb3 0.131) (lgb4 0.144) (lgb5 0.178) \n",
      "==> Ensemble Score 0.13089\n",
      "# FOLD 5  (xgb 0.230) (xgb1 0.110) (xgb2 0.128) (xgb3 0.130) (xgb4 0.136) (xgb5 0.114) (xgb6 0.174) (xgb7 0.197) (xgb8 0.146) (lgb 0.154) (lgb1 0.133) (lgb2 0.183) (lgb3 0.088) (lgb4 0.102) (lgb5 0.074) \n",
      "==> Ensemble Score 0.08049\n",
      "# FOLD 6  (xgb 0.376) (xgb1 0.357) (xgb2 0.393) (xgb3 0.375) (xgb4 0.333) (xgb5 0.422) (xgb6 0.328) (xgb7 0.414) (xgb8 0.355) (lgb 0.388) (lgb1 0.314) (lgb2 0.304) (lgb3 0.333) (lgb4 0.375) (lgb5 0.357) \n",
      "==> Ensemble Score 0.29219\n",
      "# FOLD 7  (xgb 0.443) (xgb1 0.297) (xgb2 0.298) (xgb3 0.329) (xgb4 0.259) (xgb5 0.303) (xgb6 0.322) (xgb7 0.342) (xgb8 0.278) (lgb 0.296) (lgb1 0.301) (lgb2 0.293) (lgb3 0.330) (lgb4 0.223) (lgb5 0.334) \n",
      "==> Ensemble Score 0.23691\n",
      "# FOLD 8  (xgb 0.229) (xgb1 0.115) (xgb2 0.156) (xgb3 0.101) (xgb4 0.144) (xgb5 0.160) (xgb6 0.187) (xgb7 0.297) (xgb8 0.114) (lgb 0.159) (lgb1 0.130) (lgb2 0.181) (lgb3 0.051) (lgb4 0.092) (lgb5 0.105) \n",
      "==> Ensemble Score 0.07110\n",
      "# FOLD 9  (xgb 0.298) (xgb1 0.294) (xgb2 0.313) (xgb3 0.338) (xgb4 0.292) (xgb5 0.383) (xgb6 0.307) (xgb7 0.249) (xgb8 0.342) (lgb 0.339) (lgb1 0.319) (lgb2 0.341) (lgb3 0.294) (lgb4 0.288) (lgb5 0.316) \n",
      "==> Ensemble Score 0.23334\n",
      "# FOLD 10  (xgb 0.339) (xgb1 0.198) (xgb2 0.176) (xgb3 0.138) (xgb4 0.142) (xgb5 0.136) (xgb6 0.174) (xgb7 0.180) (xgb8 0.097) (lgb 0.173) (lgb1 0.282) (lgb2 0.313) (lgb3 0.090) (lgb4 0.089) (lgb5 0.149) \n",
      "==> Ensemble Score 0.08895\n",
      "\n",
      "#### Bag/SEED no. 14\n",
      "# FOLD 1  (xgb 0.219) (xgb1 0.113) (xgb2 0.126) (xgb3 0.129) (xgb4 0.161) (xgb5 0.182) (xgb6 0.129) (xgb7 0.083) (xgb8 0.150) (lgb 0.097) (lgb1 0.182) (lgb2 0.236) (lgb3 0.070) (lgb4 0.043) (lgb5 0.132) \n",
      "==> Ensemble Score 0.05487\n",
      "# FOLD 2  (xgb 0.315) (xgb1 0.261) (xgb2 0.235) (xgb3 0.205) (xgb4 0.277) (xgb5 0.204) (xgb6 0.350) (xgb7 0.211) (xgb8 0.296) (lgb 0.292) (lgb1 0.321) (lgb2 0.331) (lgb3 0.439) (lgb4 0.428) (lgb5 0.269) \n",
      "==> Ensemble Score 0.19878\n",
      "# FOLD 3  (xgb 0.439) (xgb1 0.432) (xgb2 0.436) (xgb3 0.444) (xgb4 0.407) (xgb5 0.394) (xgb6 0.412) (xgb7 0.437) (xgb8 0.452) (lgb 0.428) (lgb1 0.422) (lgb2 0.416) (lgb3 0.417) (lgb4 0.445) (lgb5 0.431) \n",
      "==> Ensemble Score 0.35875\n",
      "# FOLD 4  (xgb 0.251) (xgb1 0.135) (xgb2 0.129) (xgb3 0.123) (xgb4 0.102) (xgb5 0.095) (xgb6 0.167) (xgb7 0.089) (xgb8 0.146) (lgb 0.161) (lgb1 0.159) (lgb2 0.153) (lgb3 0.140) (lgb4 0.116) (lgb5 0.135) \n",
      "==> Ensemble Score 0.08635\n",
      "# FOLD 5  (xgb 0.331) (xgb1 0.262) (xgb2 0.262) (xgb3 0.293) (xgb4 0.261) (xgb5 0.265) (xgb6 0.256) (xgb7 0.292) (xgb8 0.265) (lgb 0.241) (lgb1 0.298) (lgb2 0.289) (lgb3 0.237) (lgb4 0.273) (lgb5 0.236) \n",
      "==> Ensemble Score 0.21453\n",
      "# FOLD 6  (xgb 0.379) (xgb1 0.206) (xgb2 0.192) (xgb3 0.192) (xgb4 0.224) (xgb5 0.219) (xgb6 0.198) (xgb7 0.233) (xgb8 0.189) (lgb 0.207) (lgb1 0.266) (lgb2 0.289) (lgb3 0.197) (lgb4 0.176) (lgb5 0.154) \n",
      "==> Ensemble Score 0.14749\n",
      "# FOLD 7  (xgb 0.311) (xgb1 0.160) (xgb2 0.225) (xgb3 0.199) (xgb4 0.179) (xgb5 0.247) (xgb6 0.185) (xgb7 0.321) (xgb8 0.170) (lgb 0.216) (lgb1 0.124) (lgb2 0.161) (lgb3 0.217) (lgb4 0.227) (lgb5 0.205) \n",
      "==> Ensemble Score 0.12154\n",
      "# FOLD 8  (xgb 0.395) (xgb1 0.290) (xgb2 0.287) (xgb3 0.276) (xgb4 0.301) (xgb5 0.321) (xgb6 0.284) (xgb7 0.332) (xgb8 0.303) (lgb 0.262) (lgb1 0.455) (lgb2 0.444) (lgb3 0.257) (lgb4 0.304) (lgb5 0.324) \n",
      "==> Ensemble Score 0.25236\n",
      "# FOLD 9  (xgb 0.392) (xgb1 0.173) (xgb2 0.197) (xgb3 0.185) (xgb4 0.198) (xgb5 0.254) (xgb6 0.177) (xgb7 0.120) (xgb8 0.166) (lgb 0.158) (lgb1 0.071) (lgb2 0.131) (lgb3 0.078) (lgb4 0.077) (lgb5 0.106) \n",
      "==> Ensemble Score 0.07235\n",
      "# FOLD 10  (xgb 0.376) (xgb1 0.246) (xgb2 0.240) (xgb3 0.332) (xgb4 0.253) (xgb5 0.309) (xgb6 0.272) (xgb7 0.383) (xgb8 0.307) (lgb 0.275) (lgb1 0.294) (lgb2 0.370) (lgb3 0.293) (lgb4 0.265) (lgb5 0.237) \n",
      "==> Ensemble Score 0.22594\n",
      "\n",
      "#### Bag/SEED no. 15\n",
      "# FOLD 1  (xgb 0.380) (xgb1 0.285) (xgb2 0.319) (xgb3 0.356) (xgb4 0.287) (xgb5 0.266) (xgb6 0.325) (xgb7 0.392) (xgb8 0.370) (lgb 0.302) (lgb1 0.367) (lgb2 0.431) (lgb3 0.324) (lgb4 0.351) (lgb5 0.235) \n",
      "==> Ensemble Score 0.24115\n",
      "# FOLD 2  (xgb 0.319) (xgb1 0.161) (xgb2 0.143) (xgb3 0.117) (xgb4 0.146) (xgb5 0.132) (xgb6 0.134) (xgb7 0.129) (xgb8 0.137) (lgb 0.133) (lgb1 0.205) (lgb2 0.233) (lgb3 0.072) (lgb4 0.053) (lgb5 0.160) \n",
      "==> Ensemble Score 0.06539\n",
      "# FOLD 3  (xgb 0.246) (xgb1 0.160) (xgb2 0.160) (xgb3 0.130) (xgb4 0.131) (xgb5 0.120) (xgb6 0.156) (xgb7 0.093) (xgb8 0.160) (lgb 0.189) (lgb1 0.242) (lgb2 0.273) (lgb3 0.155) (lgb4 0.172) (lgb5 0.150) \n",
      "==> Ensemble Score 0.09680\n",
      "# FOLD 4  (xgb 0.348) (xgb1 0.151) (xgb2 0.163) (xgb3 0.139) (xgb4 0.158) (xgb5 0.132) (xgb6 0.223) (xgb7 0.193) (xgb8 0.197) (lgb 0.180) (lgb1 0.215) (lgb2 0.241) (lgb3 0.218) (lgb4 0.198) (lgb5 0.098) \n",
      "==> Ensemble Score 0.11561\n",
      "# FOLD 5  (xgb 0.379) (xgb1 0.218) (xgb2 0.214) (xgb3 0.237) (xgb4 0.168) (xgb5 0.173) (xgb6 0.223) (xgb7 0.181) (xgb8 0.178) (lgb 0.223) (lgb1 0.226) (lgb2 0.265) (lgb3 0.188) (lgb4 0.171) (lgb5 0.135) \n",
      "==> Ensemble Score 0.14650\n",
      "# FOLD 6  (xgb 0.221) (xgb1 0.165) (xgb2 0.207) (xgb3 0.187) (xgb4 0.181) (xgb5 0.156) (xgb6 0.111) (xgb7 0.238) (xgb8 0.100) (lgb 0.166) (lgb1 0.102) (lgb2 0.084) (lgb3 0.134) (lgb4 0.133) (lgb5 0.099) \n",
      "==> Ensemble Score 0.07469\n",
      "# FOLD 7  (xgb 0.430) (xgb1 0.328) (xgb2 0.364) (xgb3 0.425) (xgb4 0.363) (xgb5 0.503) (xgb6 0.323) (xgb7 0.477) (xgb8 0.430) (lgb 0.329) (lgb1 0.309) (lgb2 0.284) (lgb3 0.347) (lgb4 0.293) (lgb5 0.271) \n",
      "==> Ensemble Score 0.23303\n",
      "# FOLD 8  (xgb 0.318) (xgb1 0.361) (xgb2 0.377) (xgb3 0.422) (xgb4 0.396) (xgb5 0.477) (xgb6 0.354) (xgb7 0.408) (xgb8 0.376) (lgb 0.373) (lgb1 0.298) (lgb2 0.316) (lgb3 0.395) (lgb4 0.337) (lgb5 0.344) \n",
      "==> Ensemble Score 0.29044\n",
      "# FOLD 9  (xgb 0.404) (xgb1 0.243) (xgb2 0.243) (xgb3 0.210) (xgb4 0.195) (xgb5 0.319) (xgb6 0.294) (xgb7 0.246) (xgb8 0.345) (lgb 0.228) (lgb1 0.361) (lgb2 0.358) (lgb3 0.178) (lgb4 0.167) (lgb5 0.259) \n",
      "==> Ensemble Score 0.17568\n",
      "# FOLD 10  (xgb 0.255) (xgb1 0.175) (xgb2 0.186) (xgb3 0.145) (xgb4 0.146) (xgb5 0.156) (xgb6 0.147) (xgb7 0.160) (xgb8 0.126) (lgb 0.165) (lgb1 0.213) (lgb2 0.218) (lgb3 0.117) (lgb4 0.116) (lgb5 0.147) \n",
      "==> Ensemble Score 0.10492\n",
      "\n",
      "#### Bag/SEED no. 16\n",
      "# FOLD 1  (xgb 0.357) (xgb1 0.214) (xgb2 0.196) (xgb3 0.159) (xgb4 0.170) (xgb5 0.146) (xgb6 0.226) (xgb7 0.212) (xgb8 0.130) (lgb 0.166) (lgb1 0.260) (lgb2 0.309) (lgb3 0.142) (lgb4 0.161) (lgb5 0.169) \n",
      "==> Ensemble Score 0.13056\n",
      "# FOLD 2  (xgb 0.324) (xgb1 0.208) (xgb2 0.212) (xgb3 0.214) (xgb4 0.168) (xgb5 0.224) (xgb6 0.213) (xgb7 0.295) (xgb8 0.238) (lgb 0.232) (lgb1 0.217) (lgb2 0.270) (lgb3 0.262) (lgb4 0.238) (lgb5 0.171) \n",
      "==> Ensemble Score 0.15798\n",
      "# FOLD 3  (xgb 0.526) (xgb1 0.444) (xgb2 0.463) (xgb3 0.477) (xgb4 0.424) (xgb5 0.451) (xgb6 0.402) (xgb7 0.447) (xgb8 0.445) (lgb 0.447) (lgb1 0.403) (lgb2 0.398) (lgb3 0.416) (lgb4 0.390) (lgb5 0.507) \n",
      "==> Ensemble Score 0.34716\n",
      "# FOLD 4  (xgb 0.418) (xgb1 0.242) (xgb2 0.239) (xgb3 0.259) (xgb4 0.283) (xgb5 0.209) (xgb6 0.293) (xgb7 0.366) (xgb8 0.288) (lgb 0.328) (lgb1 0.209) (lgb2 0.239) (lgb3 0.212) (lgb4 0.183) (lgb5 0.103) \n",
      "==> Ensemble Score 0.13822\n",
      "# FOLD 5  (xgb 0.371) (xgb1 0.189) (xgb2 0.188) (xgb3 0.146) (xgb4 0.163) (xgb5 0.180) (xgb6 0.182) (xgb7 0.183) (xgb8 0.124) (lgb 0.206) (lgb1 0.279) (lgb2 0.320) (lgb3 0.140) (lgb4 0.164) (lgb5 0.202) \n",
      "==> Ensemble Score 0.13095\n",
      "# FOLD 6  (xgb 0.500) (xgb1 0.232) (xgb2 0.243) (xgb3 0.222) (xgb4 0.223) (xgb5 0.351) (xgb6 0.244) (xgb7 0.251) (xgb8 0.181) (lgb 0.269) (lgb1 0.224) (lgb2 0.228) (lgb3 0.279) (lgb4 0.281) (lgb5 0.240) \n",
      "==> Ensemble Score 0.15804\n",
      "# FOLD 7  (xgb 0.335) (xgb1 0.272) (xgb2 0.238) (xgb3 0.240) (xgb4 0.249) (xgb5 0.244) (xgb6 0.337) (xgb7 0.176) (xgb8 0.285) (lgb 0.305) (lgb1 0.262) (lgb2 0.313) (lgb3 0.324) (lgb4 0.336) (lgb5 0.277) \n",
      "==> Ensemble Score 0.17739\n",
      "# FOLD 8  (xgb 0.374) (xgb1 0.190) (xgb2 0.177) (xgb3 0.146) (xgb4 0.170) (xgb5 0.216) (xgb6 0.163) (xgb7 0.139) (xgb8 0.132) (lgb 0.145) (lgb1 0.166) (lgb2 0.162) (lgb3 0.174) (lgb4 0.162) (lgb5 0.139) \n",
      "==> Ensemble Score 0.11899\n",
      "# FOLD 9  (xgb 0.314) (xgb1 0.174) (xgb2 0.187) (xgb3 0.156) (xgb4 0.174) (xgb5 0.161) (xgb6 0.178) (xgb7 0.134) (xgb8 0.167) (lgb 0.163) (lgb1 0.226) (lgb2 0.237) (lgb3 0.122) (lgb4 0.111) (lgb5 0.159) \n",
      "==> Ensemble Score 0.10488\n",
      "# FOLD 10  (xgb 0.428) (xgb1 0.127) (xgb2 0.137) (xgb3 0.107) (xgb4 0.131) (xgb5 0.095) (xgb6 0.158) (xgb7 0.173) (xgb8 0.141) (lgb 0.119) (lgb1 0.106) (lgb2 0.146) (lgb3 0.079) (lgb4 0.079) (lgb5 0.096) \n",
      "==> Ensemble Score 0.07499\n",
      "\n",
      "#### Bag/SEED no. 17\n",
      "# FOLD 1  (xgb 0.356) (xgb1 0.182) (xgb2 0.161) (xgb3 0.119) (xgb4 0.151) (xgb5 0.129) (xgb6 0.212) (xgb7 0.087) (xgb8 0.143) (lgb 0.173) (lgb1 0.209) (lgb2 0.189) (lgb3 0.162) (lgb4 0.172) (lgb5 0.165) \n",
      "==> Ensemble Score 0.10310\n",
      "# FOLD 2  (xgb 0.257) (xgb1 0.099) (xgb2 0.130) (xgb3 0.094) (xgb4 0.087) (xgb5 0.114) (xgb6 0.140) (xgb7 0.074) (xgb8 0.088) (lgb 0.137) (lgb1 0.164) (lgb2 0.146) (lgb3 0.055) (lgb4 0.058) (lgb5 0.079) \n",
      "==> Ensemble Score 0.06028\n",
      "# FOLD 3  (xgb 0.329) (xgb1 0.272) (xgb2 0.297) (xgb3 0.314) (xgb4 0.249) (xgb5 0.284) (xgb6 0.285) (xgb7 0.273) (xgb8 0.284) (lgb 0.310) (lgb1 0.288) (lgb2 0.296) (lgb3 0.274) (lgb4 0.287) (lgb5 0.296) \n",
      "==> Ensemble Score 0.24429\n",
      "# FOLD 4  (xgb 0.456) (xgb1 0.399) (xgb2 0.390) (xgb3 0.386) (xgb4 0.412) (xgb5 0.407) (xgb6 0.392) (xgb7 0.440) (xgb8 0.439) (lgb 0.389) (lgb1 0.384) (lgb2 0.436) (lgb3 0.443) (lgb4 0.404) (lgb5 0.382) \n",
      "==> Ensemble Score 0.34810\n",
      "# FOLD 5  (xgb 0.396) (xgb1 0.181) (xgb2 0.217) (xgb3 0.244) (xgb4 0.176) (xgb5 0.150) (xgb6 0.200) (xgb7 0.178) (xgb8 0.121) (lgb 0.185) (lgb1 0.251) (lgb2 0.248) (lgb3 0.188) (lgb4 0.119) (lgb5 0.168) \n",
      "==> Ensemble Score 0.11305\n",
      "# FOLD 6  (xgb 0.473) (xgb1 0.239) (xgb2 0.257) (xgb3 0.229) (xgb4 0.229) (xgb5 0.241) (xgb6 0.263) (xgb7 0.263) (xgb8 0.220) (lgb 0.214) (lgb1 0.294) (lgb2 0.281) (lgb3 0.242) (lgb4 0.202) (lgb5 0.271) \n",
      "==> Ensemble Score 0.18972\n",
      "# FOLD 7  (xgb 0.396) (xgb1 0.332) (xgb2 0.355) (xgb3 0.281) (xgb4 0.314) (xgb5 0.395) (xgb6 0.374) (xgb7 0.377) (xgb8 0.360) (lgb 0.399) (lgb1 0.278) (lgb2 0.308) (lgb3 0.450) (lgb4 0.356) (lgb5 0.363) \n",
      "==> Ensemble Score 0.26589\n",
      "# FOLD 8  (xgb 0.272) (xgb1 0.224) (xgb2 0.234) (xgb3 0.272) (xgb4 0.240) (xgb5 0.254) (xgb6 0.279) (xgb7 0.316) (xgb8 0.248) (lgb 0.247) (lgb1 0.227) (lgb2 0.294) (lgb3 0.261) (lgb4 0.229) (lgb5 0.238) \n",
      "==> Ensemble Score 0.20850\n",
      "# FOLD 9  (xgb 0.331) (xgb1 0.168) (xgb2 0.176) (xgb3 0.132) (xgb4 0.164) (xgb5 0.106) (xgb6 0.164) (xgb7 0.154) (xgb8 0.092) (lgb 0.161) (lgb1 0.196) (lgb2 0.207) (lgb3 0.092) (lgb4 0.085) (lgb5 0.099) \n",
      "==> Ensemble Score 0.07915\n",
      "# FOLD 10  (xgb 0.344) (xgb1 0.163) (xgb2 0.173) (xgb3 0.163) (xgb4 0.117) (xgb5 0.097) (xgb6 0.228) (xgb7 0.173) (xgb8 0.187) (lgb 0.189) (lgb1 0.088) (lgb2 0.159) (lgb3 0.211) (lgb4 0.149) (lgb5 0.138) \n",
      "==> Ensemble Score 0.08427\n",
      "\n",
      "#### Bag/SEED no. 18\n",
      "# FOLD 1  (xgb 0.409) (xgb1 0.389) (xgb2 0.413) (xgb3 0.407) (xgb4 0.348) (xgb5 0.300) (xgb6 0.523) (xgb7 0.430) (xgb8 0.510) (lgb 0.446) (lgb1 0.333) (lgb2 0.306) (lgb3 0.443) (lgb4 0.430) (lgb5 0.380) \n",
      "==> Ensemble Score 0.28988\n",
      "# FOLD 2  (xgb 0.200) (xgb1 0.141) (xgb2 0.137) (xgb3 0.103) (xgb4 0.119) (xgb5 0.101) (xgb6 0.166) (xgb7 0.110) (xgb8 0.121) (lgb 0.158) (lgb1 0.188) (lgb2 0.237) (lgb3 0.109) (lgb4 0.089) (lgb5 0.148) \n",
      "==> Ensemble Score 0.08624\n",
      "# FOLD 3  (xgb 0.402) (xgb1 0.262) (xgb2 0.215) (xgb3 0.201) (xgb4 0.213) (xgb5 0.239) (xgb6 0.292) (xgb7 0.202) (xgb8 0.300) (lgb 0.214) (lgb1 0.312) (lgb2 0.324) (lgb3 0.214) (lgb4 0.248) (lgb5 0.272) \n",
      "==> Ensemble Score 0.19223\n",
      "# FOLD 4  (xgb 0.310) (xgb1 0.197) (xgb2 0.216) (xgb3 0.233) (xgb4 0.190) (xgb5 0.220) (xgb6 0.259) (xgb7 0.194) (xgb8 0.230) (lgb 0.248) (lgb1 0.269) (lgb2 0.270) (lgb3 0.265) (lgb4 0.257) (lgb5 0.201) \n",
      "==> Ensemble Score 0.18943\n",
      "# FOLD 5  (xgb 0.441) (xgb1 0.294) (xgb2 0.283) (xgb3 0.269) (xgb4 0.325) (xgb5 0.265) (xgb6 0.410) (xgb7 0.252) (xgb8 0.421) (lgb 0.335) (lgb1 0.353) (lgb2 0.341) (lgb3 0.422) (lgb4 0.393) (lgb5 0.288) \n",
      "==> Ensemble Score 0.24938\n",
      "# FOLD 6  (xgb 0.355) (xgb1 0.302) (xgb2 0.310) (xgb3 0.300) (xgb4 0.309) (xgb5 0.255) (xgb6 0.241) (xgb7 0.280) (xgb8 0.284) (lgb 0.304) (lgb1 0.305) (lgb2 0.260) (lgb3 0.302) (lgb4 0.279) (lgb5 0.326) \n",
      "==> Ensemble Score 0.23092\n",
      "# FOLD 7  (xgb 0.466) (xgb1 0.218) (xgb2 0.209) (xgb3 0.182) (xgb4 0.183) (xgb5 0.286) (xgb6 0.199) (xgb7 0.219) (xgb8 0.181) (lgb 0.190) (lgb1 0.389) (lgb2 0.438) (lgb3 0.132) (lgb4 0.147) (lgb5 0.227) \n",
      "==> Ensemble Score 0.13910\n",
      "# FOLD 8  (xgb 0.321) (xgb1 0.182) (xgb2 0.230) (xgb3 0.342) (xgb4 0.204) (xgb5 0.208) (xgb6 0.212) (xgb7 0.324) (xgb8 0.182) (lgb 0.219) (lgb1 0.218) (lgb2 0.241) (lgb3 0.247) (lgb4 0.220) (lgb5 0.153) \n",
      "==> Ensemble Score 0.14630\n",
      "# FOLD 9  (xgb 0.178) (xgb1 0.171) (xgb2 0.205) (xgb3 0.207) (xgb4 0.180) (xgb5 0.174) (xgb6 0.200) (xgb7 0.346) (xgb8 0.232) (lgb 0.252) (lgb1 0.204) (lgb2 0.212) (lgb3 0.214) (lgb4 0.268) (lgb5 0.186) \n",
      "==> Ensemble Score 0.14874\n",
      "# FOLD 10  (xgb 0.271) (xgb1 0.196) (xgb2 0.198) (xgb3 0.178) (xgb4 0.184) (xgb5 0.142) (xgb6 0.196) (xgb7 0.296) (xgb8 0.149) (lgb 0.221) (lgb1 0.274) (lgb2 0.289) (lgb3 0.209) (lgb4 0.191) (lgb5 0.237) \n",
      "==> Ensemble Score 0.13872\n",
      "\n",
      "#### Bag/SEED no. 19\n",
      "# FOLD 1  (xgb 0.271) (xgb1 0.229) (xgb2 0.239) (xgb3 0.235) (xgb4 0.224) (xgb5 0.248) (xgb6 0.184) (xgb7 0.272) (xgb8 0.206) (lgb 0.230) (lgb1 0.275) (lgb2 0.340) (lgb3 0.153) (lgb4 0.183) (lgb5 0.209) \n",
      "==> Ensemble Score 0.16386\n",
      "# FOLD 2  (xgb 0.374) (xgb1 0.178) (xgb2 0.223) (xgb3 0.152) (xgb4 0.191) (xgb5 0.194) (xgb6 0.293) (xgb7 0.199) (xgb8 0.188) (lgb 0.208) (lgb1 0.285) (lgb2 0.286) (lgb3 0.098) (lgb4 0.241) (lgb5 0.067) \n",
      "==> Ensemble Score 0.08094\n",
      "# FOLD 3  (xgb 0.490) (xgb1 0.244) (xgb2 0.237) (xgb3 0.212) (xgb4 0.293) (xgb5 0.278) (xgb6 0.251) (xgb7 0.235) (xgb8 0.244) (lgb 0.224) (lgb1 0.405) (lgb2 0.421) (lgb3 0.159) (lgb4 0.210) (lgb5 0.252) \n",
      "==> Ensemble Score 0.17248\n",
      "# FOLD 4  (xgb 0.540) (xgb1 0.440) (xgb2 0.354) (xgb3 0.425) (xgb4 0.409) (xgb5 0.417) (xgb6 0.471) (xgb7 0.356) (xgb8 0.377) (lgb 0.381) (lgb1 0.358) (lgb2 0.401) (lgb3 0.396) (lgb4 0.373) (lgb5 0.315) \n",
      "==> Ensemble Score 0.29869\n",
      "# FOLD 5  (xgb 0.368) (xgb1 0.275) (xgb2 0.281) (xgb3 0.277) (xgb4 0.296) (xgb5 0.188) (xgb6 0.260) (xgb7 0.377) (xgb8 0.278) (lgb 0.338) (lgb1 0.276) (lgb2 0.304) (lgb3 0.308) (lgb4 0.284) (lgb5 0.275) \n",
      "==> Ensemble Score 0.18929\n",
      "# FOLD 6  (xgb 0.344) (xgb1 0.182) (xgb2 0.168) (xgb3 0.090) (xgb4 0.156) (xgb5 0.162) (xgb6 0.206) (xgb7 0.134) (xgb8 0.147) (lgb 0.144) (lgb1 0.208) (lgb2 0.211) (lgb3 0.072) (lgb4 0.058) (lgb5 0.165) \n",
      "==> Ensemble Score 0.06630\n",
      "# FOLD 7  (xgb 0.335) (xgb1 0.221) (xgb2 0.259) (xgb3 0.207) (xgb4 0.197) (xgb5 0.254) (xgb6 0.302) (xgb7 0.316) (xgb8 0.304) (lgb 0.251) (lgb1 0.288) (lgb2 0.255) (lgb3 0.247) (lgb4 0.309) (lgb5 0.260) \n",
      "==> Ensemble Score 0.20417\n",
      "# FOLD 8  (xgb 0.388) (xgb1 0.429) (xgb2 0.426) (xgb3 0.452) (xgb4 0.431) (xgb5 0.492) (xgb6 0.409) (xgb7 0.462) (xgb8 0.365) (lgb 0.398) (lgb1 0.394) (lgb2 0.462) (lgb3 0.390) (lgb4 0.403) (lgb5 0.425) \n",
      "==> Ensemble Score 0.35416\n",
      "# FOLD 9  (xgb 0.220) (xgb1 0.121) (xgb2 0.141) (xgb3 0.112) (xgb4 0.118) (xgb5 0.080) (xgb6 0.161) (xgb7 0.139) (xgb8 0.095) (lgb 0.138) (lgb1 0.146) (lgb2 0.151) (lgb3 0.223) (lgb4 0.177) (lgb5 0.047) \n",
      "==> Ensemble Score 0.05939\n",
      "# FOLD 10  (xgb 0.454) (xgb1 0.145) (xgb2 0.144) (xgb3 0.102) (xgb4 0.110) (xgb5 0.116) (xgb6 0.137) (xgb7 0.088) (xgb8 0.112) (lgb 0.146) (lgb1 0.248) (lgb2 0.257) (lgb3 0.088) (lgb4 0.087) (lgb5 0.171) \n",
      "==> Ensemble Score 0.07752\n",
      "\n",
      "#### Bag/SEED no. 20\n",
      "# FOLD 1  (xgb 0.381) (xgb1 0.147) (xgb2 0.168) (xgb3 0.192) (xgb4 0.181) (xgb5 0.180) (xgb6 0.156) (xgb7 0.110) (xgb8 0.171) (lgb 0.150) (lgb1 0.233) (lgb2 0.254) (lgb3 0.139) (lgb4 0.090) (lgb5 0.157) \n",
      "==> Ensemble Score 0.09414\n",
      "# FOLD 2  (xgb 0.441) (xgb1 0.236) (xgb2 0.240) (xgb3 0.214) (xgb4 0.225) (xgb5 0.248) (xgb6 0.346) (xgb7 0.303) (xgb8 0.252) (lgb 0.289) (lgb1 0.316) (lgb2 0.349) (lgb3 0.292) (lgb4 0.277) (lgb5 0.246) \n",
      "==> Ensemble Score 0.20541\n",
      "# FOLD 3  (xgb 0.336) (xgb1 0.258) (xgb2 0.283) (xgb3 0.272) (xgb4 0.259) (xgb5 0.340) (xgb6 0.312) (xgb7 0.287) (xgb8 0.228) (lgb 0.273) (lgb1 0.132) (lgb2 0.148) (lgb3 0.234) (lgb4 0.236) (lgb5 0.180) \n",
      "==> Ensemble Score 0.13023\n",
      "# FOLD 4  (xgb 0.335) (xgb1 0.194) (xgb2 0.203) (xgb3 0.229) (xgb4 0.177) (xgb5 0.198) (xgb6 0.226) (xgb7 0.244) (xgb8 0.242) (lgb 0.211) (lgb1 0.247) (lgb2 0.264) (lgb3 0.156) (lgb4 0.193) (lgb5 0.246) \n",
      "==> Ensemble Score 0.15721\n",
      "# FOLD 5  (xgb 0.274) (xgb1 0.140) (xgb2 0.143) (xgb3 0.130) (xgb4 0.097) (xgb5 0.106) (xgb6 0.102) (xgb7 0.075) (xgb8 0.098) (lgb 0.120) (lgb1 0.187) (lgb2 0.213) (lgb3 0.049) (lgb4 0.059) (lgb5 0.102) \n",
      "==> Ensemble Score 0.06268\n",
      "# FOLD 6  (xgb 0.408) (xgb1 0.195) (xgb2 0.214) (xgb3 0.203) (xgb4 0.223) (xgb5 0.266) (xgb6 0.252) (xgb7 0.212) (xgb8 0.244) (lgb 0.241) (lgb1 0.278) (lgb2 0.344) (lgb3 0.272) (lgb4 0.274) (lgb5 0.262) \n",
      "==> Ensemble Score 0.18890\n",
      "# FOLD 7  (xgb 0.457) (xgb1 0.369) (xgb2 0.356) (xgb3 0.398) (xgb4 0.345) (xgb5 0.341) (xgb6 0.401) (xgb7 0.461) (xgb8 0.330) (lgb 0.412) (lgb1 0.288) (lgb2 0.285) (lgb3 0.433) (lgb4 0.434) (lgb5 0.318) \n",
      "==> Ensemble Score 0.27465\n",
      "# FOLD 8  (xgb 0.354) (xgb1 0.180) (xgb2 0.175) (xgb3 0.117) (xgb4 0.159) (xgb5 0.400) (xgb6 0.185) (xgb7 0.203) (xgb8 0.192) (lgb 0.190) (lgb1 0.271) (lgb2 0.368) (lgb3 0.164) (lgb4 0.219) (lgb5 0.208) \n",
      "==> Ensemble Score 0.12014\n",
      "# FOLD 9  (xgb 0.488) (xgb1 0.343) (xgb2 0.374) (xgb3 0.358) (xgb4 0.329) (xgb5 0.386) (xgb6 0.318) (xgb7 0.481) (xgb8 0.352) (lgb 0.393) (lgb1 0.322) (lgb2 0.344) (lgb3 0.306) (lgb4 0.331) (lgb5 0.347) \n",
      "==> Ensemble Score 0.28337\n",
      "# FOLD 10  (xgb 0.279) (xgb1 0.207) (xgb2 0.236) (xgb3 0.212) (xgb4 0.204) (xgb5 0.154) (xgb6 0.182) (xgb7 0.168) (xgb8 0.154) (lgb 0.213) (lgb1 0.192) (lgb2 0.213) (lgb3 0.139) (lgb4 0.121) (lgb5 0.169) \n",
      "==> Ensemble Score 0.12164\n",
      "\n",
      "CPU times: user 7h 18min 51s, sys: 2h 45min 1s, total: 10h 3min 52s\n",
      "Wall time: 5h 23min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "kfold = 'skf'\n",
    "n_splits = 10\n",
    "n_reapts = 20\n",
    "random_state = 42\n",
    "n_estimators = 99999\n",
    "early_stopping_rounds = 200\n",
    "device = 'gpu'\n",
    "\n",
    "# Fix seed\n",
    "random.seed(random_state)\n",
    "random_state_list = random.sample(range(9999), n_reapts)\n",
    "bag = 1\n",
    "# Initialize an array for storing test predictions\n",
    "classifier = Classifier(n_estimators, device, random_state)\n",
    "test_predss = np.zeros((X_test.shape[0]))\n",
    "oof_predss = np.zeros((X_train.shape[0], n_reapts))\n",
    "\n",
    "ensemble_score, ensemble_score_ = [], []\n",
    "weights = []\n",
    "oof_each_predss = []\n",
    "\n",
    "oof_each_preds = np.zeros((X_train.shape[0], classifier.len_models))\n",
    "test_each_predss = []\n",
    "test_each_preds = np.zeros((X_test.shape[0], classifier.len_models))\n",
    "trained_models = {'xgb':[], 'cat':[]}\n",
    "score_dict = dict(zip(classifier.models_name, [[] for _ in range(classifier.len_models)]))\n",
    "\n",
    "splitter = Splitter(kfold=kfold, n_splits=n_splits, greeks=greeks.iloc[:,1:-1])\n",
    "for i, (X_train_, X_val, y_train_, y_val) in enumerate(splitter.split_data(X_train, y_train, random_state_list=random_state_list)):\n",
    "    \n",
    "    n = i % n_splits\n",
    "    m = i // n_splits  # to handled FOLD\n",
    "            \n",
    "    # Get a set of classifier models\n",
    "    classifier = Classifier(n_estimators, device, random_state_list[m])\n",
    "    models = classifier.models\n",
    "    \n",
    "    # Initialize lists to store oof and test predictions for each base model\n",
    "    oof_preds = []\n",
    "    test_preds = []\n",
    "    if n == 0: print('\\n#### Bag/SEED no.', bag); bag+=1\n",
    "    print('# FOLD',n+1, ' ', end = '')\n",
    "    # Loop over each base model and fit it to the training data, evaluate on validation data, and store predictions\n",
    "    for name, model in models.items():\n",
    "        if ('xgb' in name) or ('lgb' in name) or ('cat' in name):\n",
    "            # weight of sample\n",
    "            train_w0, train_w1 = calc_log_loss_weight(y_train_)\n",
    "            valid_w0, valid_w1 = calc_log_loss_weight(y_val)\n",
    "            w = y_train_.map({0: train_w0, 1: train_w1})\n",
    "            e = y_val.map({0: valid_w0, 1: valid_w1})\n",
    "                             \n",
    "            if 'xgb' in name:\n",
    "                model.fit(\n",
    "                    X_train_, y_train_, sample_weight  = w , \n",
    "                     eval_metric = [\"logloss\"],\n",
    "                    eval_set = [(X_val, y_val)], sample_weight_eval_set = [e] ,\n",
    "                    early_stopping_rounds = 200,\n",
    "                    verbose=0)\n",
    "            elif 'lgb' in name:\n",
    "                model.fit(\n",
    "                    X_train_, y_train_, sample_weight = w , \n",
    "                    eval_metric = 'logloss',\n",
    "                    eval_set = [(X_val, y_val)], eval_sample_weight = [e],\n",
    "                    early_stopping_rounds = 1000, verbose = 0)\n",
    "                \n",
    "            elif 'cat' in name:\n",
    "                model.fit(\n",
    "                    Pool(X_train_, y_train_, weight = w) , \n",
    "                    eval_set = Pool(X_val, y_val, weight = e),\n",
    "#                     early_stopping_rounds = 10, \n",
    "                    verbose = 0)\n",
    "        else:\n",
    "            model.fit(X_train_ , y_train_)\n",
    "            \n",
    "        if name in trained_models.keys():\n",
    "            trained_models[f'{name}'].append(deepcopy(model))\n",
    "        \n",
    "        test_pred = model.predict_proba(X_test)[:, 1].reshape(-1)\n",
    "        y_val_pred = model.predict_proba(X_val)[:, 1].reshape(-1)\n",
    "        \n",
    "        score = balanced_log_loss(y_val, y_val_pred)\n",
    "        score_dict[name].append(score)\n",
    "#         print('=> Fold',n,', ',end='')\n",
    "        print(f'({name} {score:.3f}) ' , end='')\n",
    "#         print(f'{score:.3f}', end = '')\n",
    "#         print(f'{name} [FOLD-{n} SEED-{random_state_list[m]}] BalancedLogLoss score: {score:.5f}')\n",
    "        \n",
    "        oof_preds.append(y_val_pred)\n",
    "        test_preds.append(test_pred)\n",
    "    \n",
    "    # Use Optuna to find the best ensemble weights\n",
    "    optweights = OptunaWeights(random_state=random_state_list[m])\n",
    "    y_val_pred = optweights.fit_predict(y_val.values, oof_preds)\n",
    "    \n",
    "    score = balanced_log_loss(y_val, y_val_pred)\n",
    "    score_ = roc_auc_score(y_val, y_val_pred)\n",
    "    print(f'\\n==> Ensemble Score {score:.5f}')\n",
    "    ensemble_score.append(score)\n",
    "    ensemble_score_.append(score_)\n",
    "    weights.append(optweights.weights)\n",
    "    \n",
    "    # Predict to X_test by the best ensemble weights\n",
    "    test_predss += optweights.predict(test_preds) / (n_splits * len(random_state_list))\n",
    "    \n",
    "    oof_predss[X_val.index, m] += optweights.predict(oof_preds)\n",
    "    oof_each_preds[X_val.index] = np.stack(oof_preds).T\n",
    "    test_each_preds += np.array(test_preds).T / n_splits\n",
    "    \n",
    "    # After End of FOLD LOOP in One Bag\n",
    "    if n == (n_splits - 1):\n",
    "        oof_each_predss.append(oof_each_preds)\n",
    "        oof_each_preds = np.zeros((X_train.shape[0], classifier.len_models))\n",
    "        test_each_predss.append(test_each_preds)\n",
    "        test_each_preds = np.zeros((X_test.shape[0], classifier.len_models))\n",
    "    gc.collect()\n",
    "\n",
    "oof_each_predss = np.mean(np.array(oof_each_predss), axis=0)\n",
    "\n",
    "test_each_predss = np.mean(np.array(test_each_predss), axis=0)\n",
    "oof_each_predss = np.concatenate([oof_each_predss, np.mean(oof_predss, axis=1).reshape(-1, 1)], axis=1)\n",
    "test_each_predss = np.concatenate([test_each_predss, test_predss.reshape(-1, 1)], axis=1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556e1a06",
   "metadata": {
    "papermill": {
     "duration": 0.268326,
     "end_time": "2023-08-07T13:32:00.093310",
     "exception": false,
     "start_time": "2023-08-07T13:31:59.824984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Stacking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de4b0cd7",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-08-07T13:32:00.719194Z",
     "iopub.status.busy": "2023-08-07T13:32:00.718813Z",
     "iopub.status.idle": "2023-08-07T13:32:01.761671Z",
     "shell.execute_reply": "2023-08-07T13:32:01.759484Z"
    },
    "papermill": {
     "duration": 1.405115,
     "end_time": "2023-08-07T13:32:01.763809",
     "exception": false,
     "start_time": "2023-08-07T13:32:00.358694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Stacking [FOLD-1 SEED-1824] BalancedLogLoss score 0.20231\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-1824] BalancedLogLoss score 0.11910\n",
      "--> Stacking [FOLD-3 SEED-1824] BalancedLogLoss score 0.15131\n",
      "--> Stacking [FOLD-4 SEED-1824] BalancedLogLoss score 0.15711\n",
      "--> Stacking [FOLD-5 SEED-1824] BalancedLogLoss score 0.17488\n",
      "--> Stacking [FOLD-6 SEED-1824] BalancedLogLoss score 0.19094\n",
      "--> Stacking [FOLD-7 SEED-1824] BalancedLogLoss score 0.11936\n",
      "--> Stacking [FOLD-8 SEED-1824] BalancedLogLoss score 0.31556\n",
      "--> Stacking [FOLD-9 SEED-1824] BalancedLogLoss score 0.09787\n",
      "--> Stacking [FOLD-10 SEED-1824] BalancedLogLoss score 0.32088\n",
      "--> Stacking [FOLD-1 SEED-409] BalancedLogLoss score 0.21146\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-409] BalancedLogLoss score 0.11590\n",
      "--> Stacking [FOLD-3 SEED-409] BalancedLogLoss score 0.14135\n",
      "--> Stacking [FOLD-4 SEED-409] BalancedLogLoss score 0.25416\n",
      "--> Stacking [FOLD-5 SEED-409] BalancedLogLoss score 0.21190\n",
      "--> Stacking [FOLD-6 SEED-409] BalancedLogLoss score 0.23664\n",
      "--> Stacking [FOLD-7 SEED-409] BalancedLogLoss score 0.29167\n",
      "--> Stacking [FOLD-8 SEED-409] BalancedLogLoss score 0.09632\n",
      "--> Stacking [FOLD-9 SEED-409] BalancedLogLoss score 0.10364\n",
      "--> Stacking [FOLD-10 SEED-409] BalancedLogLoss score 0.17250\n",
      "--> Stacking [FOLD-1 SEED-4506] BalancedLogLoss score 0.22103\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-4506] BalancedLogLoss score 0.28802\n",
      "--> Stacking [FOLD-3 SEED-4506] BalancedLogLoss score 0.16023\n",
      "--> Stacking [FOLD-4 SEED-4506] BalancedLogLoss score 0.21900\n",
      "--> Stacking [FOLD-5 SEED-4506] BalancedLogLoss score 0.13118\n",
      "--> Stacking [FOLD-6 SEED-4506] BalancedLogLoss score 0.13245\n",
      "--> Stacking [FOLD-7 SEED-4506] BalancedLogLoss score 0.12421\n",
      "--> Stacking [FOLD-8 SEED-4506] BalancedLogLoss score 0.15091\n",
      "--> Stacking [FOLD-9 SEED-4506] BalancedLogLoss score 0.15940\n",
      "--> Stacking [FOLD-10 SEED-4506] BalancedLogLoss score 0.20647\n",
      "--> Stacking [FOLD-1 SEED-4012] BalancedLogLoss score 0.20614\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-4012] BalancedLogLoss score 0.20597\n",
      "--> Stacking [FOLD-3 SEED-4012] BalancedLogLoss score 0.11582\n",
      "--> Stacking [FOLD-4 SEED-4012] BalancedLogLoss score 0.37908\n",
      "--> Stacking [FOLD-5 SEED-4012] BalancedLogLoss score 0.19903\n",
      "--> Stacking [FOLD-6 SEED-4012] BalancedLogLoss score 0.12198\n",
      "--> Stacking [FOLD-7 SEED-4012] BalancedLogLoss score 0.12717\n",
      "--> Stacking [FOLD-8 SEED-4012] BalancedLogLoss score 0.15800\n",
      "--> Stacking [FOLD-9 SEED-4012] BalancedLogLoss score 0.17711\n",
      "--> Stacking [FOLD-10 SEED-4012] BalancedLogLoss score 0.13591\n",
      "--> Stacking [FOLD-1 SEED-3657] BalancedLogLoss score 0.12678\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-3657] BalancedLogLoss score 0.43011\n",
      "--> Stacking [FOLD-3 SEED-3657] BalancedLogLoss score 0.11539\n",
      "--> Stacking [FOLD-4 SEED-3657] BalancedLogLoss score 0.17585\n",
      "--> Stacking [FOLD-5 SEED-3657] BalancedLogLoss score 0.14460\n",
      "--> Stacking [FOLD-6 SEED-3657] BalancedLogLoss score 0.24399\n",
      "--> Stacking [FOLD-7 SEED-3657] BalancedLogLoss score 0.12448\n",
      "--> Stacking [FOLD-8 SEED-3657] BalancedLogLoss score 0.14552\n",
      "--> Stacking [FOLD-9 SEED-3657] BalancedLogLoss score 0.19976\n",
      "--> Stacking [FOLD-10 SEED-3657] BalancedLogLoss score 0.12503\n",
      "--> Stacking [FOLD-1 SEED-2286] BalancedLogLoss score 0.15602\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-2286] BalancedLogLoss score 0.13098\n",
      "--> Stacking [FOLD-3 SEED-2286] BalancedLogLoss score 0.22342\n",
      "--> Stacking [FOLD-4 SEED-2286] BalancedLogLoss score 0.12918\n",
      "--> Stacking [FOLD-5 SEED-2286] BalancedLogLoss score 0.25544\n",
      "--> Stacking [FOLD-6 SEED-2286] BalancedLogLoss score 0.17352\n",
      "--> Stacking [FOLD-7 SEED-2286] BalancedLogLoss score 0.12008\n",
      "--> Stacking [FOLD-8 SEED-2286] BalancedLogLoss score 0.14513\n",
      "--> Stacking [FOLD-9 SEED-2286] BalancedLogLoss score 0.23670\n",
      "--> Stacking [FOLD-10 SEED-2286] BalancedLogLoss score 0.23278\n",
      "--> Stacking [FOLD-1 SEED-1679] BalancedLogLoss score 0.17585\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-1679] BalancedLogLoss score 0.18116\n",
      "--> Stacking [FOLD-3 SEED-1679] BalancedLogLoss score 0.17419\n",
      "--> Stacking [FOLD-4 SEED-1679] BalancedLogLoss score 0.11778\n",
      "--> Stacking [FOLD-5 SEED-1679] BalancedLogLoss score 0.36024\n",
      "--> Stacking [FOLD-6 SEED-1679] BalancedLogLoss score 0.12962\n",
      "--> Stacking [FOLD-7 SEED-1679] BalancedLogLoss score 0.23295\n",
      "--> Stacking [FOLD-8 SEED-1679] BalancedLogLoss score 0.11939\n",
      "--> Stacking [FOLD-9 SEED-1679] BalancedLogLoss score 0.10543\n",
      "--> Stacking [FOLD-10 SEED-1679] BalancedLogLoss score 0.25049\n",
      "--> Stacking [FOLD-1 SEED-8935] BalancedLogLoss score 0.22923\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-8935] BalancedLogLoss score 0.11786\n",
      "--> Stacking [FOLD-3 SEED-8935] BalancedLogLoss score 0.13840\n",
      "--> Stacking [FOLD-4 SEED-8935] BalancedLogLoss score 0.11976\n",
      "--> Stacking [FOLD-5 SEED-8935] BalancedLogLoss score 0.36575\n",
      "--> Stacking [FOLD-6 SEED-8935] BalancedLogLoss score 0.19278\n",
      "--> Stacking [FOLD-7 SEED-8935] BalancedLogLoss score 0.18537\n",
      "--> Stacking [FOLD-8 SEED-8935] BalancedLogLoss score 0.15533\n",
      "--> Stacking [FOLD-9 SEED-8935] BalancedLogLoss score 0.11346\n",
      "--> Stacking [FOLD-10 SEED-8935] BalancedLogLoss score 0.18877\n",
      "--> Stacking [FOLD-1 SEED-1424] BalancedLogLoss score 0.29193\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-1424] BalancedLogLoss score 0.14079\n",
      "--> Stacking [FOLD-3 SEED-1424] BalancedLogLoss score 0.09053\n",
      "--> Stacking [FOLD-4 SEED-1424] BalancedLogLoss score 0.40375\n",
      "--> Stacking [FOLD-5 SEED-1424] BalancedLogLoss score 0.17707\n",
      "--> Stacking [FOLD-6 SEED-1424] BalancedLogLoss score 0.12099\n",
      "--> Stacking [FOLD-7 SEED-1424] BalancedLogLoss score 0.08951\n",
      "--> Stacking [FOLD-8 SEED-1424] BalancedLogLoss score 0.10993\n",
      "--> Stacking [FOLD-9 SEED-1424] BalancedLogLoss score 0.16885\n",
      "--> Stacking [FOLD-10 SEED-1424] BalancedLogLoss score 0.23184\n",
      "--> Stacking [FOLD-1 SEED-9674] BalancedLogLoss score 0.18846\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-9674] BalancedLogLoss score 0.11442\n",
      "--> Stacking [FOLD-3 SEED-9674] BalancedLogLoss score 0.16812\n",
      "--> Stacking [FOLD-4 SEED-9674] BalancedLogLoss score 0.17670\n",
      "--> Stacking [FOLD-5 SEED-9674] BalancedLogLoss score 0.15340\n",
      "--> Stacking [FOLD-6 SEED-9674] BalancedLogLoss score 0.16234\n",
      "--> Stacking [FOLD-7 SEED-9674] BalancedLogLoss score 0.13297\n",
      "--> Stacking [FOLD-8 SEED-9674] BalancedLogLoss score 0.27258\n",
      "--> Stacking [FOLD-9 SEED-9674] BalancedLogLoss score 0.15462\n",
      "--> Stacking [FOLD-10 SEED-9674] BalancedLogLoss score 0.28316\n",
      "--> Stacking [FOLD-1 SEED-6912] BalancedLogLoss score 0.35019\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-6912] BalancedLogLoss score 0.17088\n",
      "--> Stacking [FOLD-3 SEED-6912] BalancedLogLoss score 0.13770\n",
      "--> Stacking [FOLD-4 SEED-6912] BalancedLogLoss score 0.13738\n",
      "--> Stacking [FOLD-5 SEED-6912] BalancedLogLoss score 0.08863\n",
      "--> Stacking [FOLD-6 SEED-6912] BalancedLogLoss score 0.19814\n",
      "--> Stacking [FOLD-7 SEED-6912] BalancedLogLoss score 0.21532\n",
      "--> Stacking [FOLD-8 SEED-6912] BalancedLogLoss score 0.17272\n",
      "--> Stacking [FOLD-9 SEED-6912] BalancedLogLoss score 0.13656\n",
      "--> Stacking [FOLD-10 SEED-6912] BalancedLogLoss score 0.19626\n",
      "--> Stacking [FOLD-1 SEED-520] BalancedLogLoss score 0.22078\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-520] BalancedLogLoss score 0.10484\n",
      "--> Stacking [FOLD-3 SEED-520] BalancedLogLoss score 0.26610\n",
      "--> Stacking [FOLD-4 SEED-520] BalancedLogLoss score 0.17219\n",
      "--> Stacking [FOLD-5 SEED-520] BalancedLogLoss score 0.10894\n",
      "--> Stacking [FOLD-6 SEED-520] BalancedLogLoss score 0.22849\n",
      "--> Stacking [FOLD-7 SEED-520] BalancedLogLoss score 0.09611\n",
      "--> Stacking [FOLD-8 SEED-520] BalancedLogLoss score 0.28010\n",
      "--> Stacking [FOLD-9 SEED-520] BalancedLogLoss score 0.13947\n",
      "--> Stacking [FOLD-10 SEED-520] BalancedLogLoss score 0.20741\n",
      "--> Stacking [FOLD-1 SEED-488] BalancedLogLoss score 0.13409\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-488] BalancedLogLoss score 0.17827\n",
      "--> Stacking [FOLD-3 SEED-488] BalancedLogLoss score 0.28542\n",
      "--> Stacking [FOLD-4 SEED-488] BalancedLogLoss score 0.17324\n",
      "--> Stacking [FOLD-5 SEED-488] BalancedLogLoss score 0.11405\n",
      "--> Stacking [FOLD-6 SEED-488] BalancedLogLoss score 0.26284\n",
      "--> Stacking [FOLD-7 SEED-488] BalancedLogLoss score 0.25113\n",
      "--> Stacking [FOLD-8 SEED-488] BalancedLogLoss score 0.10947\n",
      "--> Stacking [FOLD-9 SEED-488] BalancedLogLoss score 0.20038\n",
      "--> Stacking [FOLD-10 SEED-488] BalancedLogLoss score 0.10828\n",
      "--> Stacking [FOLD-1 SEED-1535] BalancedLogLoss score 0.11187\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-1535] BalancedLogLoss score 0.19259\n",
      "--> Stacking [FOLD-3 SEED-1535] BalancedLogLoss score 0.43052\n",
      "--> Stacking [FOLD-4 SEED-1535] BalancedLogLoss score 0.11346\n",
      "--> Stacking [FOLD-5 SEED-1535] BalancedLogLoss score 0.19362\n",
      "--> Stacking [FOLD-6 SEED-1535] BalancedLogLoss score 0.14576\n",
      "--> Stacking [FOLD-7 SEED-1535] BalancedLogLoss score 0.14279\n",
      "--> Stacking [FOLD-8 SEED-1535] BalancedLogLoss score 0.23427\n",
      "--> Stacking [FOLD-9 SEED-1535] BalancedLogLoss score 0.10602\n",
      "--> Stacking [FOLD-10 SEED-1535] BalancedLogLoss score 0.13133\n",
      "--> Stacking [FOLD-1 SEED-3582] BalancedLogLoss score 0.28373\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-3582] BalancedLogLoss score 0.12204\n",
      "--> Stacking [FOLD-3 SEED-3582] BalancedLogLoss score 0.10972\n",
      "--> Stacking [FOLD-4 SEED-3582] BalancedLogLoss score 0.16757\n",
      "--> Stacking [FOLD-5 SEED-3582] BalancedLogLoss score 0.17158\n",
      "--> Stacking [FOLD-6 SEED-3582] BalancedLogLoss score 0.10614\n",
      "--> Stacking [FOLD-7 SEED-3582] BalancedLogLoss score 0.23194\n",
      "--> Stacking [FOLD-8 SEED-3582] BalancedLogLoss score 0.28699\n",
      "--> Stacking [FOLD-9 SEED-3582] BalancedLogLoss score 0.23442\n",
      "--> Stacking [FOLD-10 SEED-3582] BalancedLogLoss score 0.09403\n",
      "--> Stacking [FOLD-1 SEED-3811] BalancedLogLoss score 0.13193\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-3811] BalancedLogLoss score 0.14995\n",
      "--> Stacking [FOLD-3 SEED-3811] BalancedLogLoss score 0.34389\n",
      "--> Stacking [FOLD-4 SEED-3811] BalancedLogLoss score 0.15626\n",
      "--> Stacking [FOLD-5 SEED-3811] BalancedLogLoss score 0.17588\n",
      "--> Stacking [FOLD-6 SEED-3811] BalancedLogLoss score 0.23173\n",
      "--> Stacking [FOLD-7 SEED-3811] BalancedLogLoss score 0.20263\n",
      "--> Stacking [FOLD-8 SEED-3811] BalancedLogLoss score 0.16830\n",
      "--> Stacking [FOLD-9 SEED-3811] BalancedLogLoss score 0.14829\n",
      "--> Stacking [FOLD-10 SEED-3811] BalancedLogLoss score 0.09408\n",
      "--> Stacking [FOLD-1 SEED-8279] BalancedLogLoss score 0.11154\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-8279] BalancedLogLoss score 0.10196\n",
      "--> Stacking [FOLD-3 SEED-8279] BalancedLogLoss score 0.19880\n",
      "--> Stacking [FOLD-4 SEED-8279] BalancedLogLoss score 0.32057\n",
      "--> Stacking [FOLD-5 SEED-8279] BalancedLogLoss score 0.11856\n",
      "--> Stacking [FOLD-6 SEED-8279] BalancedLogLoss score 0.17848\n",
      "--> Stacking [FOLD-7 SEED-8279] BalancedLogLoss score 0.37003\n",
      "--> Stacking [FOLD-8 SEED-8279] BalancedLogLoss score 0.13696\n",
      "--> Stacking [FOLD-9 SEED-8279] BalancedLogLoss score 0.11214\n",
      "--> Stacking [FOLD-10 SEED-8279] BalancedLogLoss score 0.15202\n",
      "--> Stacking [FOLD-1 SEED-9863] BalancedLogLoss score 0.31407\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-9863] BalancedLogLoss score 0.09783\n",
      "--> Stacking [FOLD-3 SEED-9863] BalancedLogLoss score 0.22476\n",
      "--> Stacking [FOLD-4 SEED-9863] BalancedLogLoss score 0.13373\n",
      "--> Stacking [FOLD-5 SEED-9863] BalancedLogLoss score 0.27534\n",
      "--> Stacking [FOLD-6 SEED-9863] BalancedLogLoss score 0.19767\n",
      "--> Stacking [FOLD-7 SEED-9863] BalancedLogLoss score 0.16107\n",
      "--> Stacking [FOLD-8 SEED-9863] BalancedLogLoss score 0.16576\n",
      "--> Stacking [FOLD-9 SEED-9863] BalancedLogLoss score 0.11274\n",
      "--> Stacking [FOLD-10 SEED-9863] BalancedLogLoss score 0.12909\n",
      "--> Stacking [FOLD-1 SEED-434] BalancedLogLoss score 0.16239\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-434] BalancedLogLoss score 0.16650\n",
      "--> Stacking [FOLD-3 SEED-434] BalancedLogLoss score 0.20025\n",
      "--> Stacking [FOLD-4 SEED-434] BalancedLogLoss score 0.21920\n",
      "--> Stacking [FOLD-5 SEED-434] BalancedLogLoss score 0.22569\n",
      "--> Stacking [FOLD-6 SEED-434] BalancedLogLoss score 0.12737\n",
      "--> Stacking [FOLD-7 SEED-434] BalancedLogLoss score 0.18446\n",
      "--> Stacking [FOLD-8 SEED-434] BalancedLogLoss score 0.28020\n",
      "--> Stacking [FOLD-9 SEED-434] BalancedLogLoss score 0.13422\n",
      "--> Stacking [FOLD-10 SEED-434] BalancedLogLoss score 0.12718\n",
      "--> Stacking [FOLD-1 SEED-9195] BalancedLogLoss score 0.11215\n",
      "\n",
      "--> Stacking [FOLD-2 SEED-9195] BalancedLogLoss score 0.20967\n",
      "--> Stacking [FOLD-3 SEED-9195] BalancedLogLoss score 0.15926\n",
      "--> Stacking [FOLD-4 SEED-9195] BalancedLogLoss score 0.17541\n",
      "--> Stacking [FOLD-5 SEED-9195] BalancedLogLoss score 0.09991\n",
      "--> Stacking [FOLD-6 SEED-9195] BalancedLogLoss score 0.20469\n",
      "--> Stacking [FOLD-7 SEED-9195] BalancedLogLoss score 0.34645\n",
      "--> Stacking [FOLD-8 SEED-9195] BalancedLogLoss score 0.14565\n",
      "--> Stacking [FOLD-9 SEED-9195] BalancedLogLoss score 0.22045\n",
      "--> Stacking [FOLD-10 SEED-9195] BalancedLogLoss score 0.16641\n",
      "CPU times: user 1.01 s, sys: 5.36 ms, total: 1.02 s\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "stack_test_predss = np.zeros((X_test.shape[0]))\n",
    "stack_scores = []\n",
    "stack_models = []\n",
    "\n",
    "splitter = Splitter(kfold = kfold, n_splits=n_splits, greeks = greeks.iloc[:,1:-1])\n",
    "for i, (X_train_, X_val, y_train_, y_val) in enumerate(splitter.split_data(oof_each_predss, y_train, random_state_list=random_state_list)):\n",
    "    n = i % n_splits\n",
    "    m = i // n_splits\n",
    "    \n",
    "#     model =  SVC(C=5, probability=True)\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    model.fit(X_train_ , y_train_)\n",
    "    \n",
    "    \n",
    "    y_val_m_pred = model.predict_proba(X_val)[:, 1]\n",
    "    test_pred = model.predict_proba(test_each_predss)[:, 1]\n",
    "    \n",
    "    score = balanced_log_loss(y_val, y_val_m_pred)\n",
    "    print(f'--> Stacking [FOLD-{n+1} SEED-{random_state_list[m]}] BalancedLogLoss score {score:.5f}')\n",
    "    if n ==0: print()\n",
    "    stack_scores.append(score)\n",
    "    stack_models.append(deepcopy(model))\n",
    "    stack_test_predss += test_pred / (n_splits * len(random_state_list))\n",
    "# Calculate the mean LogLoss score of the ensemble\n",
    "mean_score = np.mean(stack_scores)\n",
    "std_score = np.std(stack_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87437ed2",
   "metadata": {
    "papermill": {
     "duration": 0.265872,
     "end_time": "2023-08-07T13:32:02.298530",
     "exception": false,
     "start_time": "2023-08-07T13:32:02.032658",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## OverAll Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54e0d402",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-08-07T13:32:02.832349Z",
     "iopub.status.busy": "2023-08-07T13:32:02.831973Z",
     "iopub.status.idle": "2023-08-07T13:32:02.843125Z",
     "shell.execute_reply": "2023-08-07T13:32:02.842131Z"
    },
    "papermill": {
     "duration": 0.281855,
     "end_time": "2023-08-07T13:32:02.845185",
     "exception": false,
     "start_time": "2023-08-07T13:32:02.563330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble BalancedLogLoss score 0.16684 ± 0.08113\n",
      "--- Model Weights ---\n",
      "xgb: 0.04988 ± 0.17481\n",
      "xgb1: 0.06282 ± 0.18225\n",
      "xgb2: 0.03042 ± 0.12287\n",
      "xgb3: 0.19142 ± 0.33345\n",
      "xgb4: 0.09910 ± 0.24107\n",
      "xgb5: 0.29355 ± 0.38691\n",
      "xgb6: 0.06850 ± 0.19074\n",
      "xgb7: 0.22605 ± 0.34891\n",
      "xgb8: 0.18574 ± 0.32789\n",
      "lgb: 0.01922 ± 0.08344\n",
      "lgb1: 0.18785 ± 0.34407\n",
      "lgb2: 0.12981 ± 0.27848\n",
      "lgb3: 0.37969 ± 0.40891\n",
      "lgb4: 0.33180 ± 0.40811\n",
      "lgb5: 0.33981 ± 0.41874\n",
      "\n",
      "Stacking BalancedLogLoss score 0.18182 ± 0.07075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean LogLoss score of the ensemble\n",
    "mean_score = np.mean(ensemble_score)\n",
    "std_score = np.std(ensemble_score)\n",
    "print(f'Ensemble BalancedLogLoss score {mean_score:.5f} ± {std_score:.5f}')\n",
    "# Print the mean and standard deviation of the ensemble weights for each model\n",
    "print('--- Model Weights ---')\n",
    "mean_weights = np.mean(weights, axis=0)\n",
    "std_weights = np.std(weights, axis=0)\n",
    "for name, mean_weight, std_weight in zip(models.keys(), mean_weights, std_weights):\n",
    "    print(f'{name}: {mean_weight:.5f} ± {std_weight:.5f}')\n",
    "print('')\n",
    "\n",
    "# Calculate the mean LogLoss score of the ensemble\n",
    "mean_score = np.mean(stack_scores)\n",
    "std_score = np.std(stack_scores)\n",
    "print(f'Stacking BalancedLogLoss score {mean_score:.5f} ± {std_score:.5f}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e23c79a",
   "metadata": {
    "papermill": {
     "duration": 0.265368,
     "end_time": "2023-08-07T13:32:03.383164",
     "exception": false,
     "start_time": "2023-08-07T13:32:03.117796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scores for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee6bfcb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T13:32:03.922192Z",
     "iopub.status.busy": "2023-08-07T13:32:03.921690Z",
     "iopub.status.idle": "2023-08-07T13:32:03.927238Z",
     "shell.execute_reply": "2023-08-07T13:32:03.926293Z"
    },
    "papermill": {
     "duration": 0.275835,
     "end_time": "2023-08-07T13:32:03.929171",
     "exception": false,
     "start_time": "2023-08-07T13:32:03.653336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def plot_score_from_dict(score_dict, title='', ascending=True):\n",
    "    \n",
    "#     score_df = pd.melt(pd.DataFrame(score_dict))\n",
    "    \n",
    "#     score_df = score_df.sort_values('value', ascending=ascending)\n",
    "    \n",
    "#     plt.figure(figsize=(14, 8))\n",
    "#     sns.barplot(x='value', y='variable', data=score_df, palette='Blues_r', errorbar='sd')\n",
    "#     plt.xlabel(f'{title}', fontsize=14)\n",
    "#     plt.ylabel('')\n",
    "#     #plt.title(f'{title}', fontsize=18)\n",
    "#     plt.xticks(fontsize=12)\n",
    "#     plt.yticks(fontsize=12)\n",
    "#     plt.grid(True, axis='x')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# weight_dict = dict(zip(list(score_dict.keys()), np.array(weights).T.tolist()))\n",
    "# plot_score_from_dict(weight_dict, title='Model Weights', ascending=False)\n",
    "# normalize = [((weight - np.min(weight)) / (np.max(weight) - np.min(weight))).tolist() for weight in weights]\n",
    "# weight_dict = dict(zip(list(score_dict.keys()), np.array(normalize).T.tolist()))\n",
    "# plot_score_from_dict(weight_dict, title='Model Weights (Normalize 0 to 1)', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0fd50c1",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-08-07T13:32:04.460408Z",
     "iopub.status.busy": "2023-08-07T13:32:04.460010Z",
     "iopub.status.idle": "2023-08-07T13:32:04.464450Z",
     "shell.execute_reply": "2023-08-07T13:32:04.463391Z"
    },
    "papermill": {
     "duration": 0.27408,
     "end_time": "2023-08-07T13:32:04.467082",
     "exception": false,
     "start_time": "2023-08-07T13:32:04.193002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_score_from_dict(score_dict, title=f'BalancedLogLoss (n_splits:{n_splits})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebc3a5ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T13:32:05.004343Z",
     "iopub.status.busy": "2023-08-07T13:32:05.003926Z",
     "iopub.status.idle": "2023-08-07T13:32:05.008618Z",
     "shell.execute_reply": "2023-08-07T13:32:05.007617Z"
    },
    "papermill": {
     "duration": 0.272657,
     "end_time": "2023-08-07T13:32:05.010691",
     "exception": false,
     "start_time": "2023-08-07T13:32:04.738034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_score_from_dict(weight_dict, title='Model Weights (Normalize 0 to 1)', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f599b8d6",
   "metadata": {
    "papermill": {
     "duration": 0.265909,
     "end_time": "2023-08-07T13:32:05.541033",
     "exception": false,
     "start_time": "2023-08-07T13:32:05.275124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## PREDICT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "071e3aaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T13:32:06.070131Z",
     "iopub.status.busy": "2023-08-07T13:32:06.069761Z",
     "iopub.status.idle": "2023-08-07T13:32:06.074361Z",
     "shell.execute_reply": "2023-08-07T13:32:06.073425Z"
    },
    "papermill": {
     "duration": 0.274528,
     "end_time": "2023-08-07T13:32:06.076423",
     "exception": false,
     "start_time": "2023-08-07T13:32:05.801895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PREDICT_1 = test_predss\n",
    "PREDICT_2 = stack_test_predss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "313ad90c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T13:32:06.689997Z",
     "iopub.status.busy": "2023-08-07T13:32:06.689618Z",
     "iopub.status.idle": "2023-08-07T13:32:06.694015Z",
     "shell.execute_reply": "2023-08-07T13:32:06.693114Z"
    },
    "papermill": {
     "duration": 0.356265,
     "end_time": "2023-08-07T13:32:06.695940",
     "exception": false,
     "start_time": "2023-08-07T13:32:06.339675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preds = stack_test_predss\n",
    "# preds = test_predss * 0.50 + stack_test_predss * 0.50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb664154",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T13:32:07.231755Z",
     "iopub.status.busy": "2023-08-07T13:32:07.230670Z",
     "iopub.status.idle": "2023-08-07T13:32:07.235455Z",
     "shell.execute_reply": "2023-08-07T13:32:07.234437Z"
    },
    "papermill": {
     "duration": 0.274715,
     "end_time": "2023-08-07T13:32:07.237404",
     "exception": false,
     "start_time": "2023-08-07T13:32:06.962689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sub = pd.read_csv(os.path.join(filepath, 'sample_submission.csv'))\n",
    "# sub['class_1'] = preds\n",
    "# sub['class_0'] = 1 - preds\n",
    "# sub.to_csv('submission.csv', index=False)\n",
    "# sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08f1321",
   "metadata": {
    "papermill": {
     "duration": 0.267561,
     "end_time": "2023-08-07T13:32:07.768916",
     "exception": false,
     "start_time": "2023-08-07T13:32:07.501355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **NOTEBOOK NUMBER 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78469a16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T13:32:08.303505Z",
     "iopub.status.busy": "2023-08-07T13:32:08.303150Z",
     "iopub.status.idle": "2023-08-07T13:32:43.797454Z",
     "shell.execute_reply": "2023-08-07T13:32:43.796006Z"
    },
    "papermill": {
     "duration": 35.763553,
     "end_time": "2023-08-07T13:32:43.800329",
     "exception": false,
     "start_time": "2023-08-07T13:32:08.036776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q /kaggle/input/tabpfn-019-whl/tabpfn-0.1.9-py3-none-any.whl\n",
    "!mkdir /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff\n",
    "!cp /kaggle/input/tabpfn-019-whl/prior_diff_real_checkpoint_n_0_epoch_100.cpkt /opt/conda/lib/python3.10/site-packages/tabpfn/models_diff/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db183b8c",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-08-07T13:32:44.330446Z",
     "iopub.status.busy": "2023-08-07T13:32:44.330040Z",
     "iopub.status.idle": "2023-08-07T13:32:50.217768Z",
     "shell.execute_reply": "2023-08-07T13:32:50.216694Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 6.156385,
     "end_time": "2023-08-07T13:32:50.220546",
     "exception": false,
     "start_time": "2023-08-07T13:32:44.064161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import cudf\n",
    "from cuml.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import itertools\n",
    "\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor,  Pool\n",
    "import category_encoders as ce\n",
    "\n",
    "from tabpfn import TabPFNClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1db74598",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-08-07T13:32:50.764307Z",
     "iopub.status.busy": "2023-08-07T13:32:50.763407Z",
     "iopub.status.idle": "2023-08-07T13:32:50.775872Z",
     "shell.execute_reply": "2023-08-07T13:32:50.774829Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.283791,
     "end_time": "2023-08-07T13:32:50.778138",
     "exception": false,
     "start_time": "2023-08-07T13:32:50.494347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pond_logloss(ytrue, preds):\n",
    "    preds = np.clip(preds, 1e-15, 1-1e-15)\n",
    "    n0 = (ytrue==0).sum()\n",
    "    n1 = (ytrue==1).sum()\n",
    "    \n",
    "    v0 = -np.sum(np.log(1-preds[ytrue==0]))/2/n0\n",
    "    v1 = -np.sum(np.log(preds[ytrue==1]))/2/n1\n",
    "    \n",
    "    return v1+v0\n",
    "\n",
    "def lgb_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', pond_logloss(y_true, y_pred), False\n",
    "\n",
    "# https://www.kaggle.com/code/datafan07/icr-simple-eda-baseline\n",
    "def balance_logloss(y_true, y_pred):\n",
    "    \n",
    "    y_pred = np.stack([1-y_pred,y_pred]).T\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1-1e-15)\n",
    "    y_pred / np.sum(y_pred, axis=1)[:, None]\n",
    "    nc = np.bincount(y_true)\n",
    "    \n",
    "    logloss = (-1/nc[0]*(np.sum(np.where(y_true==0,1,0) * np.log(y_pred[:,0]))) - 1/nc[1]*(np.sum(np.where(y_true!=0,1,0) * np.log(y_pred[:,1])))) / 2\n",
    "    \n",
    "    return logloss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "489cb998",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-08-07T13:32:51.321690Z",
     "iopub.status.busy": "2023-08-07T13:32:51.321320Z",
     "iopub.status.idle": "2023-08-07T13:32:51.393947Z",
     "shell.execute_reply": "2023-08-07T13:32:51.392960Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.348569,
     "end_time": "2023-08-07T13:32:51.396663",
     "exception": false,
     "start_time": "2023-08-07T13:32:51.048094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape (617, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>BD</th>\n",
       "      <th>BN</th>\n",
       "      <th>BP</th>\n",
       "      <th>BQ</th>\n",
       "      <th>BR</th>\n",
       "      <th>BZ</th>\n",
       "      <th>CB</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>CF</th>\n",
       "      <th>CH</th>\n",
       "      <th>CL</th>\n",
       "      <th>CR</th>\n",
       "      <th>CS</th>\n",
       "      <th>CU</th>\n",
       "      <th>CW</th>\n",
       "      <th>DA</th>\n",
       "      <th>DE</th>\n",
       "      <th>DF</th>\n",
       "      <th>DH</th>\n",
       "      <th>DI</th>\n",
       "      <th>DL</th>\n",
       "      <th>DN</th>\n",
       "      <th>DU</th>\n",
       "      <th>DV</th>\n",
       "      <th>DY</th>\n",
       "      <th>EB</th>\n",
       "      <th>EE</th>\n",
       "      <th>EG</th>\n",
       "      <th>EH</th>\n",
       "      <th>EJ</th>\n",
       "      <th>EL</th>\n",
       "      <th>EP</th>\n",
       "      <th>EU</th>\n",
       "      <th>FC</th>\n",
       "      <th>FD</th>\n",
       "      <th>FE</th>\n",
       "      <th>FI</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000ff2bfdfe9</td>\n",
       "      <td>0.209377</td>\n",
       "      <td>3109.03329</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>22.394407</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>0.699861</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>9.812214</td>\n",
       "      <td>5.555634</td>\n",
       "      <td>4126.58731</td>\n",
       "      <td>22.5984</td>\n",
       "      <td>175.638726</td>\n",
       "      <td>152.707705</td>\n",
       "      <td>823.928241</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>47.223358</td>\n",
       "      <td>0.563481</td>\n",
       "      <td>23.387600</td>\n",
       "      <td>4.851915</td>\n",
       "      <td>0.023482</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.069225</td>\n",
       "      <td>13.784111</td>\n",
       "      <td>1.302012</td>\n",
       "      <td>36.205956</td>\n",
       "      <td>69.08340</td>\n",
       "      <td>295.570575</td>\n",
       "      <td>0.23868</td>\n",
       "      <td>0.284232</td>\n",
       "      <td>89.245560</td>\n",
       "      <td>84.31664</td>\n",
       "      <td>29.657104</td>\n",
       "      <td>5.310690</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>23.187704</td>\n",
       "      <td>7.294176</td>\n",
       "      <td>1.987283</td>\n",
       "      <td>1433.166750</td>\n",
       "      <td>0.949104</td>\n",
       "      <td>B</td>\n",
       "      <td>30.879420</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>3.828384</td>\n",
       "      <td>13.394640</td>\n",
       "      <td>10.265073</td>\n",
       "      <td>9028.291921</td>\n",
       "      <td>3.583450</td>\n",
       "      <td>7.298162</td>\n",
       "      <td>1.73855</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>11.339138</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>2003.810319</td>\n",
       "      <td>22.136229</td>\n",
       "      <td>69.834944</td>\n",
       "      <td>0.120343</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007255e47698</td>\n",
       "      <td>0.145282</td>\n",
       "      <td>978.76416</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>36.968889</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.632190</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>13.517790</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5496.92824</td>\n",
       "      <td>19.4205</td>\n",
       "      <td>155.868030</td>\n",
       "      <td>14.754720</td>\n",
       "      <td>51.216883</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>30.284345</td>\n",
       "      <td>0.484710</td>\n",
       "      <td>50.628208</td>\n",
       "      <td>6.085041</td>\n",
       "      <td>0.031442</td>\n",
       "      <td>1.113875</td>\n",
       "      <td>1.117800</td>\n",
       "      <td>28.310953</td>\n",
       "      <td>1.357182</td>\n",
       "      <td>37.476568</td>\n",
       "      <td>70.79836</td>\n",
       "      <td>178.553100</td>\n",
       "      <td>0.23868</td>\n",
       "      <td>0.363489</td>\n",
       "      <td>110.581815</td>\n",
       "      <td>75.74548</td>\n",
       "      <td>37.532000</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>17.222328</td>\n",
       "      <td>4.926396</td>\n",
       "      <td>0.858603</td>\n",
       "      <td>1111.287150</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>A</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>95.415086</td>\n",
       "      <td>52.260480</td>\n",
       "      <td>17.175984</td>\n",
       "      <td>0.296850</td>\n",
       "      <td>6785.003474</td>\n",
       "      <td>10.358927</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.568932</td>\n",
       "      <td>9.292698</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>27981.562750</td>\n",
       "      <td>29.135430</td>\n",
       "      <td>32.131996</td>\n",
       "      <td>21.978000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>013f2bd269f5</td>\n",
       "      <td>0.470030</td>\n",
       "      <td>2635.10654</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>32.360553</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>6.732840</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>12.824570</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5135.78024</td>\n",
       "      <td>26.4825</td>\n",
       "      <td>128.988531</td>\n",
       "      <td>219.320160</td>\n",
       "      <td>482.141594</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>32.563713</td>\n",
       "      <td>0.495852</td>\n",
       "      <td>85.955376</td>\n",
       "      <td>5.376488</td>\n",
       "      <td>0.036218</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.700350</td>\n",
       "      <td>39.364743</td>\n",
       "      <td>1.009611</td>\n",
       "      <td>21.459644</td>\n",
       "      <td>70.81970</td>\n",
       "      <td>321.426625</td>\n",
       "      <td>0.23868</td>\n",
       "      <td>0.210441</td>\n",
       "      <td>120.056438</td>\n",
       "      <td>65.46984</td>\n",
       "      <td>28.053464</td>\n",
       "      <td>1.289739</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>36.861352</td>\n",
       "      <td>7.813674</td>\n",
       "      <td>8.146651</td>\n",
       "      <td>1494.076488</td>\n",
       "      <td>0.377208</td>\n",
       "      <td>B</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>5.390628</td>\n",
       "      <td>224.207424</td>\n",
       "      <td>8.745201</td>\n",
       "      <td>8338.906181</td>\n",
       "      <td>11.626917</td>\n",
       "      <td>7.709560</td>\n",
       "      <td>0.97556</td>\n",
       "      <td>1.198821</td>\n",
       "      <td>37.077772</td>\n",
       "      <td>88.609437</td>\n",
       "      <td>13676.957810</td>\n",
       "      <td>28.022851</td>\n",
       "      <td>35.192676</td>\n",
       "      <td>0.196941</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>043ac50845d5</td>\n",
       "      <td>0.252107</td>\n",
       "      <td>3819.65177</td>\n",
       "      <td>120.201618</td>\n",
       "      <td>77.112203</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.685344</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>11.053708</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>4169.67738</td>\n",
       "      <td>23.6577</td>\n",
       "      <td>237.282264</td>\n",
       "      <td>11.050410</td>\n",
       "      <td>661.518640</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>15.201914</td>\n",
       "      <td>0.717882</td>\n",
       "      <td>88.159360</td>\n",
       "      <td>2.347652</td>\n",
       "      <td>0.029054</td>\n",
       "      <td>1.400300</td>\n",
       "      <td>0.636075</td>\n",
       "      <td>41.116960</td>\n",
       "      <td>0.722727</td>\n",
       "      <td>21.530392</td>\n",
       "      <td>47.27586</td>\n",
       "      <td>196.607985</td>\n",
       "      <td>0.23868</td>\n",
       "      <td>0.292431</td>\n",
       "      <td>139.824570</td>\n",
       "      <td>71.57120</td>\n",
       "      <td>24.354856</td>\n",
       "      <td>2.655345</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>52.003884</td>\n",
       "      <td>7.386060</td>\n",
       "      <td>3.813326</td>\n",
       "      <td>15691.552180</td>\n",
       "      <td>0.614484</td>\n",
       "      <td>B</td>\n",
       "      <td>31.674357</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>31.323372</td>\n",
       "      <td>59.301984</td>\n",
       "      <td>7.884336</td>\n",
       "      <td>10965.766040</td>\n",
       "      <td>14.852022</td>\n",
       "      <td>6.122162</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.284466</td>\n",
       "      <td>18.529584</td>\n",
       "      <td>82.416803</td>\n",
       "      <td>2094.262452</td>\n",
       "      <td>39.948656</td>\n",
       "      <td>90.493248</td>\n",
       "      <td>0.155829</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>044fb8a146ec</td>\n",
       "      <td>0.380297</td>\n",
       "      <td>3733.04844</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>14.103738</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.942255</td>\n",
       "      <td>0.054810</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>102.151980</td>\n",
       "      <td>5728.73412</td>\n",
       "      <td>24.0108</td>\n",
       "      <td>324.546318</td>\n",
       "      <td>149.717165</td>\n",
       "      <td>6074.859475</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>82.213495</td>\n",
       "      <td>0.536467</td>\n",
       "      <td>72.644264</td>\n",
       "      <td>30.537722</td>\n",
       "      <td>0.025472</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.693150</td>\n",
       "      <td>31.724726</td>\n",
       "      <td>0.827550</td>\n",
       "      <td>34.415360</td>\n",
       "      <td>74.06532</td>\n",
       "      <td>200.178160</td>\n",
       "      <td>0.23868</td>\n",
       "      <td>0.207708</td>\n",
       "      <td>97.920120</td>\n",
       "      <td>52.83888</td>\n",
       "      <td>26.019912</td>\n",
       "      <td>1.144902</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>9.064856</td>\n",
       "      <td>7.350720</td>\n",
       "      <td>3.490846</td>\n",
       "      <td>1403.656300</td>\n",
       "      <td>0.164268</td>\n",
       "      <td>B</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>91.994825</td>\n",
       "      <td>51.141336</td>\n",
       "      <td>29.102640</td>\n",
       "      <td>4.274640</td>\n",
       "      <td>16198.049590</td>\n",
       "      <td>13.666727</td>\n",
       "      <td>8.153058</td>\n",
       "      <td>48.50134</td>\n",
       "      <td>0.121914</td>\n",
       "      <td>16.408728</td>\n",
       "      <td>146.109943</td>\n",
       "      <td>8524.370502</td>\n",
       "      <td>45.381316</td>\n",
       "      <td>36.262628</td>\n",
       "      <td>0.096614</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id        AB          AF          AH         AM        AR  \\\n",
       "0  000ff2bfdfe9  0.209377  3109.03329   85.200147  22.394407  8.138688   \n",
       "1  007255e47698  0.145282   978.76416   85.200147  36.968889  8.138688   \n",
       "2  013f2bd269f5  0.470030  2635.10654   85.200147  32.360553  8.138688   \n",
       "3  043ac50845d5  0.252107  3819.65177  120.201618  77.112203  8.138688   \n",
       "4  044fb8a146ec  0.380297  3733.04844   85.200147  14.103738  8.138688   \n",
       "\n",
       "         AX        AY         AZ          BC         BD        BN          BP  \\\n",
       "0  0.699861  0.025578   9.812214    5.555634  4126.58731  22.5984  175.638726   \n",
       "1  3.632190  0.025578  13.517790    1.229900  5496.92824  19.4205  155.868030   \n",
       "2  6.732840  0.025578  12.824570    1.229900  5135.78024  26.4825  128.988531   \n",
       "3  3.685344  0.025578  11.053708    1.229900  4169.67738  23.6577  237.282264   \n",
       "4  3.942255  0.054810   3.396778  102.151980  5728.73412  24.0108  324.546318   \n",
       "\n",
       "           BQ           BR          BZ         CB        CC        CD   \\\n",
       "0  152.707705   823.928241  257.432377  47.223358  0.563481  23.387600   \n",
       "1   14.754720    51.216883  257.432377  30.284345  0.484710  50.628208   \n",
       "2  219.320160   482.141594  257.432377  32.563713  0.495852  85.955376   \n",
       "3   11.050410   661.518640  257.432377  15.201914  0.717882  88.159360   \n",
       "4  149.717165  6074.859475  257.432377  82.213495  0.536467  72.644264   \n",
       "\n",
       "          CF        CH        CL        CR         CS        CU        CW   \\\n",
       "0   4.851915  0.023482  1.050225  0.069225  13.784111  1.302012  36.205956   \n",
       "1   6.085041  0.031442  1.113875  1.117800  28.310953  1.357182  37.476568   \n",
       "2   5.376488  0.036218  1.050225  0.700350  39.364743  1.009611  21.459644   \n",
       "3   2.347652  0.029054  1.400300  0.636075  41.116960  0.722727  21.530392   \n",
       "4  30.537722  0.025472  1.050225  0.693150  31.724726  0.827550  34.415360   \n",
       "\n",
       "         DA          DE       DF        DH          DI        DL         DN  \\\n",
       "0  69.08340  295.570575  0.23868  0.284232   89.245560  84.31664  29.657104   \n",
       "1  70.79836  178.553100  0.23868  0.363489  110.581815  75.74548  37.532000   \n",
       "2  70.81970  321.426625  0.23868  0.210441  120.056438  65.46984  28.053464   \n",
       "3  47.27586  196.607985  0.23868  0.292431  139.824570  71.57120  24.354856   \n",
       "4  74.06532  200.178160  0.23868  0.207708   97.920120  52.83888  26.019912   \n",
       "\n",
       "         DU       DV         DY        EB        EE            EG        EH  \\\n",
       "0  5.310690  1.74307  23.187704  7.294176  1.987283   1433.166750  0.949104   \n",
       "1  0.005518  1.74307  17.222328  4.926396  0.858603   1111.287150  0.003042   \n",
       "2  1.289739  1.74307  36.861352  7.813674  8.146651   1494.076488  0.377208   \n",
       "3  2.655345  1.74307  52.003884  7.386060  3.813326  15691.552180  0.614484   \n",
       "4  1.144902  1.74307   9.064856  7.350720  3.490846   1403.656300  0.164268   \n",
       "\n",
       "  EJ          EL         EP         EU          FC        FD             FE  \\\n",
       "0  B   30.879420  78.526968   3.828384   13.394640  10.265073   9028.291921   \n",
       "1  A  109.125159  95.415086  52.260480   17.175984   0.296850   6785.003474   \n",
       "2  B  109.125159  78.526968   5.390628  224.207424   8.745201   8338.906181   \n",
       "3  B   31.674357  78.526968  31.323372   59.301984   7.884336  10965.766040   \n",
       "4  B  109.125159  91.994825  51.141336   29.102640   4.274640  16198.049590   \n",
       "\n",
       "          FI        FL        FR        FS         GB          GE  \\\n",
       "0   3.583450  7.298162   1.73855  0.094822  11.339138   72.611063   \n",
       "1  10.358927  0.173229   0.49706  0.568932   9.292698   72.611063   \n",
       "2  11.626917  7.709560   0.97556  1.198821  37.077772   88.609437   \n",
       "3  14.852022  6.122162   0.49706  0.284466  18.529584   82.416803   \n",
       "4  13.666727  8.153058  48.50134  0.121914  16.408728  146.109943   \n",
       "\n",
       "             GF         GH         GI         GL  Class  \n",
       "0   2003.810319  22.136229  69.834944   0.120343    1.0  \n",
       "1  27981.562750  29.135430  32.131996  21.978000    0.0  \n",
       "2  13676.957810  28.022851  35.192676   0.196941    0.0  \n",
       "3   2094.262452  39.948656  90.493248   0.155829    0.0  \n",
       "4   8524.370502  45.381316  36.262628   0.096614    1.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\n",
    "\n",
    "df = pd.concat([train,test],axis=0)\n",
    "print('data shape', train.shape )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d253e3ab",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-08-07T13:32:51.985760Z",
     "iopub.status.busy": "2023-08-07T13:32:51.985382Z",
     "iopub.status.idle": "2023-08-07T13:32:52.010801Z",
     "shell.execute_reply": "2023-08-07T13:32:52.009508Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.318636,
     "end_time": "2023-08-07T13:32:52.013001",
     "exception": false,
     "start_time": "2023-08-07T13:32:51.694365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will train 59 Feature\n"
     ]
    }
   ],
   "source": [
    "# tree based feature\n",
    "train = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\n",
    "train['EJ_A'] = (train['EJ'] =='A').astype(int)\n",
    "train['EJ_B'] = (train['EJ'] =='B').astype(int)\n",
    "# isna feature\n",
    "train['BQ_isna']  = train.BQ.isna().astype(int)\n",
    "train['EL_isna']  = train.EL.isna().astype(int)\n",
    "\n",
    "train.drop('EJ',axis=1,inplace=True)\n",
    "\n",
    "FEATURES = []\n",
    "for c in train.columns:\n",
    "    if c in ['Id','Class']:continue\n",
    "    FEATURES.append(c)\n",
    "    \n",
    "print(f'I will train {len(FEATURES)} Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4cb3e4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T13:32:52.645277Z",
     "iopub.status.busy": "2023-08-07T13:32:52.644907Z",
     "iopub.status.idle": "2023-08-07T13:32:52.653321Z",
     "shell.execute_reply": "2023-08-07T13:32:52.652324Z"
    },
    "papermill": {
     "duration": 0.30493,
     "end_time": "2023-08-07T13:32:52.655389",
     "exception": false,
     "start_time": "2023-08-07T13:32:52.350459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_params_1 ={ 'colsample_bylevel' : 0.6, 'colsample_bytree' : 1.0, \n",
    "'learning_rate' : 0.3,  'max_depth' : 4,  'n_estimators' : 1000,  'subsample' : 1.0,    'scale_pos_weight' : 5}\n",
    "\n",
    "cat_params_1 = {\"depth\":4, \"l2_leaf_reg\" : 50, \"learning_rate\" : 0.3,\n",
    "\"objective\": \"Logloss\", \"logging_level\":\"Silent\", \"iterations\" : 10000,\n",
    "\"auto_class_weights\" : \"Balanced\", \"one_hot_max_size\":10}\n",
    "\n",
    "lgbm_params = {\n",
    "    \"max_depth\": 4,\n",
    "    \"num_leaves\": 9,\n",
    "    \"min_child_samples\": 17,\n",
    "    \"n_estimators\": 200,\n",
    "    \"learning_rate\": 0.15,\n",
    "    \"colsample_bytree\": 0.4,\n",
    "    \"min_split_gain\": 1e-4,\n",
    "    \"reg_alpha\": 1e-2,\n",
    "    \"reg_lambda\": 5e-3,\n",
    "    'early_stopping_round':10,\n",
    "}\n",
    "xgb_params_2 = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'learning_rate': 0.05, \n",
    "     'n_estimators' : 1000,\n",
    "        'max_depth': 3,\n",
    "        'colsample_bytree': 0.50,\n",
    "        'subsample': 0.80,\n",
    "        'eta': 0.03,\n",
    "        'gamma': 1.5,\n",
    "#         'tree_method':'gpu_hist'\n",
    "    }\n",
    "    \n",
    "cat_params_2 = {\n",
    "        'learning_rate': 0.05, \n",
    "        'iterations': 10000, \n",
    "        'depth': 3, # \n",
    "        'colsample_bylevel': 0.50,\n",
    "        'subsample': 0.80,\n",
    "        'l2_leaf_reg': 3, # 3, 30\n",
    "        'auto_class_weights': 'Balanced',\n",
    "#         'task_type':'GPU', \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd05c046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T13:32:53.267118Z",
     "iopub.status.busy": "2023-08-07T13:32:53.266740Z",
     "iopub.status.idle": "2023-08-07T13:36:50.731078Z",
     "shell.execute_reply": "2023-08-07T13:36:50.729770Z"
    },
    "papermill": {
     "duration": 237.807449,
     "end_time": "2023-08-07T13:36:50.733302",
     "exception": false,
     "start_time": "2023-08-07T13:32:52.925853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Bag 1\n",
      "=> Fold 1  (19) (4) (25) (70) (83) ,=> Fold 2  (122) (55) (145) (152) (242) ,=> Fold 3  (53) (56) (99) (210) (198) ,=> Fold 4  (33) (18) (56) (134) (109) ,=> Fold 5  (52) (17) (74) (167) (182) ,=> Fold 6  (60) (26) (131) (166) (173) ,=> Fold 7  (54) (47) (42) (101) (139) ,=> Fold 8  (52) (43) (85) (117) (171) ,=> Fold 9  (37) (45) (97) (120) (196) ,=> Fold 10  (53) (21) (87) (107) (199) ,\n",
      "### Bag 2\n",
      "=> Fold 1  (48) (24) (25) (65) (175) ,=> Fold 2  (75) (151) (119) (184) (209) ,=> Fold 3  (40) (12) (23) (119) (112) ,=> Fold 4  (42) (46) (47) (191) (122) ,=> Fold 5  (57) (20) (47) (168) (205) ,=> Fold 6  (38) (39) (75) (127) (229) ,=> Fold 7  (46) (31) (76) (106) (91) ,=> Fold 8  (53) (21) (46) (77) (197) ,=> Fold 9  (43) (10) (69) (113) (147) ,=> Fold 10  (38) (41) (85) (95) (129) ,\n",
      "### Bag 3\n",
      "=> Fold 1  (22) (7) (19) (67) (92) ,=> Fold 2  (88) (39) (143) (161) (205) ,=> Fold 3  (39) (42) (109) (182) (210) ,=> Fold 4  (31) (9) (33) (121) (130) ,=> Fold 5  (81) (64) (184) (201) (171) ,=> Fold 6  (63) (54) (76) (167) (272) ,=> Fold 7  (61) (10) (202) (148) (256) ,=> Fold 8  (37) (8) (9) (95) (79) ,=> Fold 9  (69) (36) (144) (152) (175) ,=> Fold 10  (26) (7) (43) (96) (69) ,\n",
      "### Bag 4\n",
      "=> Fold 1  (39) (34) (85) (138) (214) ,=> Fold 2  (47) (32) (101) (158) (154) ,=> Fold 3  (83) (127) (134) (195) (390) ,=> Fold 4  (48) (33) (107) (117) (110) ,=> Fold 5  (56) (13) (60) (121) (132) ,=> Fold 6  (41) (35) (72) (144) (122) ,=> Fold 7  (40) (7) (53) (103) (94) ,=> Fold 8  (65) (33) (68) (119) (217) ,=> Fold 9  (49) (24) (70) (86) (116) ,=> Fold 10  (45) (41) (40) (110) (243) ,\n",
      "### Bag 5\n",
      "=> Fold 1  (60) (10) (54) (120) (134) ,=> Fold 2  (37) (1) (19) (93) (139) ,=> Fold 3  (91) (74) (159) (127) (206) ,=> Fold 4  (67) (23) (57) (133) (131) ,=> Fold 5  (69) (39) (51) (155) (197) ,=> Fold 6  (25) (8) (82) (130) (135) ,=> Fold 7  (49) (27) (109) (115) (181) ,=> Fold 8  (98) (21) (109) (117) (138) ,=> Fold 9  (123) (58) (73) (162) (124) ,=> Fold 10  (30) (9) (28) (149) (99) ,\n",
      "### Bag 6\n",
      "=> Fold 1  (20) (24) (34) (107) (98) ,=> Fold 2  (26) (19) (38) (100) (161) ,=> Fold 3  (51) (68) (37) (110) (199) ,=> Fold 4  (51) (11) (57) (114) (169) ,=> Fold 5  (89) (60) (137) (160) (403) ,=> Fold 6  (60) (85) (103) (161) (230) ,=> Fold 7  (26) (21) (37) (91) (88) ,=> Fold 8  (46) (68) (307) (110) (145) ,=> Fold 9  (52) (30) (61) (153) (240) ,=> Fold 10  (29) (29) (64) (113) (117) ,\n",
      "### Bag 7\n",
      "=> Fold 1  (45) (19) (59) (103) (141) ,=> Fold 2  (29) (9) (84) (100) (146) ,=> Fold 3  (29) (8) (56) (68) (135) ,=> Fold 4  (106) (44) (213) (183) (289) ,=> Fold 5  (116) (40) (41) (191) (257) ,=> Fold 6  (84) (24) (163) (128) (352) ,=> Fold 7  (24) (47) (29) (107) (132) ,=> Fold 8  (34) (10) (91) (138) (240) ,=> Fold 9  (43) (22) (190) (113) (203) ,=> Fold 10  (68) (39) (121) (141) (186) ,\n",
      "### Bag 8\n",
      "=> Fold 1  (44) (35) (21) (127) (72) ,=> Fold 2  (54) (38) (203) (119) (182) ,=> Fold 3  (93) (31) (99) (151) (365) ,=> Fold 4  (91) (33) (116) (146) (211) ,=> Fold 5  (41) (14) (103) (174) (248) ,=> Fold 6  (30) (12) (41) (104) (135) ,=> Fold 7  (52) (19) (88) (133) (161) ,=> Fold 8  (27) (2) (53) (123) (84) ,=> Fold 9  (64) (34) (124) (175) (213) ,=> Fold 10  (42) (30) (99) (127) (253) ,\n",
      "### Bag 9\n",
      "=> Fold 1  (56) (20) (115) (79) (188) ,=> Fold 2  (146) (90) (248) (268) (380) ,=> Fold 3  (64) (19) (39) (157) (201) ,=> Fold 4  (56) (50) (71) (150) (162) ,=> Fold 5  (23) (30) (55) (100) (174) ,=> Fold 6  (23) (30) (73) (124) (89) ,=> Fold 7  (91) (33) (105) (161) (252) ,=> Fold 8  (109) (60) (175) (179) (326) ,=> Fold 9  (28) (32) (59) (145) (203) ,=> Fold 10  (81) (37) (36) (127) (159) ,\n",
      "### Bag 10\n",
      "=> Fold 1  (95) (34) (77) (165) (287) ,=> Fold 2  (35) (17) (99) (147) (130) ,=> Fold 3  (19) (16) (55) (106) (153) ,=> Fold 4  (43) (36) (94) (122) (184) ,=> Fold 5  (31) (25) (107) (145) (170) ,=> Fold 6  (54) (45) (88) (156) (71) ,=> Fold 7  (74) (52) (136) (174) (271) ,=> Fold 8  (60) (30) (42) (113) (127) ,=> Fold 9  (38) (19) (82) (95) (142) ,=> Fold 10  (53) (89) (28) (139) (204) ,\n",
      "### Bag 11\n",
      "=> Fold 1  (115) (66) (84) (141) (174) ,=> Fold 2  (65) (14) (51) (111) (134) ,=> Fold 3  (39) (11) (53) (101) (136) ,=> Fold 4  (59) (25) (114) (135) (177) ,=> Fold 5  (38) (35) (88) (89) (143) ,=> Fold 6  (34) (61) (87) (160) (126) ,=> Fold 7  (65) (46) (118) (190) (294) ,=> Fold 8  (79) (50) (84) (178) (197) ,=> Fold 9  (15) (8) (10) (53) (71) ,=> Fold 10  (55) (65) (194) (132) (307) ,\n",
      "### Bag 12\n",
      "=> Fold 1  (27) (29) (73) (115) (165) ,=> Fold 2  (62) (37) (90) (215) (187) ,=> Fold 3  (88) (19) (175) (172) (290) ,=> Fold 4  (48) (16) (116) (103) (174) ,=> Fold 5  (29) (20) (64) (84) (141) ,=> Fold 6  (51) (13) (63) (93) (224) ,=> Fold 7  (78) (37) (56) (137) (137) ,=> Fold 8  (48) (45) (149) (178) (162) ,=> Fold 9  (41) (42) (103) (123) (202) ,=> Fold 10  (56) (15) (55) (120) (126) ,\n",
      "### Bag 13\n",
      "=> Fold 1  (25) (11) (23) (74) (114) ,=> Fold 2  (38) (14) (41) (119) (127) ,=> Fold 3  (50) (27) (48) (131) (108) ,=> Fold 4  (57) (33) (181) (146) (269) ,=> Fold 5  (17) (9) (23) (60) (84) ,=> Fold 6  (60) (72) (105) (175) (185) ,=> Fold 7  (58) (17) (43) (147) (152) ,=> Fold 8  (60) (20) (42) (135) (168) ,=> Fold 9  (120) (178) (271) (194) (251) ,=> Fold 10  (115) (22) (135) (142) (200) ,\n",
      "### Bag 14\n",
      "=> Fold 1  (59) (26) (51) (169) (150) ,=> Fold 2  (133) (52) (114) (165) (165) ,=> Fold 3  (45) (43) (72) (140) (179) ,=> Fold 4  (28) (20) (103) (132) (179) ,=> Fold 5  (40) (51) (190) (127) (182) ,=> Fold 6  (54) (9) (16) (102) (91) ,=> Fold 7  (48) (132) (58) (239) (135) ,=> Fold 8  (29) (19) (43) (115) (178) ,=> Fold 9  (55) (41) (33) (117) (172) ,=> Fold 10  (61) (28) (131) (147) (164) ,\n",
      "### Bag 15\n",
      "=> Fold 1  (34) (11) (46) (91) (138) ,=> Fold 2  (33) (26) (70) (105) (104) ,=> Fold 3  (15) (16) (23) (67) (49) ,=> Fold 4  (62) (57) (80) (130) (172) ,=> Fold 5  (41) (26) (47) (158) (202) ,=> Fold 6  (98) (37) (175) (160) (247) ,=> Fold 7  (51) (28) (89) (164) (230) ,=> Fold 8  (66) (27) (71) (143) (210) ,=> Fold 9  (74) (66) (60) (209) (148) ,=> Fold 10  (52) (14) (108) (118) (119) ,\n",
      "### Bag 16\n",
      "=> Fold 1  (40) (25) (90) (173) (268) ,=> Fold 2  (45) (21) (53) (130) (156) ,=> Fold 3  (98) (69) (214) (138) (273) ,=> Fold 4  (48) (45) (115) (140) (319) ,=> Fold 5  (81) (49) (74) (101) (193) ,=> Fold 6  (64) (55) (101) (140) (157) ,=> Fold 7  (39) (24) (62) (115) (114) ,=> Fold 8  (43) (29) (70) (128) (125) ,=> Fold 9  (59) (40) (40) (99) (213) ,=> Fold 10  (40) (11) (58) (124) (125) ,\n",
      "### Bag 17\n",
      "=> Fold 1  (33) (37) (99) (150) (137) ,=> Fold 2  (70) (28) (161) (72) (200) ,=> Fold 3  (32) (6) (37) (69) (59) ,=> Fold 4  (98) (50) (76) (118) (342) ,=> Fold 5  (29) (18) (61) (113) (160) ,=> Fold 6  (86) (88) (58) (220) (266) ,=> Fold 7  (75) (31) (49) (131) (126) ,=> Fold 8  (62) (49) (80) (160) (193) ,=> Fold 9  (58) (21) (57) (134) (136) ,=> Fold 10  (54) (20) (146) (117) (183) ,\n",
      "### Bag 18\n",
      "=> Fold 1  (60) (34) (94) (78) (210) ,=> Fold 2  (86) (106) (166) (122) (231) ,=> Fold 3  (42) (90) (113) (189) (252) ,=> Fold 4  (38) (19) (58) (102) (147) ,=> Fold 5  (56) (30) (78) (168) (217) ,=> Fold 6  (29) (14) (60) (108) (112) ,=> Fold 7  (36) (29) (32) (89) (171) ,=> Fold 8  (29) (14) (66) (128) (285) ,=> Fold 9  (52) (9) (80) (156) (186) ,=> Fold 10  (32) (16) (31) (131) (164) ,\n",
      "### Bag 19\n",
      "=> Fold 1  (51) (32) (150) (176) (289) ,=> Fold 2  (49) (29) (50) (87) (161) ,=> Fold 3  (39) (28) (105) (131) (183) ,=> Fold 4  (50) (31) (79) (139) (176) ,=> Fold 5  (68) (27) (63) (116) (266) ,=> Fold 6  (61) (21) (77) (120) (141) ,=> Fold 7  (69) (27) (73) (158) (119) ,=> Fold 8  (48) (66) (76) (130) (155) ,=> Fold 9  (84) (29) (34) (150) (189) ,=> Fold 10  (55) (35) (143) (179) (231) ,\n",
      "### Bag 20\n",
      "=> Fold 1  (60) (21) (80) (161) (164) ,=> Fold 2  (66) (29) (109) (156) (259) ,=> Fold 3  (40) (38) (107) (114) (248) ,=> Fold 4  (33) (26) (78) (93) (64) ,=> Fold 5  (42) (31) (50) (145) (177) ,=> Fold 6  (58) (39) (44) (134) (153) ,=> Fold 7  (63) (38) (123) (138) (241) ,=> Fold 8  (97) (122) (147) (196) (102) ,=> Fold 9  (38) (23) (16) (86) (136) ,=> Fold 10  (25) (5) (53) (84) (105) ,\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "CV Score : \n",
      "TabPFN =  0.278\n",
      "LGBM   =  0.221\n",
      "XGB    =  0.219\n",
      "CBT    =  0.248\n",
      "XGB_2  =  0.279\n",
      "CBT_2  =  0.249\n"
     ]
    }
   ],
   "source": [
    "BAGS = 20\n",
    "FOLDS = 10\n",
    "## try XGBoost but not work\n",
    "\n",
    "oof_lgb = np.zeros(len(train))\n",
    "oof_xgb = np.zeros(len(train))\n",
    "oof_cbt = np.zeros(len(train))\n",
    "\n",
    "oof_xgb_2 = np.zeros(len(train))\n",
    "oof_cbt_2 = np.zeros(len(train))\n",
    "\n",
    "# model saved\n",
    "models_lgb = {}\n",
    "models_xgb = {}\n",
    "models_cbt = {}\n",
    "\n",
    "models_xgb_2 = {}\n",
    "models_cbt_2 = {}\n",
    "for bag in range(BAGS):\n",
    "    \n",
    "    print('### Bag',bag+1)\n",
    "    \n",
    "    models_lgb[bag] = []\n",
    "    models_xgb[bag] =[]\n",
    "    models_cbt[bag] =[]\n",
    "    \n",
    "    models_xgb_2[bag] =[]\n",
    "    models_cbt_2[bag] =[]\n",
    "    \n",
    "    skf = KFold(n_splits=FOLDS, shuffle=True, random_state=bag)\n",
    "    for fold,(train_idx, valid_idx) in enumerate(skf.split(X=train[FEATURES], y=train['Class'])):\n",
    "    \n",
    "        print('=> Fold',fold+1,' ',end='')\n",
    "        \n",
    "        # DOWNSAMPLE NEGATIVE CLASS TO BALANCE CLASSES\n",
    "        y_train = train.loc[train_idx,'Class']\n",
    "        RMV = y_train.loc[y_train==0].sample(\n",
    "            frac=0.7, random_state=bag*BAGS+fold).index.values\n",
    "        train_idx = np.setdiff1d(train_idx,RMV)\n",
    "\n",
    "        # TRAIN DATA\n",
    "        X_train = train.loc[train_idx,FEATURES]\n",
    "        y_train = train.loc[train_idx,'Class']\n",
    "        # VALID DATA\n",
    "        X_valid = train.loc[valid_idx,FEATURES]\n",
    "        y_valid = train.loc[valid_idx,'Class']\n",
    "        \n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)]\n",
    "        \n",
    "        # LGBM \n",
    "        clf = LGBMClassifier(**lgbm_params)\n",
    "        clf.fit(X_train, y_train, eval_metric = 'logloss', eval_set = (X_valid, y_valid),  verbose=0)\n",
    "        print(f'({clf.best_iteration_})' , end=' ')\n",
    "        oof_lgb[valid_idx] += clf.predict_proba(X_valid)[:,1] / BAGS\n",
    "        models_lgb[bag].append(clf)\n",
    "        \n",
    "        # XGB 1\n",
    "        clf = XGBClassifier(**xgb_params_1)\n",
    "        clf.fit(X_train, y_train, eval_metric = [\"logloss\"], eval_set = eval_set, early_stopping_rounds = 10, verbose=0)\n",
    "        print(f'({clf.best_iteration})' , end=' ')\n",
    "        oof_xgb[valid_idx] += clf.predict_proba(X_valid)[:,1] / BAGS\n",
    "        models_xgb[bag].append(clf)\n",
    "        \n",
    "        # CBT 1\n",
    "        clf = CatBoostClassifier(**cat_params_1)\n",
    "        clf.fit(X_train,y_train ,eval_set = eval_set, verbose=0,early_stopping_rounds=10)\n",
    "        print(f'({clf.best_iteration_})' , end=' ')\n",
    "        oof_cbt[valid_idx] += clf.predict_proba(X_valid)[:,1] / BAGS\n",
    "        models_cbt[bag].append(clf)\n",
    "        \n",
    "        # XGB 2\n",
    "        clf = XGBClassifier(**xgb_params_2)\n",
    "        clf.fit(X_train, y_train, eval_metric = [\"logloss\"], eval_set = eval_set, early_stopping_rounds = 10, verbose=0)\n",
    "        print(f'({clf.best_iteration})' , end=' ')\n",
    "        oof_xgb_2[valid_idx] += clf.predict_proba(X_valid)[:,1] / BAGS\n",
    "        models_xgb_2[bag].append(clf)\n",
    "        \n",
    "        # CBT 2\n",
    "        clf = CatBoostClassifier(**cat_params_2)\n",
    "        clf.fit(X_train,y_train ,eval_set = [(X_train, y_train), (X_valid, y_valid)], verbose=0,early_stopping_rounds=10)\n",
    "        print(f'({clf.best_iteration_})' , end=' ,')\n",
    "        oof_cbt_2[valid_idx] += clf.predict_proba(X_valid)[:,1] / BAGS\n",
    "        models_cbt_2[bag].append(clf)\n",
    "        \n",
    "    print()\n",
    "    \n",
    "print('-'*150)\n",
    "print('CV Score : ')\n",
    "# CV Score : \n",
    "oof_tpc = pd.read_csv('/kaggle/input/tabpfn-model/oof_tpc.csv')\n",
    "oof_tpc = oof_tpc.values.squeeze()\n",
    "mt = balance_logloss( train.Class.values, oof_tpc )\n",
    "print('TabPFN = ',mt.round(3))\n",
    "mg = balance_logloss( train.Class.values, oof_lgb )\n",
    "print('LGBM   = ',mg.round(3))\n",
    "mx = balance_logloss( train.Class.values, oof_xgb )\n",
    "print('XGB    = ',mx.round(3))\n",
    "mc = balance_logloss( train.Class.values, oof_cbt )\n",
    "print('CBT    = ',mc.round(3))\n",
    "\n",
    "mx2 = balance_logloss( train.Class.values, oof_xgb_2 )\n",
    "print('XGB_2  = ',mx2.round(3))\n",
    "mc2 = balance_logloss( train.Class.values, oof_cbt_2 )\n",
    "print('CBT_2  = ',mc2.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4705b31a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T13:36:51.363148Z",
     "iopub.status.busy": "2023-08-07T13:36:51.362744Z",
     "iopub.status.idle": "2023-08-07T13:36:51.461037Z",
     "shell.execute_reply": "2023-08-07T13:36:51.460054Z"
    },
    "papermill": {
     "duration": 0.417439,
     "end_time": "2023-08-07T13:36:51.463629",
     "exception": false,
     "start_time": "2023-08-07T13:36:51.046190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\n",
    "train['EJ_A'] = (train['EJ'] =='A').astype(int)\n",
    "train['EJ_B'] = (train['EJ'] =='B').astype(int)\n",
    "\n",
    "# isna feature\n",
    "train['BQ_isna']  = train.BQ.isna().astype(int)\n",
    "train['EL_isna']  = train.EL.isna().astype(int)\n",
    "\n",
    "train.drop('EJ',axis=1,inplace=True)\n",
    "\n",
    "# SAVE MEANS, STDS, NANS FOR TEST INFERENCE LATER\n",
    "means = {}; stds = {}; nans = {}\n",
    "for c in train.columns:\n",
    "    if c in ['Id','Class']:continue\n",
    "    m = train[c].mean()\n",
    "    means[c] = m\n",
    "    s = train[c].std()\n",
    "    stds[c] = s\n",
    "    train[c] = (train[c]-m)/s\n",
    "    n = train[c].min() - 0.5\n",
    "    nans[c] = n\n",
    "    train[c] = train[c].fillna(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36e44ac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T13:36:52.145256Z",
     "iopub.status.busy": "2023-08-07T13:36:52.144882Z",
     "iopub.status.idle": "2023-08-07T13:37:52.058698Z",
     "shell.execute_reply": "2023-08-07T13:37:52.057233Z"
    },
    "papermill": {
     "duration": 60.230346,
     "end_time": "2023-08-07T13:37:52.060781",
     "exception": false,
     "start_time": "2023-08-07T13:36:51.830435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Bag 1\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 2\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 3\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 4\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 5\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 6\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 7\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 8\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 9\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 10\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 11\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 12\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 13\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 14\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 15\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 16\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 17\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 18\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 19\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "### Bag 20\n",
      "=> Fold 1 , => Fold 2 , => Fold 3 , => Fold 4 , => Fold 5 , => Fold 6 , => Fold 7 , => Fold 8 , => Fold 9 , => Fold 10 , \n",
      "LogisticRegression score =  0.327\n",
      "SVM score =  0.34\n"
     ]
    }
   ],
   "source": [
    "BAGS = 20\n",
    "FOLDS = 10\n",
    "oof_svc = np.zeros(len(train))\n",
    "oof_lr = np.zeros(len(train))\n",
    "\n",
    "models_svc = {}\n",
    "models_lr = {}\n",
    "\n",
    "for bag in range(BAGS):\n",
    "#     print('#'*25)\n",
    "    print('### Bag',bag+1)\n",
    "#     print('#'*25)\n",
    "    models_svc[bag] = []\n",
    "    models_lr[bag] = []\n",
    "    \n",
    "    skf = KFold(n_splits=FOLDS, shuffle=True, random_state=bag)\n",
    "    for fold,(train_idx, valid_idx) in enumerate(skf.split(X=train[FEATURES], y=train['Class'])):\n",
    "\n",
    "        print('=> Fold',fold+1,', ',end='')\n",
    "\n",
    "        # DOWNSAMPLE NEGATIVE CLASS TO BALANCE CLASSES\n",
    "        y_train = train.loc[train_idx,'Class']\n",
    "        RMV = y_train.loc[y_train==0].sample(\n",
    "            frac=0.7, random_state=bag*BAGS+fold).index.values\n",
    "        train_idx = np.setdiff1d(train_idx,RMV)\n",
    "\n",
    "        # TRAIN DATA\n",
    "        X_train = train.loc[train_idx,FEATURES]\n",
    "        y_train = train.loc[train_idx,'Class']\n",
    "\n",
    "        # VALID DATA\n",
    "        X_valid = train.loc[valid_idx,FEATURES]\n",
    "        y_valid = train.loc[valid_idx,'Class']\n",
    "\n",
    "        \n",
    "        # SVC\n",
    "        clf = SVC(C=5, probability=True) \n",
    "        clf.fit(X_train, y_train)\n",
    "        oof_svc[valid_idx] += clf.predict_proba(X_valid).iloc[:,1].values / BAGS\n",
    "        models_svc[bag].append(clf)\n",
    "        \n",
    "        #Logistic Regression\n",
    "        clf = LogisticRegression(solver='liblinear')\n",
    "        clf.fit(X_train, y_train)\n",
    "        oof_lr[valid_idx] += clf.predict_proba(X_valid)[:,1] / BAGS\n",
    "        models_lr[bag].append(clf)\n",
    "        \n",
    "    print()\n",
    "    \n",
    "ml = balance_logloss( train.Class.values, oof_lr )\n",
    "print('LogisticRegression score = ',ml.round(3))\n",
    "ms = balance_logloss( train.Class.values, oof_svc )\n",
    "print('SVM score = ',ms.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ee84a3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T13:37:52.785745Z",
     "iopub.status.busy": "2023-08-07T13:37:52.785386Z",
     "iopub.status.idle": "2023-08-07T13:37:52.801795Z",
     "shell.execute_reply": "2023-08-07T13:37:52.800801Z"
    },
    "papermill": {
     "duration": 0.422509,
     "end_time": "2023-08-07T13:37:52.803768",
     "exception": false,
     "start_time": "2023-08-07T13:37:52.381259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM score =  0.221\n",
      "TPFN score =  0.278\n",
      "XGB score =  0.219\n",
      "CBT score =  0.248\n",
      "SVC score =  0.34\n",
      "LR  score =  0.327\n",
      "XGB2score =  0.279\n",
      "CBT2 score =  0.249\n",
      "****************************************\n",
      "CV Score = 0.23\n"
     ]
    }
   ],
   "source": [
    "m0 = balance_logloss( train.Class.values, oof_lgb )\n",
    "print('LGBM score = ',m0.round(3))\n",
    "m6 = balance_logloss( train.Class.values, oof_tpc )\n",
    "print('TPFN score = ',m6.round(3))\n",
    "m4 = balance_logloss( train.Class.values, oof_xgb )\n",
    "print('XGB score = ',m4.round(3))\n",
    "m5 = balance_logloss( train.Class.values, oof_cbt )\n",
    "print('CBT score = ',m5.round(3))\n",
    "m1 =  balance_logloss( train.Class.values, oof_svc )\n",
    "print('SVC score = ',m1.round(3))\n",
    "m2 =  balance_logloss( train.Class.values, oof_lr )\n",
    "print('LR  score = ',m2.round(3))\n",
    "m8 =  balance_logloss( train.Class.values, oof_xgb_2 )\n",
    "print('XGB2score = ',m8.round(3))\n",
    "m8 =  balance_logloss( train.Class.values, oof_cbt_2 )\n",
    "print('CBT2 score = ',m8.round(3))\n",
    "## I dorp SVM from ensemble\n",
    "oof = \\\n",
    "(oof_tpc * 0.20) + \\\n",
    "    (oof_lgb * 0.20) + \\\n",
    "        (oof_xgb * 0.25) + \\\n",
    "            (oof_cbt * 0.20) + \\\n",
    "                (oof_lr  * 0.05) + \\\n",
    "                    (oof_xgb_2  * 0.05) + \\\n",
    "                        (oof_cbt_2  * 0.05)\n",
    "m = balance_logloss( train.Class.values, oof )\n",
    "print('*'*40)\n",
    "print('CV Score =',m.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bd7058f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T13:37:53.450701Z",
     "iopub.status.busy": "2023-08-07T13:37:53.450341Z",
     "iopub.status.idle": "2023-08-07T13:38:29.542724Z",
     "shell.execute_reply": "2023-08-07T13:38:29.541602Z"
    },
    "papermill": {
     "duration": 36.415067,
     "end_time": "2023-08-07T13:38:29.545711",
     "exception": false,
     "start_time": "2023-08-07T13:37:53.130644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabPFN Model predict..\n"
     ]
    }
   ],
   "source": [
    "print('TabPFN Model predict..')\n",
    "models_tpc = {}\n",
    "for bag in range(1,6):\n",
    "    models_tpc[bag] =[]\n",
    "    for i in range(1,6):\n",
    "        loaded_model = pickle.load(open(f'/kaggle/input/tabpfn-model/bag_{bag}_fold_{i}.sav', 'rb'))\n",
    "        models_tpc[bag].append(loaded_model)\n",
    "        \n",
    "\n",
    "test = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\n",
    "test['EJ_A'] = (test['EJ'] =='A').astype(int)\n",
    "test['EJ_B'] = (test['EJ'] =='B').astype(int)\n",
    "# isna feature\n",
    "test['BQ_isna']  = test.BQ.isna().astype(int)\n",
    "test['EL_isna']  = test.EL.isna().astype(int)\n",
    "test.drop('EJ',axis=1,inplace=True)\n",
    "\n",
    "preds_tpc = np.zeros(len(test))\n",
    "\n",
    "for bag in range(1,6):\n",
    "    for clf in models_tpc[bag]:\n",
    "            X_test = test[FEATURES]\n",
    "            preds_tpc += clf.predict_proba(X_test)[:,1] / 5 / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ad6a3c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T13:38:30.226265Z",
     "iopub.status.busy": "2023-08-07T13:38:30.225877Z",
     "iopub.status.idle": "2023-08-07T13:38:32.659182Z",
     "shell.execute_reply": "2023-08-07T13:38:32.658229Z"
    },
    "papermill": {
     "duration": 2.767185,
     "end_time": "2023-08-07T13:38:32.661629",
     "exception": false,
     "start_time": "2023-08-07T13:38:29.894444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# None-Tree Based Model Predict..\n"
     ]
    }
   ],
   "source": [
    "print('# None-Tree Based Model Predict..')\n",
    "preds_svc = np.zeros(len(test))\n",
    "preds_lr = np.zeros(len(test))\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\n",
    "test['EJ_A'] = (test['EJ'] =='A').astype(int)\n",
    "test['EJ_B'] = (test['EJ'] =='B').astype(int)\n",
    "\n",
    "# isna feature\n",
    "test['BQ_isna']  = test.BQ.isna().astype(int)\n",
    "test['EL_isna']  = test.EL.isna().astype(int)\n",
    "\n",
    "test.drop('EJ',axis=1,inplace=True)\n",
    "\n",
    "for c in test.columns:\n",
    "    if c in ['Id','Class']:continue\n",
    "    m = means[c]\n",
    "    s = stds[c]\n",
    "    test[c] = (test[c]-m)/s\n",
    "    n = nans[c]\n",
    "    test[c] = test[c].fillna(n)\n",
    "    \n",
    "for bag in range(BAGS):\n",
    "    for clf in models_svc[bag]:\n",
    "            X_test = test[FEATURES]\n",
    "            preds_svc += clf.predict_proba(X_test).iloc[:,1].values / FOLDS / BAGS\n",
    "            \n",
    "    for clf in models_lr[bag]:\n",
    "            X_test = test[FEATURES]\n",
    "            preds_lr += clf.predict_proba(X_test)[:,1] / FOLDS / BAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07ba58dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T13:38:33.326592Z",
     "iopub.status.busy": "2023-08-07T13:38:33.326224Z",
     "iopub.status.idle": "2023-08-07T13:38:37.482131Z",
     "shell.execute_reply": "2023-08-07T13:38:37.481262Z"
    },
    "papermill": {
     "duration": 4.484201,
     "end_time": "2023-08-07T13:38:37.484417",
     "exception": false,
     "start_time": "2023-08-07T13:38:33.000216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models Predict (LGBM)..\n",
      "Models Predict (CBT)..\n",
      "Models Predict (XGB)..\n",
      "Models Predict (CB_2)..\n",
      "Models Predict (XGB2)..\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\n",
    "test['EJ_A'] = (test['EJ'] =='A').astype(int)\n",
    "test['EJ_B'] = (test['EJ'] =='B').astype(int)\n",
    "# isna feature\n",
    "test['BQ_isna']  = test.BQ.isna().astype(int)\n",
    "test['EL_isna']  = test.EL.isna().astype(int)\n",
    "\n",
    "test.drop('EJ',axis=1,inplace=True)\n",
    "\n",
    "print('Models Predict (LGBM)..')\n",
    "preds_lgb = np.zeros(len(test))\n",
    "for bag in range(BAGS):\n",
    "    for clf in models_lgb[bag]:\n",
    "            X_test = test[FEATURES]\n",
    "            preds_lgb += clf.predict_proba(X_test)[:,1] / FOLDS / BAGS\n",
    "            \n",
    "print('Models Predict (CBT)..')\n",
    "preds_cbt = np.zeros(len(test))\n",
    "for bag in range(BAGS):\n",
    "    \n",
    "    for clf in models_cbt[bag]:\n",
    "            X_test = test[FEATURES]\n",
    "            preds_cbt += clf.predict_proba(X_test)[:,1] / FOLDS / BAGS\n",
    "            \n",
    "print('Models Predict (XGB)..')\n",
    "preds_xgb = np.zeros(len(test))\n",
    "for bag in range(BAGS):\n",
    "    \n",
    "    for clf in models_xgb[bag]:\n",
    "            X_test = test[FEATURES]\n",
    "                        \n",
    "            preds_xgb += clf.predict_proba(X_test)[:,1] / FOLDS / BAGS\n",
    "            \n",
    "            \n",
    "print('Models Predict (CB_2)..')\n",
    "preds_cbt_2 = np.zeros(len(test))\n",
    "for bag in range(BAGS):\n",
    "    \n",
    "    for clf in models_cbt_2[bag]:\n",
    "            X_test = test[FEATURES]\n",
    "                        \n",
    "            preds_cbt_2 += clf.predict_proba(X_test)[:,1] / FOLDS / BAGS\n",
    "            \n",
    "print('Models Predict (XGB2)..')\n",
    "preds_xgb_2 = np.zeros(len(test))\n",
    "for bag in range(BAGS):\n",
    "    \n",
    "    for clf in models_xgb_2[bag]:\n",
    "            X_test = test[FEATURES]\n",
    "                        \n",
    "            preds_xgb_2 += clf.predict_proba(X_test)[:,1] / FOLDS / BAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21178452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T13:38:38.153240Z",
     "iopub.status.busy": "2023-08-07T13:38:38.152844Z",
     "iopub.status.idle": "2023-08-07T13:38:38.159245Z",
     "shell.execute_reply": "2023-08-07T13:38:38.158176Z"
    },
    "papermill": {
     "duration": 0.341371,
     "end_time": "2023-08-07T13:38:38.162403",
     "exception": false,
     "start_time": "2023-08-07T13:38:37.821032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensamble..\n"
     ]
    }
   ],
   "source": [
    "print('Ensamble..')\n",
    "preds = \\\n",
    "    preds_tpc * 0.20 + \\\n",
    "        preds_lgb * 0.20 + \\\n",
    "            preds_xgb * 0.25 + \\\n",
    "                preds_cbt * 0.20 + \\\n",
    "                    preds_lr * 0.05 + \\\n",
    "                        preds_xgb_2 * 0.05 + \\\n",
    "                            preds_cbt_2 * 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fda5d0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T13:38:38.822972Z",
     "iopub.status.busy": "2023-08-07T13:38:38.822615Z",
     "iopub.status.idle": "2023-08-07T13:38:38.827332Z",
     "shell.execute_reply": "2023-08-07T13:38:38.826136Z"
    },
    "papermill": {
     "duration": 0.33094,
     "end_time": "2023-08-07T13:38:38.829982",
     "exception": false,
     "start_time": "2023-08-07T13:38:38.499042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PREDICT_3 = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b40d591",
   "metadata": {
    "papermill": {
     "duration": 0.423195,
     "end_time": "2023-08-07T13:38:39.582033",
     "exception": false,
     "start_time": "2023-08-07T13:38:39.158838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **SUBMISSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ebecb09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T13:38:40.237155Z",
     "iopub.status.busy": "2023-08-07T13:38:40.236772Z",
     "iopub.status.idle": "2023-08-07T13:38:40.241626Z",
     "shell.execute_reply": "2023-08-07T13:38:40.240596Z"
    },
    "papermill": {
     "duration": 0.332399,
     "end_time": "2023-08-07T13:38:40.243668",
     "exception": false,
     "start_time": "2023-08-07T13:38:39.911269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FINAL_PREDICT = PREDICT_1 * 0.3 + PREDICT_2 * 0.4 + PREDICT_3 * 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "705af11c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T13:38:40.918484Z",
     "iopub.status.busy": "2023-08-07T13:38:40.918121Z",
     "iopub.status.idle": "2023-08-07T13:38:40.939825Z",
     "shell.execute_reply": "2023-08-07T13:38:40.938838Z"
    },
    "papermill": {
     "duration": 0.360497,
     "end_time": "2023-08-07T13:38:40.941863",
     "exception": false,
     "start_time": "2023-08-07T13:38:40.581366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>0.716184</td>\n",
       "      <td>0.283816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>0.716184</td>\n",
       "      <td>0.283816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>0.716184</td>\n",
       "      <td>0.283816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>0.716184</td>\n",
       "      <td>0.283816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>0.716184</td>\n",
       "      <td>0.283816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id   class_0   class_1\n",
       "0  00eed32682bb  0.716184  0.283816\n",
       "1  010ebe33f668  0.716184  0.283816\n",
       "2  02fa521e1838  0.716184  0.283816\n",
       "3  040e15f562a2  0.716184  0.283816\n",
       "4  046e85c7cc7f  0.716184  0.283816"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(os.path.join(filepath, 'sample_submission.csv'))\n",
    "sub['class_1'] = FINAL_PREDICT\n",
    "sub['class_0'] = 1 - FINAL_PREDICT\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19811.273194,
   "end_time": "2023-08-07T13:38:44.972424",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-07T08:08:33.699230",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
